2024-09-20 17:42:38,278:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,317:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,383:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,448:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,616:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,669:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,715:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 17:42:38,818:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:23:34,551:INFO:PyCaret ClassificationExperiment
2024-09-20 18:23:34,553:INFO:Logging name: clf-default-name
2024-09-20 18:23:34,553:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-20 18:23:34,553:INFO:version 3.3.2
2024-09-20 18:23:34,553:INFO:Initializing setup()
2024-09-20 18:23:34,553:INFO:self.USI: 987f
2024-09-20 18:23:34,553:INFO:self._variable_keys: {'memory', 'log_plots_param', '_ml_usecase', 'pipeline', 'target_param', 'gpu_param', 'exp_id', 'y', 'fold_generator', 'fold_shuffle_param', 'exp_name_log', 'is_multiclass', 'fix_imbalance', 'html_param', 'X_test', 'X', 'fold_groups_param', 'data', 'seed', 'idx', 'X_train', 'y_test', 'USI', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'logging_param', 'n_jobs_param'}
2024-09-20 18:23:34,554:INFO:Checking environment
2024-09-20 18:23:34,554:INFO:python_version: 3.10.14
2024-09-20 18:23:34,554:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-20 18:23:34,554:INFO:machine: arm64
2024-09-20 18:23:34,555:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-20 18:23:34,556:INFO:Memory: svmem(total=8589934592, available=1421574144, percent=83.5, used=3030515712, free=83083264, active=1356398592, inactive=1293647872, wired=1674117120)
2024-09-20 18:23:34,556:INFO:Physical Core: 8
2024-09-20 18:23:34,557:INFO:Logical Core: 8
2024-09-20 18:23:34,557:INFO:Checking libraries
2024-09-20 18:23:34,557:INFO:System:
2024-09-20 18:23:34,557:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-20 18:23:34,557:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-20 18:23:34,557:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-20 18:23:34,557:INFO:PyCaret required dependencies:
2024-09-20 18:23:34,558:INFO:                 pip: 24.2
2024-09-20 18:23:34,558:INFO:          setuptools: 72.1.0
2024-09-20 18:23:34,558:INFO:             pycaret: 3.3.2
2024-09-20 18:23:34,558:INFO:             IPython: 8.18.1
2024-09-20 18:23:34,558:INFO:          ipywidgets: 8.1.5
2024-09-20 18:23:34,558:INFO:                tqdm: 4.66.5
2024-09-20 18:23:34,558:INFO:               numpy: 1.26.4
2024-09-20 18:23:34,558:INFO:              pandas: 2.1.4
2024-09-20 18:23:34,558:INFO:              jinja2: 3.1.4
2024-09-20 18:23:34,558:INFO:               scipy: 1.11.4
2024-09-20 18:23:34,558:INFO:              joblib: 1.3.2
2024-09-20 18:23:34,558:INFO:             sklearn: 1.4.2
2024-09-20 18:23:34,558:INFO:                pyod: 2.0.2
2024-09-20 18:23:34,558:INFO:            imblearn: 0.12.3
2024-09-20 18:23:34,558:INFO:   category_encoders: 2.6.3
2024-09-20 18:23:34,558:INFO:            lightgbm: 4.5.0
2024-09-20 18:23:34,558:INFO:               numba: 0.60.0
2024-09-20 18:23:34,558:INFO:            requests: 2.32.3
2024-09-20 18:23:34,558:INFO:          matplotlib: 3.7.5
2024-09-20 18:23:34,558:INFO:          scikitplot: 0.3.7
2024-09-20 18:23:34,558:INFO:         yellowbrick: 1.5
2024-09-20 18:23:34,558:INFO:              plotly: 5.24.0
2024-09-20 18:23:34,558:INFO:    plotly-resampler: Not installed
2024-09-20 18:23:34,558:INFO:             kaleido: 0.2.1
2024-09-20 18:23:34,558:INFO:           schemdraw: 0.15
2024-09-20 18:23:34,558:INFO:         statsmodels: 0.14.3
2024-09-20 18:23:34,558:INFO:              sktime: 0.26.0
2024-09-20 18:23:34,558:INFO:               tbats: 1.1.3
2024-09-20 18:23:34,558:INFO:            pmdarima: 2.0.4
2024-09-20 18:23:34,558:INFO:              psutil: 5.9.0
2024-09-20 18:23:34,558:INFO:          markupsafe: 2.1.3
2024-09-20 18:23:34,558:INFO:             pickle5: Not installed
2024-09-20 18:23:34,558:INFO:         cloudpickle: 3.0.0
2024-09-20 18:23:34,558:INFO:         deprecation: 2.1.0
2024-09-20 18:23:34,558:INFO:              xxhash: 3.5.0
2024-09-20 18:23:34,558:INFO:           wurlitzer: 3.1.1
2024-09-20 18:23:34,558:INFO:PyCaret optional dependencies:
2024-09-20 18:23:34,558:INFO:                shap: 0.46.0
2024-09-20 18:23:34,558:INFO:           interpret: Not installed
2024-09-20 18:23:34,558:INFO:                umap: Not installed
2024-09-20 18:23:34,558:INFO:     ydata_profiling: Not installed
2024-09-20 18:23:34,558:INFO:  explainerdashboard: Not installed
2024-09-20 18:23:34,559:INFO:             autoviz: Not installed
2024-09-20 18:23:34,559:INFO:           fairlearn: Not installed
2024-09-20 18:23:34,559:INFO:          deepchecks: Not installed
2024-09-20 18:23:34,559:INFO:             xgboost: 2.1.1
2024-09-20 18:23:34,559:INFO:            catboost: Not installed
2024-09-20 18:23:34,559:INFO:              kmodes: Not installed
2024-09-20 18:23:34,559:INFO:             mlxtend: Not installed
2024-09-20 18:23:34,559:INFO:       statsforecast: Not installed
2024-09-20 18:23:34,559:INFO:        tune_sklearn: Not installed
2024-09-20 18:23:34,559:INFO:                 ray: Not installed
2024-09-20 18:23:34,559:INFO:            hyperopt: Not installed
2024-09-20 18:23:34,559:INFO:              optuna: 4.0.0
2024-09-20 18:23:34,559:INFO:               skopt: Not installed
2024-09-20 18:23:34,559:INFO:              mlflow: Not installed
2024-09-20 18:23:34,559:INFO:              gradio: Not installed
2024-09-20 18:23:34,559:INFO:             fastapi: Not installed
2024-09-20 18:23:34,559:INFO:             uvicorn: Not installed
2024-09-20 18:23:34,559:INFO:              m2cgen: Not installed
2024-09-20 18:23:34,559:INFO:           evidently: Not installed
2024-09-20 18:23:34,559:INFO:               fugue: Not installed
2024-09-20 18:23:34,559:INFO:           streamlit: 1.38.0
2024-09-20 18:23:34,559:INFO:             prophet: Not installed
2024-09-20 18:23:34,559:INFO:None
2024-09-20 18:23:34,559:INFO:Set up data.
2024-09-20 18:23:34,656:INFO:Set up folding strategy.
2024-09-20 18:23:34,657:INFO:Set up train/test split.
2024-09-20 18:23:34,725:INFO:Set up index.
2024-09-20 18:23:34,728:INFO:Assigning column types.
2024-09-20 18:23:34,743:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-20 18:23:34,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,779:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,812:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,813:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-20 18:23:34,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,842:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,862:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:23:34,873:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,874:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-20 18:23:34,904:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,934:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:34,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:34,939:INFO:Preparing preprocessing pipeline...
2024-09-20 18:23:34,943:INFO:Set up label encoding.
2024-09-20 18:23:34,943:INFO:Set up simple imputation.
2024-09-20 18:23:34,945:INFO:Set up column name cleaning.
2024-09-20 18:23:35,624:INFO:Finished creating preprocessing pipeline.
2024-09-20 18:23:35,626:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-20 18:23:35,626:INFO:Creating final display dataframe.
2024-09-20 18:23:36,087:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               987f
2024-09-20 18:23:36,123:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:36,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:36,155:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:23:36,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:23:36,157:INFO:setup() successfully completed in 1.63s...............
2024-09-20 18:23:36,177:INFO:Initializing compare_models()
2024-09-20 18:23:36,177:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-20 18:23:36,177:INFO:Checking exceptions
2024-09-20 18:23:36,200:INFO:Preparing display monitor
2024-09-20 18:23:36,213:INFO:Initializing Logistic Regression
2024-09-20 18:23:36,213:INFO:Total runtime is 3.353754679361979e-06 minutes
2024-09-20 18:23:36,215:INFO:SubProcess create_model() called ==================================
2024-09-20 18:23:36,215:INFO:Initializing create_model()
2024-09-20 18:23:36,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:23:36,216:INFO:Checking exceptions
2024-09-20 18:23:36,216:INFO:Importing libraries
2024-09-20 18:23:36,216:INFO:Copying training dataset
2024-09-20 18:23:36,300:INFO:Defining folds
2024-09-20 18:23:36,300:INFO:Declaring metric variables
2024-09-20 18:23:36,302:INFO:Importing untrained model
2024-09-20 18:23:36,303:INFO:Logistic Regression Imported successfully
2024-09-20 18:23:36,306:INFO:Starting cross validation
2024-09-20 18:23:36,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:23:49,621:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,622:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,666:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,681:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:49,721:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:49,731:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:49,829:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,915:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,948:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:49,956:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:49,974:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:50,081:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:50,092:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:50,103:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:50,322:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:50,368:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:55,165:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:55,173:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:23:55,194:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:55,198:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:23:55,218:INFO:Calculating mean and std
2024-09-20 18:23:55,220:INFO:Creating metrics dataframe
2024-09-20 18:23:55,223:INFO:Uploading results into container
2024-09-20 18:23:55,224:INFO:Uploading model into container now
2024-09-20 18:23:55,224:INFO:_master_model_container: 1
2024-09-20 18:23:55,224:INFO:_display_container: 2
2024-09-20 18:23:55,225:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-20 18:23:55,225:INFO:create_model() successfully completed......................................
2024-09-20 18:23:55,341:INFO:SubProcess create_model() end ==================================
2024-09-20 18:23:55,341:INFO:Creating metrics dataframe
2024-09-20 18:23:55,346:INFO:Initializing K Neighbors Classifier
2024-09-20 18:23:55,346:INFO:Total runtime is 0.3188851992289225 minutes
2024-09-20 18:23:55,348:INFO:SubProcess create_model() called ==================================
2024-09-20 18:23:55,348:INFO:Initializing create_model()
2024-09-20 18:23:55,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:23:55,348:INFO:Checking exceptions
2024-09-20 18:23:55,349:INFO:Importing libraries
2024-09-20 18:23:55,349:INFO:Copying training dataset
2024-09-20 18:23:55,427:INFO:Defining folds
2024-09-20 18:23:55,428:INFO:Declaring metric variables
2024-09-20 18:23:55,429:INFO:Importing untrained model
2024-09-20 18:23:55,432:INFO:K Neighbors Classifier Imported successfully
2024-09-20 18:23:55,434:INFO:Starting cross validation
2024-09-20 18:23:55,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:03,094:INFO:Calculating mean and std
2024-09-20 18:24:03,096:INFO:Creating metrics dataframe
2024-09-20 18:24:03,099:INFO:Uploading results into container
2024-09-20 18:24:03,099:INFO:Uploading model into container now
2024-09-20 18:24:03,101:INFO:_master_model_container: 2
2024-09-20 18:24:03,101:INFO:_display_container: 2
2024-09-20 18:24:03,129:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-20 18:24:03,129:INFO:create_model() successfully completed......................................
2024-09-20 18:24:03,218:INFO:SubProcess create_model() end ==================================
2024-09-20 18:24:03,218:INFO:Creating metrics dataframe
2024-09-20 18:24:03,221:INFO:Initializing Naive Bayes
2024-09-20 18:24:03,221:INFO:Total runtime is 0.4501311341921488 minutes
2024-09-20 18:24:03,222:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:03,222:INFO:Initializing create_model()
2024-09-20 18:24:03,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:03,222:INFO:Checking exceptions
2024-09-20 18:24:03,222:INFO:Importing libraries
2024-09-20 18:24:03,223:INFO:Copying training dataset
2024-09-20 18:24:03,277:INFO:Defining folds
2024-09-20 18:24:03,277:INFO:Declaring metric variables
2024-09-20 18:24:03,280:INFO:Importing untrained model
2024-09-20 18:24:03,282:INFO:Naive Bayes Imported successfully
2024-09-20 18:24:03,285:INFO:Starting cross validation
2024-09-20 18:24:03,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:03,947:INFO:Calculating mean and std
2024-09-20 18:24:03,947:INFO:Creating metrics dataframe
2024-09-20 18:24:03,949:INFO:Uploading results into container
2024-09-20 18:24:03,949:INFO:Uploading model into container now
2024-09-20 18:24:03,949:INFO:_master_model_container: 3
2024-09-20 18:24:03,949:INFO:_display_container: 2
2024-09-20 18:24:03,950:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-20 18:24:03,950:INFO:create_model() successfully completed......................................
2024-09-20 18:24:04,015:INFO:SubProcess create_model() end ==================================
2024-09-20 18:24:04,015:INFO:Creating metrics dataframe
2024-09-20 18:24:04,018:INFO:Initializing Decision Tree Classifier
2024-09-20 18:24:04,019:INFO:Total runtime is 0.46342481772104893 minutes
2024-09-20 18:24:04,020:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:04,020:INFO:Initializing create_model()
2024-09-20 18:24:04,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:04,020:INFO:Checking exceptions
2024-09-20 18:24:04,020:INFO:Importing libraries
2024-09-20 18:24:04,020:INFO:Copying training dataset
2024-09-20 18:24:04,069:INFO:Defining folds
2024-09-20 18:24:04,069:INFO:Declaring metric variables
2024-09-20 18:24:04,070:INFO:Importing untrained model
2024-09-20 18:24:04,072:INFO:Decision Tree Classifier Imported successfully
2024-09-20 18:24:04,075:INFO:Starting cross validation
2024-09-20 18:24:04,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:06,185:INFO:Calculating mean and std
2024-09-20 18:24:06,187:INFO:Creating metrics dataframe
2024-09-20 18:24:06,190:INFO:Uploading results into container
2024-09-20 18:24:06,190:INFO:Uploading model into container now
2024-09-20 18:24:06,191:INFO:_master_model_container: 4
2024-09-20 18:24:06,191:INFO:_display_container: 2
2024-09-20 18:24:06,191:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-20 18:24:06,191:INFO:create_model() successfully completed......................................
2024-09-20 18:24:06,298:INFO:SubProcess create_model() end ==================================
2024-09-20 18:24:06,298:INFO:Creating metrics dataframe
2024-09-20 18:24:06,302:INFO:Initializing SVM - Linear Kernel
2024-09-20 18:24:06,302:INFO:Total runtime is 0.5014850338300069 minutes
2024-09-20 18:24:06,304:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:06,304:INFO:Initializing create_model()
2024-09-20 18:24:06,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:06,304:INFO:Checking exceptions
2024-09-20 18:24:06,305:INFO:Importing libraries
2024-09-20 18:24:06,305:INFO:Copying training dataset
2024-09-20 18:24:06,347:INFO:Defining folds
2024-09-20 18:24:06,348:INFO:Declaring metric variables
2024-09-20 18:24:06,350:INFO:Importing untrained model
2024-09-20 18:24:06,352:INFO:SVM - Linear Kernel Imported successfully
2024-09-20 18:24:06,354:INFO:Starting cross validation
2024-09-20 18:24:06,355:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:15,228:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:15,234:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:15,759:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:15,766:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:16,271:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:16,280:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:16,406:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:16,412:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:16,507:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:16,514:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:16,972:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:16,980:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:17,200:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:17,374:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:17,379:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:18,666:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:18,670:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:24:18,708:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:18,722:INFO:Calculating mean and std
2024-09-20 18:24:18,724:INFO:Creating metrics dataframe
2024-09-20 18:24:18,726:INFO:Uploading results into container
2024-09-20 18:24:18,727:INFO:Uploading model into container now
2024-09-20 18:24:18,727:INFO:_master_model_container: 5
2024-09-20 18:24:18,727:INFO:_display_container: 2
2024-09-20 18:24:18,728:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-20 18:24:18,728:INFO:create_model() successfully completed......................................
2024-09-20 18:24:18,821:INFO:SubProcess create_model() end ==================================
2024-09-20 18:24:18,821:INFO:Creating metrics dataframe
2024-09-20 18:24:18,826:INFO:Initializing Ridge Classifier
2024-09-20 18:24:18,826:INFO:Total runtime is 0.7102148334185282 minutes
2024-09-20 18:24:18,828:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:18,829:INFO:Initializing create_model()
2024-09-20 18:24:18,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:18,829:INFO:Checking exceptions
2024-09-20 18:24:18,829:INFO:Importing libraries
2024-09-20 18:24:18,829:INFO:Copying training dataset
2024-09-20 18:24:18,894:INFO:Defining folds
2024-09-20 18:24:18,894:INFO:Declaring metric variables
2024-09-20 18:24:18,895:INFO:Importing untrained model
2024-09-20 18:24:18,898:INFO:Ridge Classifier Imported successfully
2024-09-20 18:24:18,900:INFO:Starting cross validation
2024-09-20 18:24:18,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:19,092:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,161:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,165:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,198:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,224:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,269:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,271:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,329:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,357:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,404:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,407:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,439:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,451:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,480:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,480:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,485:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,501:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:24:19,507:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,507:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,530:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:24:19,548:INFO:Calculating mean and std
2024-09-20 18:24:19,550:INFO:Creating metrics dataframe
2024-09-20 18:24:19,552:INFO:Uploading results into container
2024-09-20 18:24:19,552:INFO:Uploading model into container now
2024-09-20 18:24:19,553:INFO:_master_model_container: 6
2024-09-20 18:24:19,553:INFO:_display_container: 2
2024-09-20 18:24:19,553:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-20 18:24:19,553:INFO:create_model() successfully completed......................................
2024-09-20 18:24:19,628:INFO:SubProcess create_model() end ==================================
2024-09-20 18:24:19,628:INFO:Creating metrics dataframe
2024-09-20 18:24:19,633:INFO:Initializing Random Forest Classifier
2024-09-20 18:24:19,633:INFO:Total runtime is 0.7236613353093465 minutes
2024-09-20 18:24:19,634:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:19,634:INFO:Initializing create_model()
2024-09-20 18:24:19,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x30ea860e0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x13f100f40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:19,634:INFO:Checking exceptions
2024-09-20 18:24:19,634:INFO:Importing libraries
2024-09-20 18:24:19,634:INFO:Copying training dataset
2024-09-20 18:24:19,676:INFO:Defining folds
2024-09-20 18:24:19,676:INFO:Declaring metric variables
2024-09-20 18:24:19,678:INFO:Importing untrained model
2024-09-20 18:24:19,680:INFO:Random Forest Classifier Imported successfully
2024-09-20 18:24:19,682:INFO:Starting cross validation
2024-09-20 18:24:19,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:24:50,592:INFO:PyCaret ClassificationExperiment
2024-09-20 18:24:50,592:INFO:Logging name: clf-default-name
2024-09-20 18:24:50,592:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-20 18:24:50,592:INFO:version 3.3.2
2024-09-20 18:24:50,592:INFO:Initializing setup()
2024-09-20 18:24:50,592:INFO:self.USI: 80e2
2024-09-20 18:24:50,592:INFO:self._variable_keys: {'memory', 'log_plots_param', '_ml_usecase', 'pipeline', 'target_param', 'gpu_param', 'exp_id', 'y', 'fold_generator', 'fold_shuffle_param', 'exp_name_log', 'is_multiclass', 'fix_imbalance', 'html_param', 'X_test', 'X', 'fold_groups_param', 'data', 'seed', 'idx', 'X_train', 'y_test', 'USI', '_available_plots', 'gpu_n_jobs_param', 'y_train', 'logging_param', 'n_jobs_param'}
2024-09-20 18:24:50,592:INFO:Checking environment
2024-09-20 18:24:50,592:INFO:python_version: 3.10.14
2024-09-20 18:24:50,592:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-20 18:24:50,592:INFO:machine: arm64
2024-09-20 18:24:50,592:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-20 18:24:50,592:INFO:Memory: svmem(total=8589934592, available=2193768448, percent=74.5, used=3824812032, free=48283648, active=2160705536, inactive=2137833472, wired=1664106496)
2024-09-20 18:24:50,592:INFO:Physical Core: 8
2024-09-20 18:24:50,592:INFO:Logical Core: 8
2024-09-20 18:24:50,592:INFO:Checking libraries
2024-09-20 18:24:50,592:INFO:System:
2024-09-20 18:24:50,592:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-20 18:24:50,592:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-20 18:24:50,592:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-20 18:24:50,592:INFO:PyCaret required dependencies:
2024-09-20 18:24:50,593:INFO:                 pip: 24.2
2024-09-20 18:24:50,593:INFO:          setuptools: 72.1.0
2024-09-20 18:24:50,593:INFO:             pycaret: 3.3.2
2024-09-20 18:24:50,593:INFO:             IPython: 8.18.1
2024-09-20 18:24:50,593:INFO:          ipywidgets: 8.1.5
2024-09-20 18:24:50,593:INFO:                tqdm: 4.66.5
2024-09-20 18:24:50,593:INFO:               numpy: 1.26.4
2024-09-20 18:24:50,593:INFO:              pandas: 2.1.4
2024-09-20 18:24:50,593:INFO:              jinja2: 3.1.4
2024-09-20 18:24:50,593:INFO:               scipy: 1.11.4
2024-09-20 18:24:50,593:INFO:              joblib: 1.3.2
2024-09-20 18:24:50,593:INFO:             sklearn: 1.4.2
2024-09-20 18:24:50,593:INFO:                pyod: 2.0.2
2024-09-20 18:24:50,593:INFO:            imblearn: 0.12.3
2024-09-20 18:24:50,593:INFO:   category_encoders: 2.6.3
2024-09-20 18:24:50,593:INFO:            lightgbm: 4.5.0
2024-09-20 18:24:50,593:INFO:               numba: 0.60.0
2024-09-20 18:24:50,593:INFO:            requests: 2.32.3
2024-09-20 18:24:50,593:INFO:          matplotlib: 3.7.5
2024-09-20 18:24:50,593:INFO:          scikitplot: 0.3.7
2024-09-20 18:24:50,593:INFO:         yellowbrick: 1.5
2024-09-20 18:24:50,593:INFO:              plotly: 5.24.0
2024-09-20 18:24:50,593:INFO:    plotly-resampler: Not installed
2024-09-20 18:24:50,593:INFO:             kaleido: 0.2.1
2024-09-20 18:24:50,593:INFO:           schemdraw: 0.15
2024-09-20 18:24:50,593:INFO:         statsmodels: 0.14.3
2024-09-20 18:24:50,593:INFO:              sktime: 0.26.0
2024-09-20 18:24:50,593:INFO:               tbats: 1.1.3
2024-09-20 18:24:50,593:INFO:            pmdarima: 2.0.4
2024-09-20 18:24:50,593:INFO:              psutil: 5.9.0
2024-09-20 18:24:50,593:INFO:          markupsafe: 2.1.3
2024-09-20 18:24:50,593:INFO:             pickle5: Not installed
2024-09-20 18:24:50,593:INFO:         cloudpickle: 3.0.0
2024-09-20 18:24:50,593:INFO:         deprecation: 2.1.0
2024-09-20 18:24:50,593:INFO:              xxhash: 3.5.0
2024-09-20 18:24:50,593:INFO:           wurlitzer: 3.1.1
2024-09-20 18:24:50,593:INFO:PyCaret optional dependencies:
2024-09-20 18:24:50,593:INFO:                shap: 0.46.0
2024-09-20 18:24:50,593:INFO:           interpret: Not installed
2024-09-20 18:24:50,593:INFO:                umap: Not installed
2024-09-20 18:24:50,593:INFO:     ydata_profiling: Not installed
2024-09-20 18:24:50,593:INFO:  explainerdashboard: Not installed
2024-09-20 18:24:50,593:INFO:             autoviz: Not installed
2024-09-20 18:24:50,593:INFO:           fairlearn: Not installed
2024-09-20 18:24:50,593:INFO:          deepchecks: Not installed
2024-09-20 18:24:50,593:INFO:             xgboost: 2.1.1
2024-09-20 18:24:50,593:INFO:            catboost: Not installed
2024-09-20 18:24:50,593:INFO:              kmodes: Not installed
2024-09-20 18:24:50,593:INFO:             mlxtend: Not installed
2024-09-20 18:24:50,593:INFO:       statsforecast: Not installed
2024-09-20 18:24:50,593:INFO:        tune_sklearn: Not installed
2024-09-20 18:24:50,593:INFO:                 ray: Not installed
2024-09-20 18:24:50,593:INFO:            hyperopt: Not installed
2024-09-20 18:24:50,593:INFO:              optuna: 4.0.0
2024-09-20 18:24:50,593:INFO:               skopt: Not installed
2024-09-20 18:24:50,593:INFO:              mlflow: Not installed
2024-09-20 18:24:50,593:INFO:              gradio: Not installed
2024-09-20 18:24:50,593:INFO:             fastapi: Not installed
2024-09-20 18:24:50,593:INFO:             uvicorn: Not installed
2024-09-20 18:24:50,594:INFO:              m2cgen: Not installed
2024-09-20 18:24:50,594:INFO:           evidently: Not installed
2024-09-20 18:24:50,594:INFO:               fugue: Not installed
2024-09-20 18:24:50,594:INFO:           streamlit: 1.38.0
2024-09-20 18:24:50,594:INFO:             prophet: Not installed
2024-09-20 18:24:50,594:INFO:None
2024-09-20 18:24:50,594:INFO:Set up data.
2024-09-20 18:24:50,616:INFO:Set up folding strategy.
2024-09-20 18:24:50,616:INFO:Set up train/test split.
2024-09-20 18:24:50,650:INFO:Set up index.
2024-09-20 18:24:50,652:INFO:Assigning column types.
2024-09-20 18:24:50,666:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-20 18:24:50,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,696:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,716:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,727:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,728:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-20 18:24:50,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,759:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-20 18:24:50,790:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,791:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-20 18:24:50,821:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,852:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:50,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:50,853:INFO:Preparing preprocessing pipeline...
2024-09-20 18:24:50,856:INFO:Set up label encoding.
2024-09-20 18:24:50,856:INFO:Set up simple imputation.
2024-09-20 18:24:50,858:INFO:Set up column name cleaning.
2024-09-20 18:24:51,328:INFO:Finished creating preprocessing pipeline.
2024-09-20 18:24:51,330:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-20 18:24:51,330:INFO:Creating final display dataframe.
2024-09-20 18:24:51,866:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               80e2
2024-09-20 18:24:51,906:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:51,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:51,946:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-20 18:24:51,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-20 18:24:51,948:INFO:setup() successfully completed in 1.37s...............
2024-09-20 18:24:51,954:INFO:Initializing compare_models()
2024-09-20 18:24:51,954:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-20 18:24:51,955:INFO:Checking exceptions
2024-09-20 18:24:51,979:INFO:Preparing display monitor
2024-09-20 18:24:51,990:INFO:Initializing Logistic Regression
2024-09-20 18:24:51,990:INFO:Total runtime is 2.4517377217610677e-06 minutes
2024-09-20 18:24:51,992:INFO:SubProcess create_model() called ==================================
2024-09-20 18:24:51,993:INFO:Initializing create_model()
2024-09-20 18:24:51,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:24:51,993:INFO:Checking exceptions
2024-09-20 18:24:51,993:INFO:Importing libraries
2024-09-20 18:24:51,993:INFO:Copying training dataset
2024-09-20 18:24:52,042:INFO:Defining folds
2024-09-20 18:24:52,042:INFO:Declaring metric variables
2024-09-20 18:24:52,043:INFO:Importing untrained model
2024-09-20 18:24:52,045:INFO:Logistic Regression Imported successfully
2024-09-20 18:24:52,048:INFO:Starting cross validation
2024-09-20 18:24:52,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:05,193:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,275:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,304:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,339:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,374:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,400:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,453:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,460:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,460:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,475:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,485:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,486:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,541:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,597:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:05,734:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:05,791:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:10,814:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:10,839:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:10,965:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-20 18:25:10,991:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:11,008:INFO:Calculating mean and std
2024-09-20 18:25:11,010:INFO:Creating metrics dataframe
2024-09-20 18:25:11,013:INFO:Uploading results into container
2024-09-20 18:25:11,013:INFO:Uploading model into container now
2024-09-20 18:25:11,014:INFO:_master_model_container: 1
2024-09-20 18:25:11,014:INFO:_display_container: 2
2024-09-20 18:25:11,015:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-20 18:25:11,015:INFO:create_model() successfully completed......................................
2024-09-20 18:25:11,118:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:11,119:INFO:Creating metrics dataframe
2024-09-20 18:25:11,123:INFO:Initializing K Neighbors Classifier
2024-09-20 18:25:11,123:INFO:Total runtime is 0.3188881794611613 minutes
2024-09-20 18:25:11,126:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:11,127:INFO:Initializing create_model()
2024-09-20 18:25:11,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:11,127:INFO:Checking exceptions
2024-09-20 18:25:11,127:INFO:Importing libraries
2024-09-20 18:25:11,127:INFO:Copying training dataset
2024-09-20 18:25:11,171:INFO:Defining folds
2024-09-20 18:25:11,172:INFO:Declaring metric variables
2024-09-20 18:25:11,174:INFO:Importing untrained model
2024-09-20 18:25:11,176:INFO:K Neighbors Classifier Imported successfully
2024-09-20 18:25:11,181:INFO:Starting cross validation
2024-09-20 18:25:11,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:19,363:INFO:Calculating mean and std
2024-09-20 18:25:19,366:INFO:Creating metrics dataframe
2024-09-20 18:25:19,370:INFO:Uploading results into container
2024-09-20 18:25:19,371:INFO:Uploading model into container now
2024-09-20 18:25:19,371:INFO:_master_model_container: 2
2024-09-20 18:25:19,371:INFO:_display_container: 2
2024-09-20 18:25:19,371:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-20 18:25:19,372:INFO:create_model() successfully completed......................................
2024-09-20 18:25:19,510:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:19,511:INFO:Creating metrics dataframe
2024-09-20 18:25:19,514:INFO:Initializing Naive Bayes
2024-09-20 18:25:19,514:INFO:Total runtime is 0.4587326010068258 minutes
2024-09-20 18:25:19,516:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:19,516:INFO:Initializing create_model()
2024-09-20 18:25:19,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:19,516:INFO:Checking exceptions
2024-09-20 18:25:19,516:INFO:Importing libraries
2024-09-20 18:25:19,516:INFO:Copying training dataset
2024-09-20 18:25:19,563:INFO:Defining folds
2024-09-20 18:25:19,564:INFO:Declaring metric variables
2024-09-20 18:25:19,565:INFO:Importing untrained model
2024-09-20 18:25:19,568:INFO:Naive Bayes Imported successfully
2024-09-20 18:25:19,572:INFO:Starting cross validation
2024-09-20 18:25:19,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:20,385:INFO:Calculating mean and std
2024-09-20 18:25:20,385:INFO:Creating metrics dataframe
2024-09-20 18:25:20,386:INFO:Uploading results into container
2024-09-20 18:25:20,387:INFO:Uploading model into container now
2024-09-20 18:25:20,387:INFO:_master_model_container: 3
2024-09-20 18:25:20,387:INFO:_display_container: 2
2024-09-20 18:25:20,387:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-20 18:25:20,387:INFO:create_model() successfully completed......................................
2024-09-20 18:25:20,451:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:20,452:INFO:Creating metrics dataframe
2024-09-20 18:25:20,455:INFO:Initializing Decision Tree Classifier
2024-09-20 18:25:20,455:INFO:Total runtime is 0.4744204004605611 minutes
2024-09-20 18:25:20,457:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:20,457:INFO:Initializing create_model()
2024-09-20 18:25:20,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:20,457:INFO:Checking exceptions
2024-09-20 18:25:20,457:INFO:Importing libraries
2024-09-20 18:25:20,457:INFO:Copying training dataset
2024-09-20 18:25:20,496:INFO:Defining folds
2024-09-20 18:25:20,496:INFO:Declaring metric variables
2024-09-20 18:25:20,498:INFO:Importing untrained model
2024-09-20 18:25:20,500:INFO:Decision Tree Classifier Imported successfully
2024-09-20 18:25:20,503:INFO:Starting cross validation
2024-09-20 18:25:20,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:22,374:INFO:Calculating mean and std
2024-09-20 18:25:22,376:INFO:Creating metrics dataframe
2024-09-20 18:25:22,381:INFO:Uploading results into container
2024-09-20 18:25:22,383:INFO:Uploading model into container now
2024-09-20 18:25:22,383:INFO:_master_model_container: 4
2024-09-20 18:25:22,384:INFO:_display_container: 2
2024-09-20 18:25:22,385:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-20 18:25:22,385:INFO:create_model() successfully completed......................................
2024-09-20 18:25:22,517:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:22,517:INFO:Creating metrics dataframe
2024-09-20 18:25:22,521:INFO:Initializing SVM - Linear Kernel
2024-09-20 18:25:22,521:INFO:Total runtime is 0.5088434815406799 minutes
2024-09-20 18:25:22,522:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:22,522:INFO:Initializing create_model()
2024-09-20 18:25:22,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:22,523:INFO:Checking exceptions
2024-09-20 18:25:22,523:INFO:Importing libraries
2024-09-20 18:25:22,523:INFO:Copying training dataset
2024-09-20 18:25:22,567:INFO:Defining folds
2024-09-20 18:25:22,567:INFO:Declaring metric variables
2024-09-20 18:25:22,569:INFO:Importing untrained model
2024-09-20 18:25:22,571:INFO:SVM - Linear Kernel Imported successfully
2024-09-20 18:25:22,574:INFO:Starting cross validation
2024-09-20 18:25:22,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:31,024:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:31,030:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:31,954:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:31,960:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:32,041:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:32,047:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:32,228:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:32,236:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:32,243:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:32,252:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:32,837:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:32,843:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:33,022:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:33,029:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:33,114:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:34,522:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:34,527:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-20 18:25:34,765:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:34,780:INFO:Calculating mean and std
2024-09-20 18:25:34,782:INFO:Creating metrics dataframe
2024-09-20 18:25:34,785:INFO:Uploading results into container
2024-09-20 18:25:34,785:INFO:Uploading model into container now
2024-09-20 18:25:34,786:INFO:_master_model_container: 5
2024-09-20 18:25:34,786:INFO:_display_container: 2
2024-09-20 18:25:34,787:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-20 18:25:34,787:INFO:create_model() successfully completed......................................
2024-09-20 18:25:34,917:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:34,917:INFO:Creating metrics dataframe
2024-09-20 18:25:34,921:INFO:Initializing Ridge Classifier
2024-09-20 18:25:34,921:INFO:Total runtime is 0.7155194163322449 minutes
2024-09-20 18:25:34,924:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:34,924:INFO:Initializing create_model()
2024-09-20 18:25:34,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:34,924:INFO:Checking exceptions
2024-09-20 18:25:34,924:INFO:Importing libraries
2024-09-20 18:25:34,924:INFO:Copying training dataset
2024-09-20 18:25:34,970:INFO:Defining folds
2024-09-20 18:25:34,970:INFO:Declaring metric variables
2024-09-20 18:25:34,972:INFO:Importing untrained model
2024-09-20 18:25:34,975:INFO:Ridge Classifier Imported successfully
2024-09-20 18:25:34,980:INFO:Starting cross validation
2024-09-20 18:25:34,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:35,294:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,333:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,351:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,403:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,421:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,452:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,510:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,570:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,591:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,608:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,629:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,645:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,717:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,733:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,746:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,763:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,823:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,841:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-20 18:25:35,859:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,867:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:35,885:INFO:Calculating mean and std
2024-09-20 18:25:35,887:INFO:Creating metrics dataframe
2024-09-20 18:25:35,890:INFO:Uploading results into container
2024-09-20 18:25:35,890:INFO:Uploading model into container now
2024-09-20 18:25:35,891:INFO:_master_model_container: 6
2024-09-20 18:25:35,891:INFO:_display_container: 2
2024-09-20 18:25:35,892:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-20 18:25:35,892:INFO:create_model() successfully completed......................................
2024-09-20 18:25:36,052:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:36,052:INFO:Creating metrics dataframe
2024-09-20 18:25:36,057:INFO:Initializing Random Forest Classifier
2024-09-20 18:25:36,057:INFO:Total runtime is 0.7344555854797363 minutes
2024-09-20 18:25:36,061:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:36,061:INFO:Initializing create_model()
2024-09-20 18:25:36,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:36,061:INFO:Checking exceptions
2024-09-20 18:25:36,061:INFO:Importing libraries
2024-09-20 18:25:36,061:INFO:Copying training dataset
2024-09-20 18:25:36,121:INFO:Defining folds
2024-09-20 18:25:36,121:INFO:Declaring metric variables
2024-09-20 18:25:36,123:INFO:Importing untrained model
2024-09-20 18:25:36,126:INFO:Random Forest Classifier Imported successfully
2024-09-20 18:25:36,129:INFO:Starting cross validation
2024-09-20 18:25:36,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:58,913:INFO:Calculating mean and std
2024-09-20 18:25:58,916:INFO:Creating metrics dataframe
2024-09-20 18:25:58,923:INFO:Uploading results into container
2024-09-20 18:25:58,924:INFO:Uploading model into container now
2024-09-20 18:25:58,925:INFO:_master_model_container: 7
2024-09-20 18:25:58,925:INFO:_display_container: 2
2024-09-20 18:25:58,926:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-20 18:25:58,927:INFO:create_model() successfully completed......................................
2024-09-20 18:25:59,051:INFO:SubProcess create_model() end ==================================
2024-09-20 18:25:59,051:INFO:Creating metrics dataframe
2024-09-20 18:25:59,055:INFO:Initializing Quadratic Discriminant Analysis
2024-09-20 18:25:59,056:INFO:Total runtime is 1.117757014433543 minutes
2024-09-20 18:25:59,057:INFO:SubProcess create_model() called ==================================
2024-09-20 18:25:59,058:INFO:Initializing create_model()
2024-09-20 18:25:59,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:25:59,058:INFO:Checking exceptions
2024-09-20 18:25:59,058:INFO:Importing libraries
2024-09-20 18:25:59,058:INFO:Copying training dataset
2024-09-20 18:25:59,117:INFO:Defining folds
2024-09-20 18:25:59,118:INFO:Declaring metric variables
2024-09-20 18:25:59,120:INFO:Importing untrained model
2024-09-20 18:25:59,122:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-20 18:25:59,125:INFO:Starting cross validation
2024-09-20 18:25:59,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:25:59,457:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,613:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,678:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,771:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,826:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,928:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:25:59,952:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:00,045:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:00,070:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:00,089:INFO:Calculating mean and std
2024-09-20 18:26:00,091:INFO:Creating metrics dataframe
2024-09-20 18:26:00,092:INFO:Uploading results into container
2024-09-20 18:26:00,093:INFO:Uploading model into container now
2024-09-20 18:26:00,094:INFO:_master_model_container: 8
2024-09-20 18:26:00,094:INFO:_display_container: 2
2024-09-20 18:26:00,095:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-20 18:26:00,095:INFO:create_model() successfully completed......................................
2024-09-20 18:26:00,199:INFO:SubProcess create_model() end ==================================
2024-09-20 18:26:00,199:INFO:Creating metrics dataframe
2024-09-20 18:26:00,206:INFO:Initializing Ada Boost Classifier
2024-09-20 18:26:00,207:INFO:Total runtime is 1.1369412660598754 minutes
2024-09-20 18:26:00,211:INFO:SubProcess create_model() called ==================================
2024-09-20 18:26:00,211:INFO:Initializing create_model()
2024-09-20 18:26:00,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:26:00,212:INFO:Checking exceptions
2024-09-20 18:26:00,212:INFO:Importing libraries
2024-09-20 18:26:00,212:INFO:Copying training dataset
2024-09-20 18:26:00,271:INFO:Defining folds
2024-09-20 18:26:00,271:INFO:Declaring metric variables
2024-09-20 18:26:00,273:INFO:Importing untrained model
2024-09-20 18:26:00,276:INFO:Ada Boost Classifier Imported successfully
2024-09-20 18:26:00,279:INFO:Starting cross validation
2024-09-20 18:26:00,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-20 18:26:00,509:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:00,540:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:00,599:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:00,649:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:00,763:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:00,819:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:01,005:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:01,030:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:04,381:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,466:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,539:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,628:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,634:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:04,689:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-20 18:26:04,716:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,729:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,814:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:04,816:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:06,756:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:06,775:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-20 18:26:06,788:INFO:Calculating mean and std
2024-09-20 18:26:06,799:INFO:Creating metrics dataframe
2024-09-20 18:26:06,805:INFO:Uploading results into container
2024-09-20 18:26:06,806:INFO:Uploading model into container now
2024-09-20 18:26:06,807:INFO:_master_model_container: 9
2024-09-20 18:26:06,807:INFO:_display_container: 2
2024-09-20 18:26:06,807:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-20 18:26:06,808:INFO:create_model() successfully completed......................................
2024-09-20 18:26:06,942:INFO:SubProcess create_model() end ==================================
2024-09-20 18:26:06,942:INFO:Creating metrics dataframe
2024-09-20 18:26:06,946:INFO:Initializing Gradient Boosting Classifier
2024-09-20 18:26:06,946:INFO:Total runtime is 1.2492680509885152 minutes
2024-09-20 18:26:06,948:INFO:SubProcess create_model() called ==================================
2024-09-20 18:26:06,948:INFO:Initializing create_model()
2024-09-20 18:26:06,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x35ba78d60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x308027610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-20 18:26:06,948:INFO:Checking exceptions
2024-09-20 18:26:06,948:INFO:Importing libraries
2024-09-20 18:26:06,948:INFO:Copying training dataset
2024-09-20 18:26:06,992:INFO:Defining folds
2024-09-20 18:26:06,993:INFO:Declaring metric variables
2024-09-20 18:26:06,994:INFO:Importing untrained model
2024-09-20 18:26:06,997:INFO:Gradient Boosting Classifier Imported successfully
2024-09-20 18:26:07,000:INFO:Starting cross validation
2024-09-20 18:26:07,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
