2024-09-25 10:46:09,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-25 10:46:09,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-25 10:46:09,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-25 10:46:09,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-25 10:46:10,270:INFO:PyCaret ClassificationExperiment
2024-09-25 10:46:10,270:INFO:Logging name: clf-default-name
2024-09-25 10:46:10,270:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 10:46:10,270:INFO:version 3.3.2
2024-09-25 10:46:10,270:INFO:Initializing setup()
2024-09-25 10:46:10,270:INFO:self.USI: 37ab
2024-09-25 10:46:10,270:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 10:46:10,270:INFO:Checking environment
2024-09-25 10:46:10,271:INFO:python_version: 3.10.14
2024-09-25 10:46:10,271:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 10:46:10,271:INFO:machine: arm64
2024-09-25 10:46:10,271:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 10:46:10,271:INFO:Memory: svmem(total=8589934592, available=1524154368, percent=82.3, used=2946629632, free=48087040, active=1488306176, inactive=1422917632, wired=1458323456)
2024-09-25 10:46:10,271:INFO:Physical Core: 8
2024-09-25 10:46:10,271:INFO:Logical Core: 8
2024-09-25 10:46:10,271:INFO:Checking libraries
2024-09-25 10:46:10,271:INFO:System:
2024-09-25 10:46:10,271:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 10:46:10,272:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 10:46:10,272:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 10:46:10,272:INFO:PyCaret required dependencies:
2024-09-25 10:46:10,340:INFO:                 pip: 24.2
2024-09-25 10:46:10,341:INFO:          setuptools: 72.1.0
2024-09-25 10:46:10,341:INFO:             pycaret: 3.3.2
2024-09-25 10:46:10,341:INFO:             IPython: 8.18.1
2024-09-25 10:46:10,341:INFO:          ipywidgets: 8.1.5
2024-09-25 10:46:10,341:INFO:                tqdm: 4.66.5
2024-09-25 10:46:10,341:INFO:               numpy: 1.26.4
2024-09-25 10:46:10,341:INFO:              pandas: 2.1.4
2024-09-25 10:46:10,341:INFO:              jinja2: 3.1.4
2024-09-25 10:46:10,341:INFO:               scipy: 1.11.4
2024-09-25 10:46:10,341:INFO:              joblib: 1.3.2
2024-09-25 10:46:10,341:INFO:             sklearn: 1.4.2
2024-09-25 10:46:10,341:INFO:                pyod: 2.0.2
2024-09-25 10:46:10,341:INFO:            imblearn: 0.12.3
2024-09-25 10:46:10,341:INFO:   category_encoders: 2.6.3
2024-09-25 10:46:10,341:INFO:            lightgbm: 4.5.0
2024-09-25 10:46:10,341:INFO:               numba: 0.60.0
2024-09-25 10:46:10,341:INFO:            requests: 2.32.3
2024-09-25 10:46:10,341:INFO:          matplotlib: 3.7.5
2024-09-25 10:46:10,341:INFO:          scikitplot: 0.3.7
2024-09-25 10:46:10,341:INFO:         yellowbrick: 1.5
2024-09-25 10:46:10,341:INFO:              plotly: 5.24.0
2024-09-25 10:46:10,341:INFO:    plotly-resampler: Not installed
2024-09-25 10:46:10,342:INFO:             kaleido: 0.2.1
2024-09-25 10:46:10,342:INFO:           schemdraw: 0.15
2024-09-25 10:46:10,342:INFO:         statsmodels: 0.14.3
2024-09-25 10:46:10,342:INFO:              sktime: 0.26.0
2024-09-25 10:46:10,342:INFO:               tbats: 1.1.3
2024-09-25 10:46:10,342:INFO:            pmdarima: 2.0.4
2024-09-25 10:46:10,342:INFO:              psutil: 5.9.0
2024-09-25 10:46:10,342:INFO:          markupsafe: 2.1.3
2024-09-25 10:46:10,342:INFO:             pickle5: Not installed
2024-09-25 10:46:10,342:INFO:         cloudpickle: 3.0.0
2024-09-25 10:46:10,342:INFO:         deprecation: 2.1.0
2024-09-25 10:46:10,342:INFO:              xxhash: 3.5.0
2024-09-25 10:46:10,342:INFO:           wurlitzer: 3.1.1
2024-09-25 10:46:10,342:INFO:PyCaret optional dependencies:
2024-09-25 10:46:10,435:INFO:                shap: 0.46.0
2024-09-25 10:46:10,436:INFO:           interpret: Not installed
2024-09-25 10:46:10,436:INFO:                umap: Not installed
2024-09-25 10:46:10,436:INFO:     ydata_profiling: Not installed
2024-09-25 10:46:10,436:INFO:  explainerdashboard: Not installed
2024-09-25 10:46:10,436:INFO:             autoviz: Not installed
2024-09-25 10:46:10,436:INFO:           fairlearn: Not installed
2024-09-25 10:46:10,436:INFO:          deepchecks: Not installed
2024-09-25 10:46:10,436:INFO:             xgboost: 2.1.1
2024-09-25 10:46:10,436:INFO:            catboost: Not installed
2024-09-25 10:46:10,436:INFO:              kmodes: Not installed
2024-09-25 10:46:10,436:INFO:             mlxtend: Not installed
2024-09-25 10:46:10,436:INFO:       statsforecast: Not installed
2024-09-25 10:46:10,436:INFO:        tune_sklearn: Not installed
2024-09-25 10:46:10,436:INFO:                 ray: Not installed
2024-09-25 10:46:10,436:INFO:            hyperopt: Not installed
2024-09-25 10:46:10,436:INFO:              optuna: 4.0.0
2024-09-25 10:46:10,436:INFO:               skopt: Not installed
2024-09-25 10:46:10,436:INFO:              mlflow: Not installed
2024-09-25 10:46:10,436:INFO:              gradio: Not installed
2024-09-25 10:46:10,436:INFO:             fastapi: Not installed
2024-09-25 10:46:10,436:INFO:             uvicorn: Not installed
2024-09-25 10:46:10,436:INFO:              m2cgen: Not installed
2024-09-25 10:46:10,436:INFO:           evidently: Not installed
2024-09-25 10:46:10,436:INFO:               fugue: Not installed
2024-09-25 10:46:10,436:INFO:           streamlit: 1.38.0
2024-09-25 10:46:10,436:INFO:             prophet: Not installed
2024-09-25 10:46:10,436:INFO:None
2024-09-25 10:46:10,436:INFO:Set up data.
2024-09-25 10:46:10,461:INFO:Set up folding strategy.
2024-09-25 10:46:10,461:INFO:Set up train/test split.
2024-09-25 10:46:10,498:INFO:Set up index.
2024-09-25 10:46:10,502:INFO:Assigning column types.
2024-09-25 10:46:10,518:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 10:46:10,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,538:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,553:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,574:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,587:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,588:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 10:46:10,607:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,618:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:46:10,648:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,650:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 10:46:10,679:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,710:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:10,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:10,713:INFO:Preparing preprocessing pipeline...
2024-09-25 10:46:10,716:INFO:Set up label encoding.
2024-09-25 10:46:10,716:INFO:Set up simple imputation.
2024-09-25 10:46:10,718:INFO:Set up column name cleaning.
2024-09-25 10:46:11,131:INFO:Finished creating preprocessing pipeline.
2024-09-25 10:46:11,134:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-25 10:46:11,134:INFO:Creating final display dataframe.
2024-09-25 10:46:11,897:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 18
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               37ab
2024-09-25 10:46:11,934:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:11,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:11,968:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:46:11,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:46:11,970:INFO:setup() successfully completed in 1.7s...............
2024-09-25 10:46:11,975:INFO:Initializing compare_models()
2024-09-25 10:46:11,975:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 10:46:11,975:INFO:Checking exceptions
2024-09-25 10:46:11,998:INFO:Preparing display monitor
2024-09-25 10:46:12,030:INFO:Initializing Logistic Regression
2024-09-25 10:46:12,030:INFO:Total runtime is 3.1828880310058593e-06 minutes
2024-09-25 10:46:12,031:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:12,032:INFO:Initializing create_model()
2024-09-25 10:46:12,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:12,032:INFO:Checking exceptions
2024-09-25 10:46:12,032:INFO:Importing libraries
2024-09-25 10:46:12,032:INFO:Copying training dataset
2024-09-25 10:46:12,082:INFO:Defining folds
2024-09-25 10:46:12,082:INFO:Declaring metric variables
2024-09-25 10:46:12,083:INFO:Importing untrained model
2024-09-25 10:46:12,085:INFO:Logistic Regression Imported successfully
2024-09-25 10:46:12,088:INFO:Starting cross validation
2024-09-25 10:46:12,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:24,731:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:24,765:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:24,941:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:24,960:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,000:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,004:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,081:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,081:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,124:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,129:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,161:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,197:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,353:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,377:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:25,388:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:25,423:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:30,063:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:30,074:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:30,082:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:46:30,113:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:30,130:INFO:Calculating mean and std
2024-09-25 10:46:30,133:INFO:Creating metrics dataframe
2024-09-25 10:46:30,137:INFO:Uploading results into container
2024-09-25 10:46:30,137:INFO:Uploading model into container now
2024-09-25 10:46:30,138:INFO:_master_model_container: 1
2024-09-25 10:46:30,138:INFO:_display_container: 2
2024-09-25 10:46:30,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 10:46:30,139:INFO:create_model() successfully completed......................................
2024-09-25 10:46:30,250:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:30,250:INFO:Creating metrics dataframe
2024-09-25 10:46:30,253:INFO:Initializing K Neighbors Classifier
2024-09-25 10:46:30,253:INFO:Total runtime is 0.30371554692586267 minutes
2024-09-25 10:46:30,254:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:30,254:INFO:Initializing create_model()
2024-09-25 10:46:30,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:30,254:INFO:Checking exceptions
2024-09-25 10:46:30,254:INFO:Importing libraries
2024-09-25 10:46:30,255:INFO:Copying training dataset
2024-09-25 10:46:30,297:INFO:Defining folds
2024-09-25 10:46:30,297:INFO:Declaring metric variables
2024-09-25 10:46:30,299:INFO:Importing untrained model
2024-09-25 10:46:30,300:INFO:K Neighbors Classifier Imported successfully
2024-09-25 10:46:30,303:INFO:Starting cross validation
2024-09-25 10:46:30,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:37,349:INFO:Calculating mean and std
2024-09-25 10:46:37,352:INFO:Creating metrics dataframe
2024-09-25 10:46:37,353:INFO:Uploading results into container
2024-09-25 10:46:37,354:INFO:Uploading model into container now
2024-09-25 10:46:37,354:INFO:_master_model_container: 2
2024-09-25 10:46:37,354:INFO:_display_container: 2
2024-09-25 10:46:37,355:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 10:46:37,355:INFO:create_model() successfully completed......................................
2024-09-25 10:46:37,444:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:37,444:INFO:Creating metrics dataframe
2024-09-25 10:46:37,447:INFO:Initializing Naive Bayes
2024-09-25 10:46:37,447:INFO:Total runtime is 0.42361834843953455 minutes
2024-09-25 10:46:37,448:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:37,448:INFO:Initializing create_model()
2024-09-25 10:46:37,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:37,448:INFO:Checking exceptions
2024-09-25 10:46:37,448:INFO:Importing libraries
2024-09-25 10:46:37,448:INFO:Copying training dataset
2024-09-25 10:46:37,490:INFO:Defining folds
2024-09-25 10:46:37,490:INFO:Declaring metric variables
2024-09-25 10:46:37,492:INFO:Importing untrained model
2024-09-25 10:46:37,493:INFO:Naive Bayes Imported successfully
2024-09-25 10:46:37,496:INFO:Starting cross validation
2024-09-25 10:46:37,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:37,897:INFO:Calculating mean and std
2024-09-25 10:46:37,897:INFO:Creating metrics dataframe
2024-09-25 10:46:37,898:INFO:Uploading results into container
2024-09-25 10:46:37,898:INFO:Uploading model into container now
2024-09-25 10:46:37,899:INFO:_master_model_container: 3
2024-09-25 10:46:37,899:INFO:_display_container: 2
2024-09-25 10:46:37,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 10:46:37,899:INFO:create_model() successfully completed......................................
2024-09-25 10:46:37,949:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:37,949:INFO:Creating metrics dataframe
2024-09-25 10:46:37,953:INFO:Initializing Decision Tree Classifier
2024-09-25 10:46:37,953:INFO:Total runtime is 0.4320510149002076 minutes
2024-09-25 10:46:37,954:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:37,954:INFO:Initializing create_model()
2024-09-25 10:46:37,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:37,955:INFO:Checking exceptions
2024-09-25 10:46:37,955:INFO:Importing libraries
2024-09-25 10:46:37,955:INFO:Copying training dataset
2024-09-25 10:46:37,993:INFO:Defining folds
2024-09-25 10:46:37,993:INFO:Declaring metric variables
2024-09-25 10:46:37,995:INFO:Importing untrained model
2024-09-25 10:46:37,996:INFO:Decision Tree Classifier Imported successfully
2024-09-25 10:46:37,999:INFO:Starting cross validation
2024-09-25 10:46:38,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:39,593:INFO:Calculating mean and std
2024-09-25 10:46:39,594:INFO:Creating metrics dataframe
2024-09-25 10:46:39,597:INFO:Uploading results into container
2024-09-25 10:46:39,597:INFO:Uploading model into container now
2024-09-25 10:46:39,597:INFO:_master_model_container: 4
2024-09-25 10:46:39,597:INFO:_display_container: 2
2024-09-25 10:46:39,598:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 10:46:39,598:INFO:create_model() successfully completed......................................
2024-09-25 10:46:39,662:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:39,663:INFO:Creating metrics dataframe
2024-09-25 10:46:39,666:INFO:Initializing SVM - Linear Kernel
2024-09-25 10:46:39,666:INFO:Total runtime is 0.4606060942014059 minutes
2024-09-25 10:46:39,668:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:39,668:INFO:Initializing create_model()
2024-09-25 10:46:39,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:39,668:INFO:Checking exceptions
2024-09-25 10:46:39,668:INFO:Importing libraries
2024-09-25 10:46:39,669:INFO:Copying training dataset
2024-09-25 10:46:39,713:INFO:Defining folds
2024-09-25 10:46:39,749:INFO:Declaring metric variables
2024-09-25 10:46:39,750:INFO:Importing untrained model
2024-09-25 10:46:39,752:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 10:46:39,755:INFO:Starting cross validation
2024-09-25 10:46:39,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:48,346:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:48,353:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:49,205:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:49,211:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:49,838:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:49,846:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:49,882:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:49,895:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:49,899:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:49,908:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:50,267:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:50,272:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:50,660:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:50,672:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:50,726:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,122:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,128:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:46:52,160:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,177:INFO:Calculating mean and std
2024-09-25 10:46:52,178:INFO:Creating metrics dataframe
2024-09-25 10:46:52,181:INFO:Uploading results into container
2024-09-25 10:46:52,181:INFO:Uploading model into container now
2024-09-25 10:46:52,181:INFO:_master_model_container: 5
2024-09-25 10:46:52,182:INFO:_display_container: 2
2024-09-25 10:46:52,182:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-25 10:46:52,182:INFO:create_model() successfully completed......................................
2024-09-25 10:46:52,275:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:52,276:INFO:Creating metrics dataframe
2024-09-25 10:46:52,281:INFO:Initializing Ridge Classifier
2024-09-25 10:46:52,281:INFO:Total runtime is 0.6708536307017009 minutes
2024-09-25 10:46:52,283:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:52,283:INFO:Initializing create_model()
2024-09-25 10:46:52,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:52,283:INFO:Checking exceptions
2024-09-25 10:46:52,283:INFO:Importing libraries
2024-09-25 10:46:52,283:INFO:Copying training dataset
2024-09-25 10:46:52,337:INFO:Defining folds
2024-09-25 10:46:52,337:INFO:Declaring metric variables
2024-09-25 10:46:52,339:INFO:Importing untrained model
2024-09-25 10:46:52,341:INFO:Ridge Classifier Imported successfully
2024-09-25 10:46:52,345:INFO:Starting cross validation
2024-09-25 10:46:52,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:46:52,472:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,485:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,528:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,595:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,608:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,610:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,623:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,657:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,670:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,713:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,727:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,742:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,752:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,800:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,813:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,844:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,852:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,854:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:46:52,865:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:46:52,880:INFO:Calculating mean and std
2024-09-25 10:46:52,881:INFO:Creating metrics dataframe
2024-09-25 10:46:52,883:INFO:Uploading results into container
2024-09-25 10:46:52,883:INFO:Uploading model into container now
2024-09-25 10:46:52,884:INFO:_master_model_container: 6
2024-09-25 10:46:52,885:INFO:_display_container: 2
2024-09-25 10:46:52,885:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-25 10:46:52,885:INFO:create_model() successfully completed......................................
2024-09-25 10:46:52,954:INFO:SubProcess create_model() end ==================================
2024-09-25 10:46:52,954:INFO:Creating metrics dataframe
2024-09-25 10:46:52,958:INFO:Initializing Random Forest Classifier
2024-09-25 10:46:52,958:INFO:Total runtime is 0.6821361978848776 minutes
2024-09-25 10:46:52,960:INFO:SubProcess create_model() called ==================================
2024-09-25 10:46:52,960:INFO:Initializing create_model()
2024-09-25 10:46:52,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:46:52,960:INFO:Checking exceptions
2024-09-25 10:46:52,960:INFO:Importing libraries
2024-09-25 10:46:52,960:INFO:Copying training dataset
2024-09-25 10:46:53,009:INFO:Defining folds
2024-09-25 10:46:53,010:INFO:Declaring metric variables
2024-09-25 10:46:53,012:INFO:Importing untrained model
2024-09-25 10:46:53,015:INFO:Random Forest Classifier Imported successfully
2024-09-25 10:46:53,018:INFO:Starting cross validation
2024-09-25 10:46:53,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:47:12,596:INFO:Calculating mean and std
2024-09-25 10:47:12,597:INFO:Creating metrics dataframe
2024-09-25 10:47:12,601:INFO:Uploading results into container
2024-09-25 10:47:12,602:INFO:Uploading model into container now
2024-09-25 10:47:12,603:INFO:_master_model_container: 7
2024-09-25 10:47:12,603:INFO:_display_container: 2
2024-09-25 10:47:12,604:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:47:12,604:INFO:create_model() successfully completed......................................
2024-09-25 10:47:12,716:INFO:SubProcess create_model() end ==================================
2024-09-25 10:47:12,716:INFO:Creating metrics dataframe
2024-09-25 10:47:12,720:INFO:Initializing Quadratic Discriminant Analysis
2024-09-25 10:47:12,720:INFO:Total runtime is 1.0115047136942545 minutes
2024-09-25 10:47:12,722:INFO:SubProcess create_model() called ==================================
2024-09-25 10:47:12,723:INFO:Initializing create_model()
2024-09-25 10:47:12,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:47:12,723:INFO:Checking exceptions
2024-09-25 10:47:12,723:INFO:Importing libraries
2024-09-25 10:47:12,723:INFO:Copying training dataset
2024-09-25 10:47:12,777:INFO:Defining folds
2024-09-25 10:47:12,778:INFO:Declaring metric variables
2024-09-25 10:47:12,780:INFO:Importing untrained model
2024-09-25 10:47:12,782:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-25 10:47:12,785:INFO:Starting cross validation
2024-09-25 10:47:12,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:47:12,944:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,015:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,083:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,129:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,149:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,194:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,235:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,274:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,321:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,353:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:13,371:INFO:Calculating mean and std
2024-09-25 10:47:13,372:INFO:Creating metrics dataframe
2024-09-25 10:47:13,372:INFO:Uploading results into container
2024-09-25 10:47:13,373:INFO:Uploading model into container now
2024-09-25 10:47:13,373:INFO:_master_model_container: 8
2024-09-25 10:47:13,373:INFO:_display_container: 2
2024-09-25 10:47:13,373:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-25 10:47:13,373:INFO:create_model() successfully completed......................................
2024-09-25 10:47:13,425:INFO:SubProcess create_model() end ==================================
2024-09-25 10:47:13,426:INFO:Creating metrics dataframe
2024-09-25 10:47:13,429:INFO:Initializing Ada Boost Classifier
2024-09-25 10:47:13,429:INFO:Total runtime is 1.0233244140942892 minutes
2024-09-25 10:47:13,430:INFO:SubProcess create_model() called ==================================
2024-09-25 10:47:13,431:INFO:Initializing create_model()
2024-09-25 10:47:13,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:47:13,431:INFO:Checking exceptions
2024-09-25 10:47:13,431:INFO:Importing libraries
2024-09-25 10:47:13,431:INFO:Copying training dataset
2024-09-25 10:47:13,473:INFO:Defining folds
2024-09-25 10:47:13,473:INFO:Declaring metric variables
2024-09-25 10:47:13,475:INFO:Importing untrained model
2024-09-25 10:47:13,476:INFO:Ada Boost Classifier Imported successfully
2024-09-25 10:47:13,479:INFO:Starting cross validation
2024-09-25 10:47:13,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:47:13,559:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,606:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,624:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,682:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,775:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,866:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:13,943:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:14,018:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:17,010:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,111:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,121:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:17,215:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:47:17,268:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,289:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,320:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,404:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,525:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:17,604:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:19,384:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:19,411:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:47:19,428:INFO:Calculating mean and std
2024-09-25 10:47:19,429:INFO:Creating metrics dataframe
2024-09-25 10:47:19,431:INFO:Uploading results into container
2024-09-25 10:47:19,431:INFO:Uploading model into container now
2024-09-25 10:47:19,432:INFO:_master_model_container: 9
2024-09-25 10:47:19,432:INFO:_display_container: 2
2024-09-25 10:47:19,432:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-25 10:47:19,432:INFO:create_model() successfully completed......................................
2024-09-25 10:47:19,505:INFO:SubProcess create_model() end ==================================
2024-09-25 10:47:19,505:INFO:Creating metrics dataframe
2024-09-25 10:47:19,510:INFO:Initializing Gradient Boosting Classifier
2024-09-25 10:47:19,510:INFO:Total runtime is 1.1246734778086345 minutes
2024-09-25 10:47:19,512:INFO:SubProcess create_model() called ==================================
2024-09-25 10:47:19,512:INFO:Initializing create_model()
2024-09-25 10:47:19,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:47:19,512:INFO:Checking exceptions
2024-09-25 10:47:19,512:INFO:Importing libraries
2024-09-25 10:47:19,512:INFO:Copying training dataset
2024-09-25 10:47:19,566:INFO:Defining folds
2024-09-25 10:47:19,567:INFO:Declaring metric variables
2024-09-25 10:47:19,569:INFO:Importing untrained model
2024-09-25 10:47:19,570:INFO:Gradient Boosting Classifier Imported successfully
2024-09-25 10:47:19,575:INFO:Starting cross validation
2024-09-25 10:47:19,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:48:03,869:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:03,924:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:03,996:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:04,333:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:04,432:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:04,524:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:04,680:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:04,707:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:29,758:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:29,879:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:29,898:INFO:Calculating mean and std
2024-09-25 10:48:29,901:INFO:Creating metrics dataframe
2024-09-25 10:48:29,903:INFO:Uploading results into container
2024-09-25 10:48:29,903:INFO:Uploading model into container now
2024-09-25 10:48:29,904:INFO:_master_model_container: 10
2024-09-25 10:48:29,904:INFO:_display_container: 2
2024-09-25 10:48:29,905:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-25 10:48:29,905:INFO:create_model() successfully completed......................................
2024-09-25 10:48:29,997:INFO:SubProcess create_model() end ==================================
2024-09-25 10:48:29,997:INFO:Creating metrics dataframe
2024-09-25 10:48:30,002:INFO:Initializing Linear Discriminant Analysis
2024-09-25 10:48:30,002:INFO:Total runtime is 2.2995335777600605 minutes
2024-09-25 10:48:30,003:INFO:SubProcess create_model() called ==================================
2024-09-25 10:48:30,003:INFO:Initializing create_model()
2024-09-25 10:48:30,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:48:30,003:INFO:Checking exceptions
2024-09-25 10:48:30,004:INFO:Importing libraries
2024-09-25 10:48:30,004:INFO:Copying training dataset
2024-09-25 10:48:30,045:INFO:Defining folds
2024-09-25 10:48:30,045:INFO:Declaring metric variables
2024-09-25 10:48:30,047:INFO:Importing untrained model
2024-09-25 10:48:30,049:INFO:Linear Discriminant Analysis Imported successfully
2024-09-25 10:48:30,052:INFO:Starting cross validation
2024-09-25 10:48:30,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:48:30,178:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,212:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,242:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,275:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,303:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,351:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,390:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,425:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,465:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,488:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:48:30,498:INFO:Calculating mean and std
2024-09-25 10:48:30,499:INFO:Creating metrics dataframe
2024-09-25 10:48:30,500:INFO:Uploading results into container
2024-09-25 10:48:30,500:INFO:Uploading model into container now
2024-09-25 10:48:30,500:INFO:_master_model_container: 11
2024-09-25 10:48:30,500:INFO:_display_container: 2
2024-09-25 10:48:30,501:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-25 10:48:30,501:INFO:create_model() successfully completed......................................
2024-09-25 10:48:30,555:INFO:SubProcess create_model() end ==================================
2024-09-25 10:48:30,555:INFO:Creating metrics dataframe
2024-09-25 10:48:30,559:INFO:Initializing Extra Trees Classifier
2024-09-25 10:48:30,559:INFO:Total runtime is 2.3088269313176473 minutes
2024-09-25 10:48:30,561:INFO:SubProcess create_model() called ==================================
2024-09-25 10:48:30,561:INFO:Initializing create_model()
2024-09-25 10:48:30,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:48:30,561:INFO:Checking exceptions
2024-09-25 10:48:30,561:INFO:Importing libraries
2024-09-25 10:48:30,561:INFO:Copying training dataset
2024-09-25 10:48:30,602:INFO:Defining folds
2024-09-25 10:48:30,602:INFO:Declaring metric variables
2024-09-25 10:48:30,604:INFO:Importing untrained model
2024-09-25 10:48:30,606:INFO:Extra Trees Classifier Imported successfully
2024-09-25 10:48:30,608:INFO:Starting cross validation
2024-09-25 10:48:30,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:48:43,614:INFO:Calculating mean and std
2024-09-25 10:48:43,617:INFO:Creating metrics dataframe
2024-09-25 10:48:43,622:INFO:Uploading results into container
2024-09-25 10:48:43,622:INFO:Uploading model into container now
2024-09-25 10:48:43,623:INFO:_master_model_container: 12
2024-09-25 10:48:43,623:INFO:_display_container: 2
2024-09-25 10:48:43,624:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-25 10:48:43,624:INFO:create_model() successfully completed......................................
2024-09-25 10:48:43,728:INFO:SubProcess create_model() end ==================================
2024-09-25 10:48:43,728:INFO:Creating metrics dataframe
2024-09-25 10:48:43,733:INFO:Initializing Extreme Gradient Boosting
2024-09-25 10:48:43,733:INFO:Total runtime is 2.528385861714681 minutes
2024-09-25 10:48:43,734:INFO:SubProcess create_model() called ==================================
2024-09-25 10:48:43,735:INFO:Initializing create_model()
2024-09-25 10:48:43,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:48:43,735:INFO:Checking exceptions
2024-09-25 10:48:43,735:INFO:Importing libraries
2024-09-25 10:48:43,735:INFO:Copying training dataset
2024-09-25 10:48:43,800:INFO:Defining folds
2024-09-25 10:48:43,800:INFO:Declaring metric variables
2024-09-25 10:48:43,803:INFO:Importing untrained model
2024-09-25 10:48:43,805:INFO:Extreme Gradient Boosting Imported successfully
2024-09-25 10:48:43,809:INFO:Starting cross validation
2024-09-25 10:48:43,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:48:44,336:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-25 10:48:49,750:INFO:Calculating mean and std
2024-09-25 10:48:49,751:INFO:Creating metrics dataframe
2024-09-25 10:48:49,754:INFO:Uploading results into container
2024-09-25 10:48:49,754:INFO:Uploading model into container now
2024-09-25 10:48:49,755:INFO:_master_model_container: 13
2024-09-25 10:48:49,755:INFO:_display_container: 2
2024-09-25 10:48:49,756:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-25 10:48:49,757:INFO:create_model() successfully completed......................................
2024-09-25 10:48:49,825:INFO:SubProcess create_model() end ==================================
2024-09-25 10:48:49,826:INFO:Creating metrics dataframe
2024-09-25 10:48:49,831:INFO:Initializing Light Gradient Boosting Machine
2024-09-25 10:48:49,831:INFO:Total runtime is 2.630018631617228 minutes
2024-09-25 10:48:49,833:INFO:SubProcess create_model() called ==================================
2024-09-25 10:48:49,833:INFO:Initializing create_model()
2024-09-25 10:48:49,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:48:49,833:INFO:Checking exceptions
2024-09-25 10:48:49,833:INFO:Importing libraries
2024-09-25 10:48:49,833:INFO:Copying training dataset
2024-09-25 10:48:49,881:INFO:Defining folds
2024-09-25 10:48:49,881:INFO:Declaring metric variables
2024-09-25 10:48:49,883:INFO:Importing untrained model
2024-09-25 10:48:49,885:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-25 10:48:49,888:INFO:Starting cross validation
2024-09-25 10:48:49,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:49:08,186:INFO:Calculating mean and std
2024-09-25 10:49:08,187:INFO:Creating metrics dataframe
2024-09-25 10:49:08,188:INFO:Uploading results into container
2024-09-25 10:49:08,189:INFO:Uploading model into container now
2024-09-25 10:49:08,189:INFO:_master_model_container: 14
2024-09-25 10:49:08,190:INFO:_display_container: 2
2024-09-25 10:49:08,190:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-25 10:49:08,190:INFO:create_model() successfully completed......................................
2024-09-25 10:49:08,268:INFO:SubProcess create_model() end ==================================
2024-09-25 10:49:08,268:INFO:Creating metrics dataframe
2024-09-25 10:49:08,274:INFO:Initializing Dummy Classifier
2024-09-25 10:49:08,274:INFO:Total runtime is 2.937402884165446 minutes
2024-09-25 10:49:08,277:INFO:SubProcess create_model() called ==================================
2024-09-25 10:49:08,278:INFO:Initializing create_model()
2024-09-25 10:49:08,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d0b4280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:49:08,278:INFO:Checking exceptions
2024-09-25 10:49:08,278:INFO:Importing libraries
2024-09-25 10:49:08,278:INFO:Copying training dataset
2024-09-25 10:49:08,340:INFO:Defining folds
2024-09-25 10:49:08,341:INFO:Declaring metric variables
2024-09-25 10:49:08,343:INFO:Importing untrained model
2024-09-25 10:49:08,346:INFO:Dummy Classifier Imported successfully
2024-09-25 10:49:08,350:INFO:Starting cross validation
2024-09-25 10:49:08,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:49:08,460:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,484:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,517:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,592:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,617:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,658:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,695:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,721:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,754:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,791:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:49:08,806:INFO:Calculating mean and std
2024-09-25 10:49:08,807:INFO:Creating metrics dataframe
2024-09-25 10:49:08,808:INFO:Uploading results into container
2024-09-25 10:49:08,808:INFO:Uploading model into container now
2024-09-25 10:49:08,809:INFO:_master_model_container: 15
2024-09-25 10:49:08,809:INFO:_display_container: 2
2024-09-25 10:49:08,809:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-25 10:49:08,809:INFO:create_model() successfully completed......................................
2024-09-25 10:49:08,863:INFO:SubProcess create_model() end ==================================
2024-09-25 10:49:08,863:INFO:Creating metrics dataframe
2024-09-25 10:49:08,869:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-25 10:49:08,873:INFO:Initializing create_model()
2024-09-25 10:49:08,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3123974c0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:49:08,873:INFO:Checking exceptions
2024-09-25 10:49:08,874:INFO:Importing libraries
2024-09-25 10:49:08,874:INFO:Copying training dataset
2024-09-25 10:49:08,917:INFO:Defining folds
2024-09-25 10:49:08,917:INFO:Declaring metric variables
2024-09-25 10:49:08,917:INFO:Importing untrained model
2024-09-25 10:49:08,917:INFO:Declaring custom model
2024-09-25 10:49:08,917:INFO:Random Forest Classifier Imported successfully
2024-09-25 10:49:08,918:INFO:Cross validation set to False
2024-09-25 10:49:08,918:INFO:Fitting Model
2024-09-25 10:49:11,183:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:49:11,183:INFO:create_model() successfully completed......................................
2024-09-25 10:49:11,255:INFO:_master_model_container: 15
2024-09-25 10:49:11,255:INFO:_display_container: 2
2024-09-25 10:49:11,256:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:49:11,256:INFO:compare_models() successfully completed......................................
2024-09-25 10:52:46,791:INFO:PyCaret ClassificationExperiment
2024-09-25 10:52:46,791:INFO:Logging name: clf-default-name
2024-09-25 10:52:46,792:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 10:52:46,792:INFO:version 3.3.2
2024-09-25 10:52:46,792:INFO:Initializing setup()
2024-09-25 10:52:46,792:INFO:self.USI: 0962
2024-09-25 10:52:46,792:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 10:52:46,792:INFO:Checking environment
2024-09-25 10:52:46,792:INFO:python_version: 3.10.14
2024-09-25 10:52:46,792:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 10:52:46,792:INFO:machine: arm64
2024-09-25 10:52:46,792:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 10:52:46,792:INFO:Memory: svmem(total=8589934592, available=2320400384, percent=73.0, used=3704750080, free=51118080, active=2285371392, inactive=2252177408, wired=1419378688)
2024-09-25 10:52:46,792:INFO:Physical Core: 8
2024-09-25 10:52:46,792:INFO:Logical Core: 8
2024-09-25 10:52:46,792:INFO:Checking libraries
2024-09-25 10:52:46,792:INFO:System:
2024-09-25 10:52:46,792:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 10:52:46,792:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 10:52:46,792:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 10:52:46,792:INFO:PyCaret required dependencies:
2024-09-25 10:52:46,792:INFO:                 pip: 24.2
2024-09-25 10:52:46,792:INFO:          setuptools: 72.1.0
2024-09-25 10:52:46,792:INFO:             pycaret: 3.3.2
2024-09-25 10:52:46,792:INFO:             IPython: 8.18.1
2024-09-25 10:52:46,792:INFO:          ipywidgets: 8.1.5
2024-09-25 10:52:46,792:INFO:                tqdm: 4.66.5
2024-09-25 10:52:46,792:INFO:               numpy: 1.26.4
2024-09-25 10:52:46,792:INFO:              pandas: 2.1.4
2024-09-25 10:52:46,792:INFO:              jinja2: 3.1.4
2024-09-25 10:52:46,792:INFO:               scipy: 1.11.4
2024-09-25 10:52:46,792:INFO:              joblib: 1.3.2
2024-09-25 10:52:46,792:INFO:             sklearn: 1.4.2
2024-09-25 10:52:46,792:INFO:                pyod: 2.0.2
2024-09-25 10:52:46,792:INFO:            imblearn: 0.12.3
2024-09-25 10:52:46,792:INFO:   category_encoders: 2.6.3
2024-09-25 10:52:46,792:INFO:            lightgbm: 4.5.0
2024-09-25 10:52:46,792:INFO:               numba: 0.60.0
2024-09-25 10:52:46,792:INFO:            requests: 2.32.3
2024-09-25 10:52:46,792:INFO:          matplotlib: 3.7.5
2024-09-25 10:52:46,793:INFO:          scikitplot: 0.3.7
2024-09-25 10:52:46,793:INFO:         yellowbrick: 1.5
2024-09-25 10:52:46,793:INFO:              plotly: 5.24.0
2024-09-25 10:52:46,793:INFO:    plotly-resampler: Not installed
2024-09-25 10:52:46,793:INFO:             kaleido: 0.2.1
2024-09-25 10:52:46,793:INFO:           schemdraw: 0.15
2024-09-25 10:52:46,793:INFO:         statsmodels: 0.14.3
2024-09-25 10:52:46,793:INFO:              sktime: 0.26.0
2024-09-25 10:52:46,793:INFO:               tbats: 1.1.3
2024-09-25 10:52:46,793:INFO:            pmdarima: 2.0.4
2024-09-25 10:52:46,793:INFO:              psutil: 5.9.0
2024-09-25 10:52:46,793:INFO:          markupsafe: 2.1.3
2024-09-25 10:52:46,793:INFO:             pickle5: Not installed
2024-09-25 10:52:46,793:INFO:         cloudpickle: 3.0.0
2024-09-25 10:52:46,793:INFO:         deprecation: 2.1.0
2024-09-25 10:52:46,793:INFO:              xxhash: 3.5.0
2024-09-25 10:52:46,793:INFO:           wurlitzer: 3.1.1
2024-09-25 10:52:46,793:INFO:PyCaret optional dependencies:
2024-09-25 10:52:46,793:INFO:                shap: 0.46.0
2024-09-25 10:52:46,793:INFO:           interpret: Not installed
2024-09-25 10:52:46,793:INFO:                umap: Not installed
2024-09-25 10:52:46,793:INFO:     ydata_profiling: Not installed
2024-09-25 10:52:46,793:INFO:  explainerdashboard: Not installed
2024-09-25 10:52:46,793:INFO:             autoviz: Not installed
2024-09-25 10:52:46,793:INFO:           fairlearn: Not installed
2024-09-25 10:52:46,793:INFO:          deepchecks: Not installed
2024-09-25 10:52:46,793:INFO:             xgboost: 2.1.1
2024-09-25 10:52:46,793:INFO:            catboost: Not installed
2024-09-25 10:52:46,793:INFO:              kmodes: Not installed
2024-09-25 10:52:46,793:INFO:             mlxtend: Not installed
2024-09-25 10:52:46,793:INFO:       statsforecast: Not installed
2024-09-25 10:52:46,793:INFO:        tune_sklearn: Not installed
2024-09-25 10:52:46,793:INFO:                 ray: Not installed
2024-09-25 10:52:46,793:INFO:            hyperopt: Not installed
2024-09-25 10:52:46,793:INFO:              optuna: 4.0.0
2024-09-25 10:52:46,793:INFO:               skopt: Not installed
2024-09-25 10:52:46,793:INFO:              mlflow: Not installed
2024-09-25 10:52:46,793:INFO:              gradio: Not installed
2024-09-25 10:52:46,793:INFO:             fastapi: Not installed
2024-09-25 10:52:46,793:INFO:             uvicorn: Not installed
2024-09-25 10:52:46,793:INFO:              m2cgen: Not installed
2024-09-25 10:52:46,793:INFO:           evidently: Not installed
2024-09-25 10:52:46,793:INFO:               fugue: Not installed
2024-09-25 10:52:46,793:INFO:           streamlit: 1.38.0
2024-09-25 10:52:46,793:INFO:             prophet: Not installed
2024-09-25 10:52:46,793:INFO:None
2024-09-25 10:52:46,793:INFO:Set up data.
2024-09-25 10:52:46,816:INFO:Set up folding strategy.
2024-09-25 10:52:46,816:INFO:Set up train/test split.
2024-09-25 10:52:46,847:INFO:Set up index.
2024-09-25 10:52:46,852:INFO:Assigning column types.
2024-09-25 10:52:46,864:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 10:52:46,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,896:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:46,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:46,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,916:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,928:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:46,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:46,929:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 10:52:46,948:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,959:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:46,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:46,979:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:52:46,991:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:46,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:46,992:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 10:52:47,022:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:47,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:47,054:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:47,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:47,055:INFO:Preparing preprocessing pipeline...
2024-09-25 10:52:47,058:INFO:Set up label encoding.
2024-09-25 10:52:47,058:INFO:Set up simple imputation.
2024-09-25 10:52:47,369:INFO:Finished creating preprocessing pipeline.
2024-09-25 10:52:47,371:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 10:52:47,371:INFO:Creating final display dataframe.
2024-09-25 10:52:48,090:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 16)
5        Transformed data shape       (100000, 16)
6   Transformed train set shape        (70000, 16)
7    Transformed test set shape        (30000, 16)
8              Numeric features                 15
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               0962
2024-09-25 10:52:48,127:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:48,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:48,162:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:52:48,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:52:48,164:INFO:setup() successfully completed in 1.37s...............
2024-09-25 10:52:48,173:INFO:Initializing compare_models()
2024-09-25 10:52:48,175:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 10:52:48,175:INFO:Checking exceptions
2024-09-25 10:52:48,199:INFO:Preparing display monitor
2024-09-25 10:52:48,212:INFO:Initializing Logistic Regression
2024-09-25 10:52:48,212:INFO:Total runtime is 2.2451082865397134e-06 minutes
2024-09-25 10:52:48,214:INFO:SubProcess create_model() called ==================================
2024-09-25 10:52:48,214:INFO:Initializing create_model()
2024-09-25 10:52:48,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:52:48,214:INFO:Checking exceptions
2024-09-25 10:52:48,214:INFO:Importing libraries
2024-09-25 10:52:48,214:INFO:Copying training dataset
2024-09-25 10:52:48,258:INFO:Defining folds
2024-09-25 10:52:48,258:INFO:Declaring metric variables
2024-09-25 10:52:48,260:INFO:Importing untrained model
2024-09-25 10:52:48,262:INFO:Logistic Regression Imported successfully
2024-09-25 10:52:48,265:INFO:Starting cross validation
2024-09-25 10:52:48,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:52:57,793:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:57,818:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,234:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,240:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,248:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,257:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,381:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,395:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,416:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,433:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,474:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,487:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,499:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,510:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:52:58,824:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:52:58,833:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:03,410:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:53:03,417:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:03,634:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:53:03,640:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:03,656:INFO:Calculating mean and std
2024-09-25 10:53:03,658:INFO:Creating metrics dataframe
2024-09-25 10:53:03,660:INFO:Uploading results into container
2024-09-25 10:53:03,660:INFO:Uploading model into container now
2024-09-25 10:53:03,661:INFO:_master_model_container: 1
2024-09-25 10:53:03,661:INFO:_display_container: 2
2024-09-25 10:53:03,662:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 10:53:03,662:INFO:create_model() successfully completed......................................
2024-09-25 10:53:03,769:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:03,770:INFO:Creating metrics dataframe
2024-09-25 10:53:03,772:INFO:Initializing K Neighbors Classifier
2024-09-25 10:53:03,773:INFO:Total runtime is 0.25934771299362186 minutes
2024-09-25 10:53:03,774:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:03,774:INFO:Initializing create_model()
2024-09-25 10:53:03,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:03,774:INFO:Checking exceptions
2024-09-25 10:53:03,775:INFO:Importing libraries
2024-09-25 10:53:03,775:INFO:Copying training dataset
2024-09-25 10:53:03,814:INFO:Defining folds
2024-09-25 10:53:03,814:INFO:Declaring metric variables
2024-09-25 10:53:03,815:INFO:Importing untrained model
2024-09-25 10:53:03,817:INFO:K Neighbors Classifier Imported successfully
2024-09-25 10:53:03,820:INFO:Starting cross validation
2024-09-25 10:53:03,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:04,791:INFO:Calculating mean and std
2024-09-25 10:53:04,792:INFO:Creating metrics dataframe
2024-09-25 10:53:04,792:INFO:Uploading results into container
2024-09-25 10:53:04,793:INFO:Uploading model into container now
2024-09-25 10:53:04,793:INFO:_master_model_container: 2
2024-09-25 10:53:04,793:INFO:_display_container: 2
2024-09-25 10:53:04,793:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 10:53:04,793:INFO:create_model() successfully completed......................................
2024-09-25 10:53:04,856:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:04,856:INFO:Creating metrics dataframe
2024-09-25 10:53:04,859:INFO:Initializing Naive Bayes
2024-09-25 10:53:04,859:INFO:Total runtime is 0.27745936314264935 minutes
2024-09-25 10:53:04,861:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:04,861:INFO:Initializing create_model()
2024-09-25 10:53:04,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:04,862:INFO:Checking exceptions
2024-09-25 10:53:04,862:INFO:Importing libraries
2024-09-25 10:53:04,862:INFO:Copying training dataset
2024-09-25 10:53:04,900:INFO:Defining folds
2024-09-25 10:53:04,900:INFO:Declaring metric variables
2024-09-25 10:53:04,901:INFO:Importing untrained model
2024-09-25 10:53:04,904:INFO:Naive Bayes Imported successfully
2024-09-25 10:53:04,906:INFO:Starting cross validation
2024-09-25 10:53:04,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:05,316:INFO:Calculating mean and std
2024-09-25 10:53:05,317:INFO:Creating metrics dataframe
2024-09-25 10:53:05,318:INFO:Uploading results into container
2024-09-25 10:53:05,318:INFO:Uploading model into container now
2024-09-25 10:53:05,318:INFO:_master_model_container: 3
2024-09-25 10:53:05,318:INFO:_display_container: 2
2024-09-25 10:53:05,318:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 10:53:05,318:INFO:create_model() successfully completed......................................
2024-09-25 10:53:05,386:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:05,386:INFO:Creating metrics dataframe
2024-09-25 10:53:05,390:INFO:Initializing Decision Tree Classifier
2024-09-25 10:53:05,390:INFO:Total runtime is 0.2862996459007263 minutes
2024-09-25 10:53:05,391:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:05,391:INFO:Initializing create_model()
2024-09-25 10:53:05,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:05,391:INFO:Checking exceptions
2024-09-25 10:53:05,391:INFO:Importing libraries
2024-09-25 10:53:05,392:INFO:Copying training dataset
2024-09-25 10:53:05,435:INFO:Defining folds
2024-09-25 10:53:05,435:INFO:Declaring metric variables
2024-09-25 10:53:05,437:INFO:Importing untrained model
2024-09-25 10:53:05,439:INFO:Decision Tree Classifier Imported successfully
2024-09-25 10:53:05,442:INFO:Starting cross validation
2024-09-25 10:53:05,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:07,129:INFO:Calculating mean and std
2024-09-25 10:53:07,130:INFO:Creating metrics dataframe
2024-09-25 10:53:07,132:INFO:Uploading results into container
2024-09-25 10:53:07,132:INFO:Uploading model into container now
2024-09-25 10:53:07,133:INFO:_master_model_container: 4
2024-09-25 10:53:07,133:INFO:_display_container: 2
2024-09-25 10:53:07,134:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 10:53:07,134:INFO:create_model() successfully completed......................................
2024-09-25 10:53:07,209:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:07,209:INFO:Creating metrics dataframe
2024-09-25 10:53:07,215:INFO:Initializing SVM - Linear Kernel
2024-09-25 10:53:07,215:INFO:Total runtime is 0.31672669649124147 minutes
2024-09-25 10:53:07,217:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:07,217:INFO:Initializing create_model()
2024-09-25 10:53:07,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:07,218:INFO:Checking exceptions
2024-09-25 10:53:07,218:INFO:Importing libraries
2024-09-25 10:53:07,218:INFO:Copying training dataset
2024-09-25 10:53:07,264:INFO:Defining folds
2024-09-25 10:53:07,264:INFO:Declaring metric variables
2024-09-25 10:53:07,267:INFO:Importing untrained model
2024-09-25 10:53:07,268:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 10:53:07,271:INFO:Starting cross validation
2024-09-25 10:53:07,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:14,424:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:14,431:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:14,475:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:14,485:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:15,047:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:15,053:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:15,458:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:15,462:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:15,532:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:15,536:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:15,580:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:15,584:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:15,975:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:15,980:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:16,366:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:16,372:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:18,010:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,014:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:18,259:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,263:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:53:18,279:INFO:Calculating mean and std
2024-09-25 10:53:18,280:INFO:Creating metrics dataframe
2024-09-25 10:53:18,282:INFO:Uploading results into container
2024-09-25 10:53:18,282:INFO:Uploading model into container now
2024-09-25 10:53:18,282:INFO:_master_model_container: 5
2024-09-25 10:53:18,282:INFO:_display_container: 2
2024-09-25 10:53:18,282:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-25 10:53:18,283:INFO:create_model() successfully completed......................................
2024-09-25 10:53:18,358:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:18,358:INFO:Creating metrics dataframe
2024-09-25 10:53:18,362:INFO:Initializing Ridge Classifier
2024-09-25 10:53:18,362:INFO:Total runtime is 0.5025086839993795 minutes
2024-09-25 10:53:18,364:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:18,365:INFO:Initializing create_model()
2024-09-25 10:53:18,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:18,365:INFO:Checking exceptions
2024-09-25 10:53:18,365:INFO:Importing libraries
2024-09-25 10:53:18,365:INFO:Copying training dataset
2024-09-25 10:53:18,409:INFO:Defining folds
2024-09-25 10:53:18,409:INFO:Declaring metric variables
2024-09-25 10:53:18,411:INFO:Importing untrained model
2024-09-25 10:53:18,414:INFO:Ridge Classifier Imported successfully
2024-09-25 10:53:18,417:INFO:Starting cross validation
2024-09-25 10:53:18,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:18,502:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14739e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,511:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,544:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15469e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,552:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,590:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14051e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,605:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,624:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15354e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,635:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,672:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.1534e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,682:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,713:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14985e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,722:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,772:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14098e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,783:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,807:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15386e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,815:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,846:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15292e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,854:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,891:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.16245e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:53:18,897:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:18,919:INFO:Calculating mean and std
2024-09-25 10:53:18,920:INFO:Creating metrics dataframe
2024-09-25 10:53:18,921:INFO:Uploading results into container
2024-09-25 10:53:18,921:INFO:Uploading model into container now
2024-09-25 10:53:18,922:INFO:_master_model_container: 6
2024-09-25 10:53:18,922:INFO:_display_container: 2
2024-09-25 10:53:18,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-25 10:53:18,922:INFO:create_model() successfully completed......................................
2024-09-25 10:53:18,983:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:18,983:INFO:Creating metrics dataframe
2024-09-25 10:53:18,986:INFO:Initializing Random Forest Classifier
2024-09-25 10:53:18,986:INFO:Total runtime is 0.5129098653793336 minutes
2024-09-25 10:53:18,988:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:18,988:INFO:Initializing create_model()
2024-09-25 10:53:18,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:18,988:INFO:Checking exceptions
2024-09-25 10:53:18,988:INFO:Importing libraries
2024-09-25 10:53:18,988:INFO:Copying training dataset
2024-09-25 10:53:19,023:INFO:Defining folds
2024-09-25 10:53:19,023:INFO:Declaring metric variables
2024-09-25 10:53:19,025:INFO:Importing untrained model
2024-09-25 10:53:19,027:INFO:Random Forest Classifier Imported successfully
2024-09-25 10:53:19,030:INFO:Starting cross validation
2024-09-25 10:53:19,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:38,245:INFO:Calculating mean and std
2024-09-25 10:53:38,249:INFO:Creating metrics dataframe
2024-09-25 10:53:38,253:INFO:Uploading results into container
2024-09-25 10:53:38,254:INFO:Uploading model into container now
2024-09-25 10:53:38,255:INFO:_master_model_container: 7
2024-09-25 10:53:38,255:INFO:_display_container: 2
2024-09-25 10:53:38,256:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:53:38,256:INFO:create_model() successfully completed......................................
2024-09-25 10:53:38,402:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:38,403:INFO:Creating metrics dataframe
2024-09-25 10:53:38,407:INFO:Initializing Quadratic Discriminant Analysis
2024-09-25 10:53:38,407:INFO:Total runtime is 0.8365894993146261 minutes
2024-09-25 10:53:38,410:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:38,410:INFO:Initializing create_model()
2024-09-25 10:53:38,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:38,411:INFO:Checking exceptions
2024-09-25 10:53:38,411:INFO:Importing libraries
2024-09-25 10:53:38,411:INFO:Copying training dataset
2024-09-25 10:53:38,466:INFO:Defining folds
2024-09-25 10:53:38,467:INFO:Declaring metric variables
2024-09-25 10:53:38,468:INFO:Importing untrained model
2024-09-25 10:53:38,471:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-25 10:53:38,474:INFO:Starting cross validation
2024-09-25 10:53:38,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:38,697:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:38,764:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:38,817:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:38,879:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:38,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,013:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,056:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,180:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,257:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,313:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:39,338:INFO:Calculating mean and std
2024-09-25 10:53:39,339:INFO:Creating metrics dataframe
2024-09-25 10:53:39,340:INFO:Uploading results into container
2024-09-25 10:53:39,341:INFO:Uploading model into container now
2024-09-25 10:53:39,345:INFO:_master_model_container: 8
2024-09-25 10:53:39,345:INFO:_display_container: 2
2024-09-25 10:53:39,345:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-25 10:53:39,345:INFO:create_model() successfully completed......................................
2024-09-25 10:53:39,429:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:39,429:INFO:Creating metrics dataframe
2024-09-25 10:53:39,433:INFO:Initializing Ada Boost Classifier
2024-09-25 10:53:39,433:INFO:Total runtime is 0.8536957184473674 minutes
2024-09-25 10:53:39,435:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:39,436:INFO:Initializing create_model()
2024-09-25 10:53:39,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:39,436:INFO:Checking exceptions
2024-09-25 10:53:39,436:INFO:Importing libraries
2024-09-25 10:53:39,436:INFO:Copying training dataset
2024-09-25 10:53:39,494:INFO:Defining folds
2024-09-25 10:53:39,494:INFO:Declaring metric variables
2024-09-25 10:53:39,496:INFO:Importing untrained model
2024-09-25 10:53:39,499:INFO:Ada Boost Classifier Imported successfully
2024-09-25 10:53:39,502:INFO:Starting cross validation
2024-09-25 10:53:39,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:53:39,599:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,659:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,719:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,779:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,842:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,914:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:39,961:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:40,068:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:43,293:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,343:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,482:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:43,489:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,552:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:53:43,604:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,613:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,637:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:43,696:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:45,900:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:45,946:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:53:45,964:INFO:Calculating mean and std
2024-09-25 10:53:45,965:INFO:Creating metrics dataframe
2024-09-25 10:53:45,967:INFO:Uploading results into container
2024-09-25 10:53:45,967:INFO:Uploading model into container now
2024-09-25 10:53:45,967:INFO:_master_model_container: 9
2024-09-25 10:53:45,967:INFO:_display_container: 2
2024-09-25 10:53:45,968:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-25 10:53:45,968:INFO:create_model() successfully completed......................................
2024-09-25 10:53:46,035:INFO:SubProcess create_model() end ==================================
2024-09-25 10:53:46,035:INFO:Creating metrics dataframe
2024-09-25 10:53:46,039:INFO:Initializing Gradient Boosting Classifier
2024-09-25 10:53:46,039:INFO:Total runtime is 0.9637952486673991 minutes
2024-09-25 10:53:46,041:INFO:SubProcess create_model() called ==================================
2024-09-25 10:53:46,041:INFO:Initializing create_model()
2024-09-25 10:53:46,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:53:46,041:INFO:Checking exceptions
2024-09-25 10:53:46,041:INFO:Importing libraries
2024-09-25 10:53:46,041:INFO:Copying training dataset
2024-09-25 10:53:46,078:INFO:Defining folds
2024-09-25 10:53:46,078:INFO:Declaring metric variables
2024-09-25 10:53:46,081:INFO:Importing untrained model
2024-09-25 10:53:46,083:INFO:Gradient Boosting Classifier Imported successfully
2024-09-25 10:53:46,085:INFO:Starting cross validation
2024-09-25 10:53:46,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:54:33,617:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:33,879:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:33,949:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:34,001:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:34,064:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:34,131:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:34,179:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:54:34,291:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:00,444:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:00,569:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:00,592:INFO:Calculating mean and std
2024-09-25 10:55:00,595:INFO:Creating metrics dataframe
2024-09-25 10:55:00,599:INFO:Uploading results into container
2024-09-25 10:55:00,600:INFO:Uploading model into container now
2024-09-25 10:55:00,600:INFO:_master_model_container: 10
2024-09-25 10:55:00,600:INFO:_display_container: 2
2024-09-25 10:55:00,601:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-25 10:55:00,601:INFO:create_model() successfully completed......................................
2024-09-25 10:55:00,709:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:00,709:INFO:Creating metrics dataframe
2024-09-25 10:55:00,718:INFO:Initializing Linear Discriminant Analysis
2024-09-25 10:55:00,718:INFO:Total runtime is 2.2084447463353474 minutes
2024-09-25 10:55:00,720:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:00,720:INFO:Initializing create_model()
2024-09-25 10:55:00,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:00,720:INFO:Checking exceptions
2024-09-25 10:55:00,720:INFO:Importing libraries
2024-09-25 10:55:00,720:INFO:Copying training dataset
2024-09-25 10:55:00,760:INFO:Defining folds
2024-09-25 10:55:00,760:INFO:Declaring metric variables
2024-09-25 10:55:00,763:INFO:Importing untrained model
2024-09-25 10:55:00,764:INFO:Linear Discriminant Analysis Imported successfully
2024-09-25 10:55:00,768:INFO:Starting cross validation
2024-09-25 10:55:00,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:00,916:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:00,945:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,017:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,075:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,091:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,137:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,187:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,235:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,278:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,319:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:01,333:INFO:Calculating mean and std
2024-09-25 10:55:01,334:INFO:Creating metrics dataframe
2024-09-25 10:55:01,335:INFO:Uploading results into container
2024-09-25 10:55:01,335:INFO:Uploading model into container now
2024-09-25 10:55:01,335:INFO:_master_model_container: 11
2024-09-25 10:55:01,335:INFO:_display_container: 2
2024-09-25 10:55:01,336:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-25 10:55:01,336:INFO:create_model() successfully completed......................................
2024-09-25 10:55:01,396:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:01,396:INFO:Creating metrics dataframe
2024-09-25 10:55:01,401:INFO:Initializing Extra Trees Classifier
2024-09-25 10:55:01,401:INFO:Total runtime is 2.219826630751292 minutes
2024-09-25 10:55:01,404:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:01,404:INFO:Initializing create_model()
2024-09-25 10:55:01,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17d0e5bd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f00f730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:01,404:INFO:Checking exceptions
2024-09-25 10:55:01,404:INFO:Importing libraries
2024-09-25 10:55:01,404:INFO:Copying training dataset
2024-09-25 10:55:01,474:INFO:Defining folds
2024-09-25 10:55:01,474:INFO:Declaring metric variables
2024-09-25 10:55:01,477:INFO:Importing untrained model
2024-09-25 10:55:01,479:INFO:Extra Trees Classifier Imported successfully
2024-09-25 10:55:01,483:INFO:Starting cross validation
2024-09-25 10:55:01,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:05,476:INFO:PyCaret ClassificationExperiment
2024-09-25 10:55:05,476:INFO:Logging name: clf-default-name
2024-09-25 10:55:05,476:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 10:55:05,476:INFO:version 3.3.2
2024-09-25 10:55:05,476:INFO:Initializing setup()
2024-09-25 10:55:05,476:INFO:self.USI: dc45
2024-09-25 10:55:05,476:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 10:55:05,477:INFO:Checking environment
2024-09-25 10:55:05,477:INFO:python_version: 3.10.14
2024-09-25 10:55:05,477:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 10:55:05,477:INFO:machine: arm64
2024-09-25 10:55:05,477:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 10:55:05,477:INFO:Memory: svmem(total=8589934592, available=2749808640, percent=68.0, used=3278995456, free=856719360, active=1896251392, inactive=1866743808, wired=1382744064)
2024-09-25 10:55:05,477:INFO:Physical Core: 8
2024-09-25 10:55:05,477:INFO:Logical Core: 8
2024-09-25 10:55:05,477:INFO:Checking libraries
2024-09-25 10:55:05,477:INFO:System:
2024-09-25 10:55:05,477:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 10:55:05,477:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 10:55:05,477:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 10:55:05,477:INFO:PyCaret required dependencies:
2024-09-25 10:55:05,477:INFO:                 pip: 24.2
2024-09-25 10:55:05,477:INFO:          setuptools: 72.1.0
2024-09-25 10:55:05,477:INFO:             pycaret: 3.3.2
2024-09-25 10:55:05,477:INFO:             IPython: 8.18.1
2024-09-25 10:55:05,477:INFO:          ipywidgets: 8.1.5
2024-09-25 10:55:05,477:INFO:                tqdm: 4.66.5
2024-09-25 10:55:05,477:INFO:               numpy: 1.26.4
2024-09-25 10:55:05,477:INFO:              pandas: 2.1.4
2024-09-25 10:55:05,477:INFO:              jinja2: 3.1.4
2024-09-25 10:55:05,477:INFO:               scipy: 1.11.4
2024-09-25 10:55:05,477:INFO:              joblib: 1.3.2
2024-09-25 10:55:05,477:INFO:             sklearn: 1.4.2
2024-09-25 10:55:05,477:INFO:                pyod: 2.0.2
2024-09-25 10:55:05,477:INFO:            imblearn: 0.12.3
2024-09-25 10:55:05,477:INFO:   category_encoders: 2.6.3
2024-09-25 10:55:05,477:INFO:            lightgbm: 4.5.0
2024-09-25 10:55:05,477:INFO:               numba: 0.60.0
2024-09-25 10:55:05,477:INFO:            requests: 2.32.3
2024-09-25 10:55:05,477:INFO:          matplotlib: 3.7.5
2024-09-25 10:55:05,477:INFO:          scikitplot: 0.3.7
2024-09-25 10:55:05,477:INFO:         yellowbrick: 1.5
2024-09-25 10:55:05,477:INFO:              plotly: 5.24.0
2024-09-25 10:55:05,477:INFO:    plotly-resampler: Not installed
2024-09-25 10:55:05,477:INFO:             kaleido: 0.2.1
2024-09-25 10:55:05,477:INFO:           schemdraw: 0.15
2024-09-25 10:55:05,477:INFO:         statsmodels: 0.14.3
2024-09-25 10:55:05,477:INFO:              sktime: 0.26.0
2024-09-25 10:55:05,477:INFO:               tbats: 1.1.3
2024-09-25 10:55:05,477:INFO:            pmdarima: 2.0.4
2024-09-25 10:55:05,477:INFO:              psutil: 5.9.0
2024-09-25 10:55:05,477:INFO:          markupsafe: 2.1.3
2024-09-25 10:55:05,477:INFO:             pickle5: Not installed
2024-09-25 10:55:05,477:INFO:         cloudpickle: 3.0.0
2024-09-25 10:55:05,477:INFO:         deprecation: 2.1.0
2024-09-25 10:55:05,477:INFO:              xxhash: 3.5.0
2024-09-25 10:55:05,477:INFO:           wurlitzer: 3.1.1
2024-09-25 10:55:05,477:INFO:PyCaret optional dependencies:
2024-09-25 10:55:05,477:INFO:                shap: 0.46.0
2024-09-25 10:55:05,478:INFO:           interpret: Not installed
2024-09-25 10:55:05,478:INFO:                umap: Not installed
2024-09-25 10:55:05,478:INFO:     ydata_profiling: Not installed
2024-09-25 10:55:05,478:INFO:  explainerdashboard: Not installed
2024-09-25 10:55:05,478:INFO:             autoviz: Not installed
2024-09-25 10:55:05,478:INFO:           fairlearn: Not installed
2024-09-25 10:55:05,478:INFO:          deepchecks: Not installed
2024-09-25 10:55:05,478:INFO:             xgboost: 2.1.1
2024-09-25 10:55:05,478:INFO:            catboost: Not installed
2024-09-25 10:55:05,478:INFO:              kmodes: Not installed
2024-09-25 10:55:05,478:INFO:             mlxtend: Not installed
2024-09-25 10:55:05,478:INFO:       statsforecast: Not installed
2024-09-25 10:55:05,478:INFO:        tune_sklearn: Not installed
2024-09-25 10:55:05,478:INFO:                 ray: Not installed
2024-09-25 10:55:05,478:INFO:            hyperopt: Not installed
2024-09-25 10:55:05,478:INFO:              optuna: 4.0.0
2024-09-25 10:55:05,478:INFO:               skopt: Not installed
2024-09-25 10:55:05,478:INFO:              mlflow: Not installed
2024-09-25 10:55:05,478:INFO:              gradio: Not installed
2024-09-25 10:55:05,478:INFO:             fastapi: Not installed
2024-09-25 10:55:05,478:INFO:             uvicorn: Not installed
2024-09-25 10:55:05,478:INFO:              m2cgen: Not installed
2024-09-25 10:55:05,478:INFO:           evidently: Not installed
2024-09-25 10:55:05,478:INFO:               fugue: Not installed
2024-09-25 10:55:05,478:INFO:           streamlit: 1.38.0
2024-09-25 10:55:05,478:INFO:             prophet: Not installed
2024-09-25 10:55:05,478:INFO:None
2024-09-25 10:55:05,478:INFO:Set up data.
2024-09-25 10:55:05,503:INFO:Set up folding strategy.
2024-09-25 10:55:05,503:INFO:Set up train/test split.
2024-09-25 10:55:05,537:INFO:Set up index.
2024-09-25 10:55:05,544:INFO:Assigning column types.
2024-09-25 10:55:05,557:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 10:55:05,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,579:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,592:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,641:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,642:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 10:55:05,672:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,686:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,710:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 10:55:05,724:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 10:55:05,761:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,799:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:05,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:05,801:INFO:Preparing preprocessing pipeline...
2024-09-25 10:55:05,804:INFO:Set up label encoding.
2024-09-25 10:55:05,804:INFO:Set up simple imputation.
2024-09-25 10:55:06,192:INFO:Finished creating preprocessing pipeline.
2024-09-25 10:55:06,194:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 10:55:06,194:INFO:Creating final display dataframe.
2024-09-25 10:55:06,912:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 15)
5        Transformed data shape       (100000, 15)
6   Transformed train set shape        (70000, 15)
7    Transformed test set shape        (30000, 15)
8              Numeric features                 14
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               dc45
2024-09-25 10:55:06,950:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:06,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:06,986:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 10:55:06,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 10:55:06,988:INFO:setup() successfully completed in 1.52s...............
2024-09-25 10:55:06,994:INFO:Initializing compare_models()
2024-09-25 10:55:06,994:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 10:55:06,994:INFO:Checking exceptions
2024-09-25 10:55:07,015:INFO:Preparing display monitor
2024-09-25 10:55:07,027:INFO:Initializing Logistic Regression
2024-09-25 10:55:07,027:INFO:Total runtime is 2.7338663736979167e-06 minutes
2024-09-25 10:55:07,029:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:07,029:INFO:Initializing create_model()
2024-09-25 10:55:07,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:07,029:INFO:Checking exceptions
2024-09-25 10:55:07,029:INFO:Importing libraries
2024-09-25 10:55:07,029:INFO:Copying training dataset
2024-09-25 10:55:07,077:INFO:Defining folds
2024-09-25 10:55:07,077:INFO:Declaring metric variables
2024-09-25 10:55:07,079:INFO:Importing untrained model
2024-09-25 10:55:07,080:INFO:Logistic Regression Imported successfully
2024-09-25 10:55:07,084:INFO:Starting cross validation
2024-09-25 10:55:07,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:21,890:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:21,999:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,224:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,264:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,616:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,647:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,695:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,700:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,728:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,738:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,848:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,876:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:22,905:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:22,925:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:23,042:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:23,095:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:28,073:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:28,081:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:28,172:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 10:55:28,179:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:28,203:INFO:Calculating mean and std
2024-09-25 10:55:28,205:INFO:Creating metrics dataframe
2024-09-25 10:55:28,208:INFO:Uploading results into container
2024-09-25 10:55:28,208:INFO:Uploading model into container now
2024-09-25 10:55:28,209:INFO:_master_model_container: 1
2024-09-25 10:55:28,209:INFO:_display_container: 2
2024-09-25 10:55:28,209:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 10:55:28,209:INFO:create_model() successfully completed......................................
2024-09-25 10:55:28,329:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:28,329:INFO:Creating metrics dataframe
2024-09-25 10:55:28,332:INFO:Initializing K Neighbors Classifier
2024-09-25 10:55:28,332:INFO:Total runtime is 0.35508436759312945 minutes
2024-09-25 10:55:28,334:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:28,334:INFO:Initializing create_model()
2024-09-25 10:55:28,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:28,334:INFO:Checking exceptions
2024-09-25 10:55:28,334:INFO:Importing libraries
2024-09-25 10:55:28,334:INFO:Copying training dataset
2024-09-25 10:55:28,385:INFO:Defining folds
2024-09-25 10:55:28,386:INFO:Declaring metric variables
2024-09-25 10:55:28,387:INFO:Importing untrained model
2024-09-25 10:55:28,389:INFO:K Neighbors Classifier Imported successfully
2024-09-25 10:55:28,391:INFO:Starting cross validation
2024-09-25 10:55:28,392:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:29,662:INFO:Calculating mean and std
2024-09-25 10:55:29,663:INFO:Creating metrics dataframe
2024-09-25 10:55:29,664:INFO:Uploading results into container
2024-09-25 10:55:29,664:INFO:Uploading model into container now
2024-09-25 10:55:29,665:INFO:_master_model_container: 2
2024-09-25 10:55:29,665:INFO:_display_container: 2
2024-09-25 10:55:29,666:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 10:55:29,666:INFO:create_model() successfully completed......................................
2024-09-25 10:55:29,756:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:29,756:INFO:Creating metrics dataframe
2024-09-25 10:55:29,760:INFO:Initializing Naive Bayes
2024-09-25 10:55:29,760:INFO:Total runtime is 0.37888514995574946 minutes
2024-09-25 10:55:29,762:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:29,763:INFO:Initializing create_model()
2024-09-25 10:55:29,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:29,763:INFO:Checking exceptions
2024-09-25 10:55:29,764:INFO:Importing libraries
2024-09-25 10:55:29,764:INFO:Copying training dataset
2024-09-25 10:55:29,825:INFO:Defining folds
2024-09-25 10:55:29,825:INFO:Declaring metric variables
2024-09-25 10:55:29,828:INFO:Importing untrained model
2024-09-25 10:55:29,831:INFO:Naive Bayes Imported successfully
2024-09-25 10:55:29,835:INFO:Starting cross validation
2024-09-25 10:55:29,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:30,415:INFO:Calculating mean and std
2024-09-25 10:55:30,416:INFO:Creating metrics dataframe
2024-09-25 10:55:30,418:INFO:Uploading results into container
2024-09-25 10:55:30,418:INFO:Uploading model into container now
2024-09-25 10:55:30,418:INFO:_master_model_container: 3
2024-09-25 10:55:30,418:INFO:_display_container: 2
2024-09-25 10:55:30,419:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 10:55:30,419:INFO:create_model() successfully completed......................................
2024-09-25 10:55:30,502:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:30,502:INFO:Creating metrics dataframe
2024-09-25 10:55:30,506:INFO:Initializing Decision Tree Classifier
2024-09-25 10:55:30,506:INFO:Total runtime is 0.39131711324055984 minutes
2024-09-25 10:55:30,508:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:30,508:INFO:Initializing create_model()
2024-09-25 10:55:30,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:30,508:INFO:Checking exceptions
2024-09-25 10:55:30,508:INFO:Importing libraries
2024-09-25 10:55:30,508:INFO:Copying training dataset
2024-09-25 10:55:30,554:INFO:Defining folds
2024-09-25 10:55:30,554:INFO:Declaring metric variables
2024-09-25 10:55:30,556:INFO:Importing untrained model
2024-09-25 10:55:30,559:INFO:Decision Tree Classifier Imported successfully
2024-09-25 10:55:30,563:INFO:Starting cross validation
2024-09-25 10:55:30,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:32,336:INFO:Calculating mean and std
2024-09-25 10:55:32,337:INFO:Creating metrics dataframe
2024-09-25 10:55:32,338:INFO:Uploading results into container
2024-09-25 10:55:32,339:INFO:Uploading model into container now
2024-09-25 10:55:32,339:INFO:_master_model_container: 4
2024-09-25 10:55:32,339:INFO:_display_container: 2
2024-09-25 10:55:32,340:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 10:55:32,340:INFO:create_model() successfully completed......................................
2024-09-25 10:55:32,443:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:32,443:INFO:Creating metrics dataframe
2024-09-25 10:55:32,447:INFO:Initializing SVM - Linear Kernel
2024-09-25 10:55:32,447:INFO:Total runtime is 0.42367269992828366 minutes
2024-09-25 10:55:32,449:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:32,449:INFO:Initializing create_model()
2024-09-25 10:55:32,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:32,449:INFO:Checking exceptions
2024-09-25 10:55:32,449:INFO:Importing libraries
2024-09-25 10:55:32,449:INFO:Copying training dataset
2024-09-25 10:55:32,498:INFO:Defining folds
2024-09-25 10:55:32,499:INFO:Declaring metric variables
2024-09-25 10:55:32,502:INFO:Importing untrained model
2024-09-25 10:55:32,504:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 10:55:32,507:INFO:Starting cross validation
2024-09-25 10:55:32,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:40,402:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:40,410:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:40,448:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:40,454:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:40,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:40,936:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:41,116:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:41,122:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:41,151:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:41,160:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:41,372:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:41,559:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:41,574:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:41,717:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:42,926:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:42,931:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:55:43,333:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,354:INFO:Calculating mean and std
2024-09-25 10:55:43,356:INFO:Creating metrics dataframe
2024-09-25 10:55:43,359:INFO:Uploading results into container
2024-09-25 10:55:43,360:INFO:Uploading model into container now
2024-09-25 10:55:43,360:INFO:_master_model_container: 5
2024-09-25 10:55:43,361:INFO:_display_container: 2
2024-09-25 10:55:43,361:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-25 10:55:43,362:INFO:create_model() successfully completed......................................
2024-09-25 10:55:43,468:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:43,468:INFO:Creating metrics dataframe
2024-09-25 10:55:43,472:INFO:Initializing Ridge Classifier
2024-09-25 10:55:43,472:INFO:Total runtime is 0.6074139515558878 minutes
2024-09-25 10:55:43,473:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:43,473:INFO:Initializing create_model()
2024-09-25 10:55:43,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:43,473:INFO:Checking exceptions
2024-09-25 10:55:43,473:INFO:Importing libraries
2024-09-25 10:55:43,474:INFO:Copying training dataset
2024-09-25 10:55:43,520:INFO:Defining folds
2024-09-25 10:55:43,520:INFO:Declaring metric variables
2024-09-25 10:55:43,522:INFO:Importing untrained model
2024-09-25 10:55:43,524:INFO:Ridge Classifier Imported successfully
2024-09-25 10:55:43,527:INFO:Starting cross validation
2024-09-25 10:55:43,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:55:43,617:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.1475e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,623:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,653:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15513e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,663:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,684:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.141e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,691:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,726:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15401e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,738:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,782:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15348e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,795:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,833:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15008e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,843:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,872:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14134e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,880:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,934:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15461e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,946:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,970:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15292e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,978:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:43,991:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.16295e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 10:55:43,999:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:55:44,015:INFO:Calculating mean and std
2024-09-25 10:55:44,016:INFO:Creating metrics dataframe
2024-09-25 10:55:44,017:INFO:Uploading results into container
2024-09-25 10:55:44,017:INFO:Uploading model into container now
2024-09-25 10:55:44,017:INFO:_master_model_container: 6
2024-09-25 10:55:44,017:INFO:_display_container: 2
2024-09-25 10:55:44,018:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-25 10:55:44,018:INFO:create_model() successfully completed......................................
2024-09-25 10:55:44,110:INFO:SubProcess create_model() end ==================================
2024-09-25 10:55:44,110:INFO:Creating metrics dataframe
2024-09-25 10:55:44,114:INFO:Initializing Random Forest Classifier
2024-09-25 10:55:44,114:INFO:Total runtime is 0.6181225856145223 minutes
2024-09-25 10:55:44,116:INFO:SubProcess create_model() called ==================================
2024-09-25 10:55:44,117:INFO:Initializing create_model()
2024-09-25 10:55:44,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:55:44,117:INFO:Checking exceptions
2024-09-25 10:55:44,117:INFO:Importing libraries
2024-09-25 10:55:44,117:INFO:Copying training dataset
2024-09-25 10:55:44,173:INFO:Defining folds
2024-09-25 10:55:44,173:INFO:Declaring metric variables
2024-09-25 10:55:44,176:INFO:Importing untrained model
2024-09-25 10:55:44,178:INFO:Random Forest Classifier Imported successfully
2024-09-25 10:55:44,181:INFO:Starting cross validation
2024-09-25 10:55:44,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:56:05,982:INFO:Calculating mean and std
2024-09-25 10:56:05,985:INFO:Creating metrics dataframe
2024-09-25 10:56:05,990:INFO:Uploading results into container
2024-09-25 10:56:05,991:INFO:Uploading model into container now
2024-09-25 10:56:05,992:INFO:_master_model_container: 7
2024-09-25 10:56:05,992:INFO:_display_container: 2
2024-09-25 10:56:05,993:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:56:05,994:INFO:create_model() successfully completed......................................
2024-09-25 10:56:06,134:INFO:SubProcess create_model() end ==================================
2024-09-25 10:56:06,134:INFO:Creating metrics dataframe
2024-09-25 10:56:06,138:INFO:Initializing Quadratic Discriminant Analysis
2024-09-25 10:56:06,138:INFO:Total runtime is 0.9851867794990539 minutes
2024-09-25 10:56:06,140:INFO:SubProcess create_model() called ==================================
2024-09-25 10:56:06,140:INFO:Initializing create_model()
2024-09-25 10:56:06,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:56:06,140:INFO:Checking exceptions
2024-09-25 10:56:06,140:INFO:Importing libraries
2024-09-25 10:56:06,140:INFO:Copying training dataset
2024-09-25 10:56:06,188:INFO:Defining folds
2024-09-25 10:56:06,188:INFO:Declaring metric variables
2024-09-25 10:56:06,190:INFO:Importing untrained model
2024-09-25 10:56:06,192:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-25 10:56:06,194:INFO:Starting cross validation
2024-09-25 10:56:06,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:56:06,334:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,371:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,420:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,478:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,511:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,572:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,637:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,667:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,715:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,769:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:06,785:INFO:Calculating mean and std
2024-09-25 10:56:06,786:INFO:Creating metrics dataframe
2024-09-25 10:56:06,787:INFO:Uploading results into container
2024-09-25 10:56:06,787:INFO:Uploading model into container now
2024-09-25 10:56:06,787:INFO:_master_model_container: 8
2024-09-25 10:56:06,787:INFO:_display_container: 2
2024-09-25 10:56:06,788:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-25 10:56:06,788:INFO:create_model() successfully completed......................................
2024-09-25 10:56:06,866:INFO:SubProcess create_model() end ==================================
2024-09-25 10:56:06,866:INFO:Creating metrics dataframe
2024-09-25 10:56:06,870:INFO:Initializing Ada Boost Classifier
2024-09-25 10:56:06,870:INFO:Total runtime is 0.997379183769226 minutes
2024-09-25 10:56:06,871:INFO:SubProcess create_model() called ==================================
2024-09-25 10:56:06,871:INFO:Initializing create_model()
2024-09-25 10:56:06,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:56:06,871:INFO:Checking exceptions
2024-09-25 10:56:06,871:INFO:Importing libraries
2024-09-25 10:56:06,871:INFO:Copying training dataset
2024-09-25 10:56:06,907:INFO:Defining folds
2024-09-25 10:56:06,907:INFO:Declaring metric variables
2024-09-25 10:56:06,909:INFO:Importing untrained model
2024-09-25 10:56:06,911:INFO:Ada Boost Classifier Imported successfully
2024-09-25 10:56:06,913:INFO:Starting cross validation
2024-09-25 10:56:06,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:56:06,976:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,007:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,040:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,098:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,205:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,285:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,394:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:07,468:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:10,709:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:10,837:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:10,863:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:10,908:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:10,970:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 10:56:10,988:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:11,076:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:11,212:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:11,266:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:11,299:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:13,182:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:13,265:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:13,286:INFO:Calculating mean and std
2024-09-25 10:56:13,287:INFO:Creating metrics dataframe
2024-09-25 10:56:13,289:INFO:Uploading results into container
2024-09-25 10:56:13,289:INFO:Uploading model into container now
2024-09-25 10:56:13,290:INFO:_master_model_container: 9
2024-09-25 10:56:13,290:INFO:_display_container: 2
2024-09-25 10:56:13,291:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-25 10:56:13,291:INFO:create_model() successfully completed......................................
2024-09-25 10:56:13,373:INFO:SubProcess create_model() end ==================================
2024-09-25 10:56:13,373:INFO:Creating metrics dataframe
2024-09-25 10:56:13,377:INFO:Initializing Gradient Boosting Classifier
2024-09-25 10:56:13,377:INFO:Total runtime is 1.105834917227427 minutes
2024-09-25 10:56:13,378:INFO:SubProcess create_model() called ==================================
2024-09-25 10:56:13,379:INFO:Initializing create_model()
2024-09-25 10:56:13,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:56:13,379:INFO:Checking exceptions
2024-09-25 10:56:13,379:INFO:Importing libraries
2024-09-25 10:56:13,379:INFO:Copying training dataset
2024-09-25 10:56:13,419:INFO:Defining folds
2024-09-25 10:56:13,419:INFO:Declaring metric variables
2024-09-25 10:56:13,420:INFO:Importing untrained model
2024-09-25 10:56:13,423:INFO:Gradient Boosting Classifier Imported successfully
2024-09-25 10:56:13,426:INFO:Starting cross validation
2024-09-25 10:56:13,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:56:58,582:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,631:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,791:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,823:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,863:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,871:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,905:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:56:58,996:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,490:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,530:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,550:INFO:Calculating mean and std
2024-09-25 10:57:25,552:INFO:Creating metrics dataframe
2024-09-25 10:57:25,555:INFO:Uploading results into container
2024-09-25 10:57:25,555:INFO:Uploading model into container now
2024-09-25 10:57:25,556:INFO:_master_model_container: 10
2024-09-25 10:57:25,556:INFO:_display_container: 2
2024-09-25 10:57:25,557:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-25 10:57:25,557:INFO:create_model() successfully completed......................................
2024-09-25 10:57:25,672:INFO:SubProcess create_model() end ==================================
2024-09-25 10:57:25,673:INFO:Creating metrics dataframe
2024-09-25 10:57:25,677:INFO:Initializing Linear Discriminant Analysis
2024-09-25 10:57:25,677:INFO:Total runtime is 2.3108263850212096 minutes
2024-09-25 10:57:25,678:INFO:SubProcess create_model() called ==================================
2024-09-25 10:57:25,678:INFO:Initializing create_model()
2024-09-25 10:57:25,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:57:25,678:INFO:Checking exceptions
2024-09-25 10:57:25,678:INFO:Importing libraries
2024-09-25 10:57:25,678:INFO:Copying training dataset
2024-09-25 10:57:25,718:INFO:Defining folds
2024-09-25 10:57:25,718:INFO:Declaring metric variables
2024-09-25 10:57:25,719:INFO:Importing untrained model
2024-09-25 10:57:25,722:INFO:Linear Discriminant Analysis Imported successfully
2024-09-25 10:57:25,724:INFO:Starting cross validation
2024-09-25 10:57:25,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:57:25,844:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,873:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,906:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,965:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:25,987:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,040:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,079:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,118:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,162:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,185:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 10:57:26,208:INFO:Calculating mean and std
2024-09-25 10:57:26,209:INFO:Creating metrics dataframe
2024-09-25 10:57:26,210:INFO:Uploading results into container
2024-09-25 10:57:26,210:INFO:Uploading model into container now
2024-09-25 10:57:26,211:INFO:_master_model_container: 11
2024-09-25 10:57:26,211:INFO:_display_container: 2
2024-09-25 10:57:26,212:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-25 10:57:26,212:INFO:create_model() successfully completed......................................
2024-09-25 10:57:26,284:INFO:SubProcess create_model() end ==================================
2024-09-25 10:57:26,284:INFO:Creating metrics dataframe
2024-09-25 10:57:26,288:INFO:Initializing Extra Trees Classifier
2024-09-25 10:57:26,288:INFO:Total runtime is 2.3210242350896197 minutes
2024-09-25 10:57:26,290:INFO:SubProcess create_model() called ==================================
2024-09-25 10:57:26,290:INFO:Initializing create_model()
2024-09-25 10:57:26,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:57:26,290:INFO:Checking exceptions
2024-09-25 10:57:26,290:INFO:Importing libraries
2024-09-25 10:57:26,290:INFO:Copying training dataset
2024-09-25 10:57:26,333:INFO:Defining folds
2024-09-25 10:57:26,333:INFO:Declaring metric variables
2024-09-25 10:57:26,334:INFO:Importing untrained model
2024-09-25 10:57:26,337:INFO:Extra Trees Classifier Imported successfully
2024-09-25 10:57:26,339:INFO:Starting cross validation
2024-09-25 10:57:26,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:57:40,421:INFO:Calculating mean and std
2024-09-25 10:57:40,425:INFO:Creating metrics dataframe
2024-09-25 10:57:40,432:INFO:Uploading results into container
2024-09-25 10:57:40,433:INFO:Uploading model into container now
2024-09-25 10:57:40,434:INFO:_master_model_container: 12
2024-09-25 10:57:40,434:INFO:_display_container: 2
2024-09-25 10:57:40,435:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-25 10:57:40,435:INFO:create_model() successfully completed......................................
2024-09-25 10:57:40,582:INFO:SubProcess create_model() end ==================================
2024-09-25 10:57:40,582:INFO:Creating metrics dataframe
2024-09-25 10:57:40,587:INFO:Initializing Extreme Gradient Boosting
2024-09-25 10:57:40,587:INFO:Total runtime is 2.5593403975168862 minutes
2024-09-25 10:57:40,590:INFO:SubProcess create_model() called ==================================
2024-09-25 10:57:40,591:INFO:Initializing create_model()
2024-09-25 10:57:40,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:57:40,591:INFO:Checking exceptions
2024-09-25 10:57:40,591:INFO:Importing libraries
2024-09-25 10:57:40,591:INFO:Copying training dataset
2024-09-25 10:57:40,665:INFO:Defining folds
2024-09-25 10:57:40,665:INFO:Declaring metric variables
2024-09-25 10:57:40,667:INFO:Importing untrained model
2024-09-25 10:57:40,670:INFO:Extreme Gradient Boosting Imported successfully
2024-09-25 10:57:40,673:INFO:Starting cross validation
2024-09-25 10:57:40,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:57:41,152:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-25 10:57:48,252:INFO:Calculating mean and std
2024-09-25 10:57:48,255:INFO:Creating metrics dataframe
2024-09-25 10:57:48,261:INFO:Uploading results into container
2024-09-25 10:57:48,261:INFO:Uploading model into container now
2024-09-25 10:57:48,262:INFO:_master_model_container: 13
2024-09-25 10:57:48,262:INFO:_display_container: 2
2024-09-25 10:57:48,264:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-25 10:57:48,264:INFO:create_model() successfully completed......................................
2024-09-25 10:57:48,385:INFO:SubProcess create_model() end ==================================
2024-09-25 10:57:48,385:INFO:Creating metrics dataframe
2024-09-25 10:57:48,392:INFO:Initializing Light Gradient Boosting Machine
2024-09-25 10:57:48,392:INFO:Total runtime is 2.6894162694613137 minutes
2024-09-25 10:57:48,396:INFO:SubProcess create_model() called ==================================
2024-09-25 10:57:48,396:INFO:Initializing create_model()
2024-09-25 10:57:48,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:57:48,396:INFO:Checking exceptions
2024-09-25 10:57:48,397:INFO:Importing libraries
2024-09-25 10:57:48,397:INFO:Copying training dataset
2024-09-25 10:57:48,491:INFO:Defining folds
2024-09-25 10:57:48,491:INFO:Declaring metric variables
2024-09-25 10:57:48,495:INFO:Importing untrained model
2024-09-25 10:57:48,499:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-25 10:57:48,507:INFO:Starting cross validation
2024-09-25 10:57:48,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:58:07,872:INFO:Calculating mean and std
2024-09-25 10:58:07,875:INFO:Creating metrics dataframe
2024-09-25 10:58:07,878:INFO:Uploading results into container
2024-09-25 10:58:07,879:INFO:Uploading model into container now
2024-09-25 10:58:07,879:INFO:_master_model_container: 14
2024-09-25 10:58:07,880:INFO:_display_container: 2
2024-09-25 10:58:07,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-25 10:58:07,881:INFO:create_model() successfully completed......................................
2024-09-25 10:58:08,019:INFO:SubProcess create_model() end ==================================
2024-09-25 10:58:08,019:INFO:Creating metrics dataframe
2024-09-25 10:58:08,025:INFO:Initializing Dummy Classifier
2024-09-25 10:58:08,025:INFO:Total runtime is 3.0166321833928427 minutes
2024-09-25 10:58:08,027:INFO:SubProcess create_model() called ==================================
2024-09-25 10:58:08,027:INFO:Initializing create_model()
2024-09-25 10:58:08,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d436fb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:58:08,028:INFO:Checking exceptions
2024-09-25 10:58:08,028:INFO:Importing libraries
2024-09-25 10:58:08,028:INFO:Copying training dataset
2024-09-25 10:58:08,077:INFO:Defining folds
2024-09-25 10:58:08,077:INFO:Declaring metric variables
2024-09-25 10:58:08,079:INFO:Importing untrained model
2024-09-25 10:58:08,081:INFO:Dummy Classifier Imported successfully
2024-09-25 10:58:08,084:INFO:Starting cross validation
2024-09-25 10:58:08,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 10:58:08,175:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,205:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,233:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,268:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,307:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,339:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,373:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,404:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,434:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,461:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 10:58:08,475:INFO:Calculating mean and std
2024-09-25 10:58:08,476:INFO:Creating metrics dataframe
2024-09-25 10:58:08,477:INFO:Uploading results into container
2024-09-25 10:58:08,477:INFO:Uploading model into container now
2024-09-25 10:58:08,477:INFO:_master_model_container: 15
2024-09-25 10:58:08,477:INFO:_display_container: 2
2024-09-25 10:58:08,478:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-25 10:58:08,478:INFO:create_model() successfully completed......................................
2024-09-25 10:58:08,548:INFO:SubProcess create_model() end ==================================
2024-09-25 10:58:08,548:INFO:Creating metrics dataframe
2024-09-25 10:58:08,552:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-25 10:58:08,555:INFO:Initializing create_model()
2024-09-25 10:58:08,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x313ec30d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 10:58:08,555:INFO:Checking exceptions
2024-09-25 10:58:08,557:INFO:Importing libraries
2024-09-25 10:58:08,557:INFO:Copying training dataset
2024-09-25 10:58:08,592:INFO:Defining folds
2024-09-25 10:58:08,592:INFO:Declaring metric variables
2024-09-25 10:58:08,592:INFO:Importing untrained model
2024-09-25 10:58:08,592:INFO:Declaring custom model
2024-09-25 10:58:08,593:INFO:Random Forest Classifier Imported successfully
2024-09-25 10:58:08,593:INFO:Cross validation set to False
2024-09-25 10:58:08,593:INFO:Fitting Model
2024-09-25 10:58:10,753:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:58:10,753:INFO:create_model() successfully completed......................................
2024-09-25 10:58:10,861:INFO:_master_model_container: 15
2024-09-25 10:58:10,862:INFO:_display_container: 2
2024-09-25 10:58:10,862:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 10:58:10,863:INFO:compare_models() successfully completed......................................
2024-09-25 11:11:52,488:INFO:PyCaret ClassificationExperiment
2024-09-25 11:11:52,490:INFO:Logging name: clf-default-name
2024-09-25 11:11:52,490:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 11:11:52,490:INFO:version 3.3.2
2024-09-25 11:11:52,490:INFO:Initializing setup()
2024-09-25 11:11:52,490:INFO:self.USI: 99a2
2024-09-25 11:11:52,490:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 11:11:52,490:INFO:Checking environment
2024-09-25 11:11:52,490:INFO:python_version: 3.10.14
2024-09-25 11:11:52,490:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 11:11:52,490:INFO:machine: arm64
2024-09-25 11:11:52,490:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 11:11:52,491:INFO:Memory: svmem(total=8589934592, available=2333310976, percent=72.8, used=3613442048, free=44482560, active=2311864320, inactive=2287910912, wired=1301577728)
2024-09-25 11:11:52,491:INFO:Physical Core: 8
2024-09-25 11:11:52,491:INFO:Logical Core: 8
2024-09-25 11:11:52,491:INFO:Checking libraries
2024-09-25 11:11:52,491:INFO:System:
2024-09-25 11:11:52,491:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 11:11:52,491:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 11:11:52,491:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 11:11:52,492:INFO:PyCaret required dependencies:
2024-09-25 11:11:52,492:INFO:                 pip: 24.2
2024-09-25 11:11:52,492:INFO:          setuptools: 72.1.0
2024-09-25 11:11:52,492:INFO:             pycaret: 3.3.2
2024-09-25 11:11:52,492:INFO:             IPython: 8.18.1
2024-09-25 11:11:52,492:INFO:          ipywidgets: 8.1.5
2024-09-25 11:11:52,492:INFO:                tqdm: 4.66.5
2024-09-25 11:11:52,492:INFO:               numpy: 1.26.4
2024-09-25 11:11:52,492:INFO:              pandas: 2.1.4
2024-09-25 11:11:52,492:INFO:              jinja2: 3.1.4
2024-09-25 11:11:52,492:INFO:               scipy: 1.11.4
2024-09-25 11:11:52,492:INFO:              joblib: 1.3.2
2024-09-25 11:11:52,492:INFO:             sklearn: 1.4.2
2024-09-25 11:11:52,492:INFO:                pyod: 2.0.2
2024-09-25 11:11:52,492:INFO:            imblearn: 0.12.3
2024-09-25 11:11:52,492:INFO:   category_encoders: 2.6.3
2024-09-25 11:11:52,492:INFO:            lightgbm: 4.5.0
2024-09-25 11:11:52,492:INFO:               numba: 0.60.0
2024-09-25 11:11:52,492:INFO:            requests: 2.32.3
2024-09-25 11:11:52,492:INFO:          matplotlib: 3.7.5
2024-09-25 11:11:52,492:INFO:          scikitplot: 0.3.7
2024-09-25 11:11:52,492:INFO:         yellowbrick: 1.5
2024-09-25 11:11:52,492:INFO:              plotly: 5.24.0
2024-09-25 11:11:52,492:INFO:    plotly-resampler: Not installed
2024-09-25 11:11:52,493:INFO:             kaleido: 0.2.1
2024-09-25 11:11:52,493:INFO:           schemdraw: 0.15
2024-09-25 11:11:52,493:INFO:         statsmodels: 0.14.3
2024-09-25 11:11:52,493:INFO:              sktime: 0.26.0
2024-09-25 11:11:52,493:INFO:               tbats: 1.1.3
2024-09-25 11:11:52,493:INFO:            pmdarima: 2.0.4
2024-09-25 11:11:52,493:INFO:              psutil: 5.9.0
2024-09-25 11:11:52,493:INFO:          markupsafe: 2.1.3
2024-09-25 11:11:52,493:INFO:             pickle5: Not installed
2024-09-25 11:11:52,493:INFO:         cloudpickle: 3.0.0
2024-09-25 11:11:52,493:INFO:         deprecation: 2.1.0
2024-09-25 11:11:52,493:INFO:              xxhash: 3.5.0
2024-09-25 11:11:52,493:INFO:           wurlitzer: 3.1.1
2024-09-25 11:11:52,493:INFO:PyCaret optional dependencies:
2024-09-25 11:11:52,493:INFO:                shap: 0.46.0
2024-09-25 11:11:52,493:INFO:           interpret: Not installed
2024-09-25 11:11:52,493:INFO:                umap: Not installed
2024-09-25 11:11:52,493:INFO:     ydata_profiling: Not installed
2024-09-25 11:11:52,493:INFO:  explainerdashboard: Not installed
2024-09-25 11:11:52,493:INFO:             autoviz: Not installed
2024-09-25 11:11:52,493:INFO:           fairlearn: Not installed
2024-09-25 11:11:52,493:INFO:          deepchecks: Not installed
2024-09-25 11:11:52,493:INFO:             xgboost: 2.1.1
2024-09-25 11:11:52,493:INFO:            catboost: Not installed
2024-09-25 11:11:52,493:INFO:              kmodes: Not installed
2024-09-25 11:11:52,493:INFO:             mlxtend: Not installed
2024-09-25 11:11:52,493:INFO:       statsforecast: Not installed
2024-09-25 11:11:52,493:INFO:        tune_sklearn: Not installed
2024-09-25 11:11:52,493:INFO:                 ray: Not installed
2024-09-25 11:11:52,493:INFO:            hyperopt: Not installed
2024-09-25 11:11:52,493:INFO:              optuna: 4.0.0
2024-09-25 11:11:52,493:INFO:               skopt: Not installed
2024-09-25 11:11:52,493:INFO:              mlflow: Not installed
2024-09-25 11:11:52,493:INFO:              gradio: Not installed
2024-09-25 11:11:52,493:INFO:             fastapi: Not installed
2024-09-25 11:11:52,493:INFO:             uvicorn: Not installed
2024-09-25 11:11:52,493:INFO:              m2cgen: Not installed
2024-09-25 11:11:52,493:INFO:           evidently: Not installed
2024-09-25 11:11:52,494:INFO:               fugue: Not installed
2024-09-25 11:11:52,494:INFO:           streamlit: 1.38.0
2024-09-25 11:11:52,494:INFO:             prophet: Not installed
2024-09-25 11:11:52,494:INFO:None
2024-09-25 11:11:52,494:INFO:Set up data.
2024-09-25 11:11:52,515:INFO:Set up folding strategy.
2024-09-25 11:11:52,515:INFO:Set up train/test split.
2024-09-25 11:11:52,549:INFO:Set up index.
2024-09-25 11:11:52,553:INFO:Assigning column types.
2024-09-25 11:11:52,567:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 11:11:52,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,597:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,617:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,629:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,630:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 11:11:52,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,660:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,680:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:11:52,691:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,692:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 11:11:52,722:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,753:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:52,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:52,755:INFO:Preparing preprocessing pipeline...
2024-09-25 11:11:52,758:INFO:Set up label encoding.
2024-09-25 11:11:52,758:INFO:Set up simple imputation.
2024-09-25 11:11:53,114:INFO:Finished creating preprocessing pipeline.
2024-09-25 11:11:53,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 11:11:53,116:INFO:Creating final display dataframe.
2024-09-25 11:11:53,791:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 16)
5        Transformed data shape       (100000, 16)
6   Transformed train set shape        (70000, 16)
7    Transformed test set shape        (30000, 16)
8              Numeric features                 15
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               99a2
2024-09-25 11:11:53,831:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:53,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:53,865:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:11:53,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:11:53,868:INFO:setup() successfully completed in 1.38s...............
2024-09-25 11:11:53,883:INFO:Initializing compare_models()
2024-09-25 11:11:53,884:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3128913f0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3128913f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 11:11:53,884:INFO:Checking exceptions
2024-09-25 11:11:53,910:INFO:Preparing display monitor
2024-09-25 11:11:53,926:INFO:Initializing Logistic Regression
2024-09-25 11:11:53,926:INFO:Total runtime is 3.6676724751790363e-06 minutes
2024-09-25 11:11:53,928:INFO:SubProcess create_model() called ==================================
2024-09-25 11:11:53,929:INFO:Initializing create_model()
2024-09-25 11:11:53,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3128913f0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17d435540>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:11:53,929:INFO:Checking exceptions
2024-09-25 11:11:53,930:INFO:Importing libraries
2024-09-25 11:11:53,930:INFO:Copying training dataset
2024-09-25 11:11:54,025:INFO:Defining folds
2024-09-25 11:11:54,025:INFO:Declaring metric variables
2024-09-25 11:11:54,027:INFO:Importing untrained model
2024-09-25 11:11:54,029:INFO:Logistic Regression Imported successfully
2024-09-25 11:11:54,032:INFO:Starting cross validation
2024-09-25 11:11:54,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:07,036:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,056:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:07,188:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,240:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:07,326:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,353:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:07,370:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,405:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:07,407:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,437:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:07,497:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:07,530:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:09,589:INFO:PyCaret ClassificationExperiment
2024-09-25 11:12:09,590:INFO:Logging name: clf-default-name
2024-09-25 11:12:09,590:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 11:12:09,590:INFO:version 3.3.2
2024-09-25 11:12:09,590:INFO:Initializing setup()
2024-09-25 11:12:09,590:INFO:self.USI: e680
2024-09-25 11:12:09,590:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 11:12:09,590:INFO:Checking environment
2024-09-25 11:12:09,590:INFO:python_version: 3.10.14
2024-09-25 11:12:09,590:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 11:12:09,590:INFO:machine: arm64
2024-09-25 11:12:09,590:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 11:12:09,590:INFO:Memory: svmem(total=8589934592, available=2390966272, percent=72.2, used=3226779648, free=785088512, active=1622425600, inactive=1585954816, wired=1604354048)
2024-09-25 11:12:09,590:INFO:Physical Core: 8
2024-09-25 11:12:09,590:INFO:Logical Core: 8
2024-09-25 11:12:09,590:INFO:Checking libraries
2024-09-25 11:12:09,590:INFO:System:
2024-09-25 11:12:09,590:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 11:12:09,590:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 11:12:09,590:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 11:12:09,590:INFO:PyCaret required dependencies:
2024-09-25 11:12:09,590:INFO:                 pip: 24.2
2024-09-25 11:12:09,590:INFO:          setuptools: 72.1.0
2024-09-25 11:12:09,590:INFO:             pycaret: 3.3.2
2024-09-25 11:12:09,590:INFO:             IPython: 8.18.1
2024-09-25 11:12:09,590:INFO:          ipywidgets: 8.1.5
2024-09-25 11:12:09,590:INFO:                tqdm: 4.66.5
2024-09-25 11:12:09,590:INFO:               numpy: 1.26.4
2024-09-25 11:12:09,590:INFO:              pandas: 2.1.4
2024-09-25 11:12:09,590:INFO:              jinja2: 3.1.4
2024-09-25 11:12:09,590:INFO:               scipy: 1.11.4
2024-09-25 11:12:09,590:INFO:              joblib: 1.3.2
2024-09-25 11:12:09,590:INFO:             sklearn: 1.4.2
2024-09-25 11:12:09,590:INFO:                pyod: 2.0.2
2024-09-25 11:12:09,590:INFO:            imblearn: 0.12.3
2024-09-25 11:12:09,590:INFO:   category_encoders: 2.6.3
2024-09-25 11:12:09,590:INFO:            lightgbm: 4.5.0
2024-09-25 11:12:09,590:INFO:               numba: 0.60.0
2024-09-25 11:12:09,590:INFO:            requests: 2.32.3
2024-09-25 11:12:09,590:INFO:          matplotlib: 3.7.5
2024-09-25 11:12:09,590:INFO:          scikitplot: 0.3.7
2024-09-25 11:12:09,591:INFO:         yellowbrick: 1.5
2024-09-25 11:12:09,591:INFO:              plotly: 5.24.0
2024-09-25 11:12:09,591:INFO:    plotly-resampler: Not installed
2024-09-25 11:12:09,591:INFO:             kaleido: 0.2.1
2024-09-25 11:12:09,591:INFO:           schemdraw: 0.15
2024-09-25 11:12:09,591:INFO:         statsmodels: 0.14.3
2024-09-25 11:12:09,591:INFO:              sktime: 0.26.0
2024-09-25 11:12:09,591:INFO:               tbats: 1.1.3
2024-09-25 11:12:09,591:INFO:            pmdarima: 2.0.4
2024-09-25 11:12:09,591:INFO:              psutil: 5.9.0
2024-09-25 11:12:09,591:INFO:          markupsafe: 2.1.3
2024-09-25 11:12:09,591:INFO:             pickle5: Not installed
2024-09-25 11:12:09,591:INFO:         cloudpickle: 3.0.0
2024-09-25 11:12:09,591:INFO:         deprecation: 2.1.0
2024-09-25 11:12:09,591:INFO:              xxhash: 3.5.0
2024-09-25 11:12:09,591:INFO:           wurlitzer: 3.1.1
2024-09-25 11:12:09,591:INFO:PyCaret optional dependencies:
2024-09-25 11:12:09,591:INFO:                shap: 0.46.0
2024-09-25 11:12:09,591:INFO:           interpret: Not installed
2024-09-25 11:12:09,591:INFO:                umap: Not installed
2024-09-25 11:12:09,591:INFO:     ydata_profiling: Not installed
2024-09-25 11:12:09,591:INFO:  explainerdashboard: Not installed
2024-09-25 11:12:09,591:INFO:             autoviz: Not installed
2024-09-25 11:12:09,591:INFO:           fairlearn: Not installed
2024-09-25 11:12:09,591:INFO:          deepchecks: Not installed
2024-09-25 11:12:09,591:INFO:             xgboost: 2.1.1
2024-09-25 11:12:09,591:INFO:            catboost: Not installed
2024-09-25 11:12:09,591:INFO:              kmodes: Not installed
2024-09-25 11:12:09,591:INFO:             mlxtend: Not installed
2024-09-25 11:12:09,591:INFO:       statsforecast: Not installed
2024-09-25 11:12:09,591:INFO:        tune_sklearn: Not installed
2024-09-25 11:12:09,591:INFO:                 ray: Not installed
2024-09-25 11:12:09,591:INFO:            hyperopt: Not installed
2024-09-25 11:12:09,591:INFO:              optuna: 4.0.0
2024-09-25 11:12:09,591:INFO:               skopt: Not installed
2024-09-25 11:12:09,591:INFO:              mlflow: Not installed
2024-09-25 11:12:09,591:INFO:              gradio: Not installed
2024-09-25 11:12:09,591:INFO:             fastapi: Not installed
2024-09-25 11:12:09,591:INFO:             uvicorn: Not installed
2024-09-25 11:12:09,591:INFO:              m2cgen: Not installed
2024-09-25 11:12:09,591:INFO:           evidently: Not installed
2024-09-25 11:12:09,591:INFO:               fugue: Not installed
2024-09-25 11:12:09,591:INFO:           streamlit: 1.38.0
2024-09-25 11:12:09,591:INFO:             prophet: Not installed
2024-09-25 11:12:09,591:INFO:None
2024-09-25 11:12:09,591:INFO:Set up data.
2024-09-25 11:12:09,619:INFO:Set up folding strategy.
2024-09-25 11:12:09,619:INFO:Set up train/test split.
2024-09-25 11:12:09,667:INFO:Set up index.
2024-09-25 11:12:09,674:INFO:Assigning column types.
2024-09-25 11:12:09,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 11:12:09,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,735:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,788:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,791:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 11:12:09,825:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,842:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 11:12:09,879:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,880:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 11:12:09,914:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,957:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:09,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:09,960:INFO:Preparing preprocessing pipeline...
2024-09-25 11:12:09,964:INFO:Set up label encoding.
2024-09-25 11:12:09,964:INFO:Set up simple imputation.
2024-09-25 11:12:10,374:INFO:Finished creating preprocessing pipeline.
2024-09-25 11:12:10,376:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 11:12:10,376:INFO:Creating final display dataframe.
2024-09-25 11:12:11,043:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 16)
5        Transformed data shape       (100000, 16)
6   Transformed train set shape        (70000, 16)
7    Transformed test set shape        (30000, 16)
8              Numeric features                 15
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               e680
2024-09-25 11:12:11,083:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:11,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:11,118:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 11:12:11,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 11:12:11,119:INFO:setup() successfully completed in 1.53s...............
2024-09-25 11:12:11,125:INFO:Initializing compare_models()
2024-09-25 11:12:11,126:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 11:12:11,126:INFO:Checking exceptions
2024-09-25 11:12:11,186:INFO:Preparing display monitor
2024-09-25 11:12:11,199:INFO:Initializing Logistic Regression
2024-09-25 11:12:11,200:INFO:Total runtime is 3.5683314005533854e-06 minutes
2024-09-25 11:12:11,202:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:11,202:INFO:Initializing create_model()
2024-09-25 11:12:11,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:11,202:INFO:Checking exceptions
2024-09-25 11:12:11,203:INFO:Importing libraries
2024-09-25 11:12:11,203:INFO:Copying training dataset
2024-09-25 11:12:11,250:INFO:Defining folds
2024-09-25 11:12:11,250:INFO:Declaring metric variables
2024-09-25 11:12:11,252:INFO:Importing untrained model
2024-09-25 11:12:11,254:INFO:Logistic Regression Imported successfully
2024-09-25 11:12:11,257:INFO:Starting cross validation
2024-09-25 11:12:11,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:24,678:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:24,706:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:24,755:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:24,790:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:24,801:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:24,825:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:25,005:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:25,037:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:25,042:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:25,072:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:25,084:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:25,115:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:25,293:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:25,315:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:25,355:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:25,382:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:30,124:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:30,134:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:30,233:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 11:12:30,240:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:30,258:INFO:Calculating mean and std
2024-09-25 11:12:30,262:INFO:Creating metrics dataframe
2024-09-25 11:12:30,266:INFO:Uploading results into container
2024-09-25 11:12:30,267:INFO:Uploading model into container now
2024-09-25 11:12:30,269:INFO:_master_model_container: 1
2024-09-25 11:12:30,269:INFO:_display_container: 2
2024-09-25 11:12:30,270:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 11:12:30,270:INFO:create_model() successfully completed......................................
2024-09-25 11:12:30,506:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:30,506:INFO:Creating metrics dataframe
2024-09-25 11:12:30,509:INFO:Initializing K Neighbors Classifier
2024-09-25 11:12:30,509:INFO:Total runtime is 0.3218323508898417 minutes
2024-09-25 11:12:30,511:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:30,511:INFO:Initializing create_model()
2024-09-25 11:12:30,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:30,511:INFO:Checking exceptions
2024-09-25 11:12:30,511:INFO:Importing libraries
2024-09-25 11:12:30,511:INFO:Copying training dataset
2024-09-25 11:12:30,554:INFO:Defining folds
2024-09-25 11:12:30,554:INFO:Declaring metric variables
2024-09-25 11:12:30,557:INFO:Importing untrained model
2024-09-25 11:12:30,558:INFO:K Neighbors Classifier Imported successfully
2024-09-25 11:12:30,561:INFO:Starting cross validation
2024-09-25 11:12:30,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:31,406:INFO:Calculating mean and std
2024-09-25 11:12:31,407:INFO:Creating metrics dataframe
2024-09-25 11:12:31,408:INFO:Uploading results into container
2024-09-25 11:12:31,409:INFO:Uploading model into container now
2024-09-25 11:12:31,409:INFO:_master_model_container: 2
2024-09-25 11:12:31,409:INFO:_display_container: 2
2024-09-25 11:12:31,409:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 11:12:31,409:INFO:create_model() successfully completed......................................
2024-09-25 11:12:31,480:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:31,480:INFO:Creating metrics dataframe
2024-09-25 11:12:31,483:INFO:Initializing Naive Bayes
2024-09-25 11:12:31,483:INFO:Total runtime is 0.33806025187174477 minutes
2024-09-25 11:12:31,484:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:31,484:INFO:Initializing create_model()
2024-09-25 11:12:31,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:31,484:INFO:Checking exceptions
2024-09-25 11:12:31,485:INFO:Importing libraries
2024-09-25 11:12:31,485:INFO:Copying training dataset
2024-09-25 11:12:31,520:INFO:Defining folds
2024-09-25 11:12:31,520:INFO:Declaring metric variables
2024-09-25 11:12:31,522:INFO:Importing untrained model
2024-09-25 11:12:31,524:INFO:Naive Bayes Imported successfully
2024-09-25 11:12:31,527:INFO:Starting cross validation
2024-09-25 11:12:31,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:31,921:INFO:Calculating mean and std
2024-09-25 11:12:31,921:INFO:Creating metrics dataframe
2024-09-25 11:12:31,922:INFO:Uploading results into container
2024-09-25 11:12:31,923:INFO:Uploading model into container now
2024-09-25 11:12:31,923:INFO:_master_model_container: 3
2024-09-25 11:12:31,923:INFO:_display_container: 2
2024-09-25 11:12:31,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 11:12:31,923:INFO:create_model() successfully completed......................................
2024-09-25 11:12:31,994:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:31,994:INFO:Creating metrics dataframe
2024-09-25 11:12:31,998:INFO:Initializing Decision Tree Classifier
2024-09-25 11:12:31,998:INFO:Total runtime is 0.3466484189033508 minutes
2024-09-25 11:12:31,999:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:32,000:INFO:Initializing create_model()
2024-09-25 11:12:32,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:32,000:INFO:Checking exceptions
2024-09-25 11:12:32,000:INFO:Importing libraries
2024-09-25 11:12:32,000:INFO:Copying training dataset
2024-09-25 11:12:32,034:INFO:Defining folds
2024-09-25 11:12:32,034:INFO:Declaring metric variables
2024-09-25 11:12:32,036:INFO:Importing untrained model
2024-09-25 11:12:32,038:INFO:Decision Tree Classifier Imported successfully
2024-09-25 11:12:32,040:INFO:Starting cross validation
2024-09-25 11:12:32,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:33,808:INFO:Calculating mean and std
2024-09-25 11:12:33,809:INFO:Creating metrics dataframe
2024-09-25 11:12:33,813:INFO:Uploading results into container
2024-09-25 11:12:33,813:INFO:Uploading model into container now
2024-09-25 11:12:33,813:INFO:_master_model_container: 4
2024-09-25 11:12:33,813:INFO:_display_container: 2
2024-09-25 11:12:33,814:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 11:12:33,814:INFO:create_model() successfully completed......................................
2024-09-25 11:12:33,903:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:33,903:INFO:Creating metrics dataframe
2024-09-25 11:12:33,907:INFO:Initializing SVM - Linear Kernel
2024-09-25 11:12:33,907:INFO:Total runtime is 0.3784552057584126 minutes
2024-09-25 11:12:33,909:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:33,909:INFO:Initializing create_model()
2024-09-25 11:12:33,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:33,909:INFO:Checking exceptions
2024-09-25 11:12:33,909:INFO:Importing libraries
2024-09-25 11:12:33,909:INFO:Copying training dataset
2024-09-25 11:12:33,955:INFO:Defining folds
2024-09-25 11:12:33,955:INFO:Declaring metric variables
2024-09-25 11:12:33,956:INFO:Importing untrained model
2024-09-25 11:12:33,960:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 11:12:33,963:INFO:Starting cross validation
2024-09-25 11:12:33,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:41,841:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,056:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,066:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:12:42,130:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,136:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:12:42,601:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,607:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:12:42,624:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,629:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:12:42,713:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,718:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:12:42,733:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:42,885:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:44,885:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,288:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,312:INFO:Calculating mean and std
2024-09-25 11:12:45,315:INFO:Creating metrics dataframe
2024-09-25 11:12:45,318:INFO:Uploading results into container
2024-09-25 11:12:45,319:INFO:Uploading model into container now
2024-09-25 11:12:45,320:INFO:_master_model_container: 5
2024-09-25 11:12:45,320:INFO:_display_container: 2
2024-09-25 11:12:45,321:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-25 11:12:45,322:INFO:create_model() successfully completed......................................
2024-09-25 11:12:45,457:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:45,458:INFO:Creating metrics dataframe
2024-09-25 11:12:45,461:INFO:Initializing Ridge Classifier
2024-09-25 11:12:45,461:INFO:Total runtime is 0.5710318366686502 minutes
2024-09-25 11:12:45,463:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:45,463:INFO:Initializing create_model()
2024-09-25 11:12:45,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:45,463:INFO:Checking exceptions
2024-09-25 11:12:45,463:INFO:Importing libraries
2024-09-25 11:12:45,463:INFO:Copying training dataset
2024-09-25 11:12:45,510:INFO:Defining folds
2024-09-25 11:12:45,511:INFO:Declaring metric variables
2024-09-25 11:12:45,515:INFO:Importing untrained model
2024-09-25 11:12:45,518:INFO:Ridge Classifier Imported successfully
2024-09-25 11:12:45,521:INFO:Starting cross validation
2024-09-25 11:12:45,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:12:45,648:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.22695e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,663:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,688:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.41175e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,708:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,764:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.26595e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,773:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,816:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.22647e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,829:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,872:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.43072e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,883:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,914:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.40118e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,926:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:45,973:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.43746e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:45,984:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:46,036:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.3656e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:46,048:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:46,071:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.16655e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:46,080:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:46,117:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.31361e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 11:12:46,125:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:12:46,139:INFO:Calculating mean and std
2024-09-25 11:12:46,139:INFO:Creating metrics dataframe
2024-09-25 11:12:46,141:INFO:Uploading results into container
2024-09-25 11:12:46,141:INFO:Uploading model into container now
2024-09-25 11:12:46,142:INFO:_master_model_container: 6
2024-09-25 11:12:46,142:INFO:_display_container: 2
2024-09-25 11:12:46,142:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-25 11:12:46,142:INFO:create_model() successfully completed......................................
2024-09-25 11:12:46,250:INFO:SubProcess create_model() end ==================================
2024-09-25 11:12:46,250:INFO:Creating metrics dataframe
2024-09-25 11:12:46,254:INFO:Initializing Random Forest Classifier
2024-09-25 11:12:46,255:INFO:Total runtime is 0.5842539032300312 minutes
2024-09-25 11:12:46,258:INFO:SubProcess create_model() called ==================================
2024-09-25 11:12:46,259:INFO:Initializing create_model()
2024-09-25 11:12:46,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:12:46,259:INFO:Checking exceptions
2024-09-25 11:12:46,259:INFO:Importing libraries
2024-09-25 11:12:46,260:INFO:Copying training dataset
2024-09-25 11:12:46,323:INFO:Defining folds
2024-09-25 11:12:46,323:INFO:Declaring metric variables
2024-09-25 11:12:46,326:INFO:Importing untrained model
2024-09-25 11:12:46,329:INFO:Random Forest Classifier Imported successfully
2024-09-25 11:12:46,332:INFO:Starting cross validation
2024-09-25 11:12:46,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:13:09,267:INFO:Calculating mean and std
2024-09-25 11:13:09,272:INFO:Creating metrics dataframe
2024-09-25 11:13:09,281:INFO:Uploading results into container
2024-09-25 11:13:09,282:INFO:Uploading model into container now
2024-09-25 11:13:09,283:INFO:_master_model_container: 7
2024-09-25 11:13:09,283:INFO:_display_container: 2
2024-09-25 11:13:09,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 11:13:09,285:INFO:create_model() successfully completed......................................
2024-09-25 11:13:09,497:INFO:SubProcess create_model() end ==================================
2024-09-25 11:13:09,498:INFO:Creating metrics dataframe
2024-09-25 11:13:09,503:INFO:Initializing Quadratic Discriminant Analysis
2024-09-25 11:13:09,503:INFO:Total runtime is 0.9717275818188984 minutes
2024-09-25 11:13:09,506:INFO:SubProcess create_model() called ==================================
2024-09-25 11:13:09,507:INFO:Initializing create_model()
2024-09-25 11:13:09,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:13:09,507:INFO:Checking exceptions
2024-09-25 11:13:09,507:INFO:Importing libraries
2024-09-25 11:13:09,507:INFO:Copying training dataset
2024-09-25 11:13:09,575:INFO:Defining folds
2024-09-25 11:13:09,575:INFO:Declaring metric variables
2024-09-25 11:13:09,578:INFO:Importing untrained model
2024-09-25 11:13:09,581:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-25 11:13:09,587:INFO:Starting cross validation
2024-09-25 11:13:09,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:13:09,799:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:09,889:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:09,947:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,001:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,063:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,109:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,187:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,230:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,299:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,362:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:10,383:INFO:Calculating mean and std
2024-09-25 11:13:10,384:INFO:Creating metrics dataframe
2024-09-25 11:13:10,385:INFO:Uploading results into container
2024-09-25 11:13:10,386:INFO:Uploading model into container now
2024-09-25 11:13:10,386:INFO:_master_model_container: 8
2024-09-25 11:13:10,386:INFO:_display_container: 2
2024-09-25 11:13:10,386:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-25 11:13:10,387:INFO:create_model() successfully completed......................................
2024-09-25 11:13:10,467:INFO:SubProcess create_model() end ==================================
2024-09-25 11:13:10,467:INFO:Creating metrics dataframe
2024-09-25 11:13:10,471:INFO:Initializing Ada Boost Classifier
2024-09-25 11:13:10,471:INFO:Total runtime is 0.9878537694613138 minutes
2024-09-25 11:13:10,472:INFO:SubProcess create_model() called ==================================
2024-09-25 11:13:10,472:INFO:Initializing create_model()
2024-09-25 11:13:10,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:13:10,472:INFO:Checking exceptions
2024-09-25 11:13:10,473:INFO:Importing libraries
2024-09-25 11:13:10,473:INFO:Copying training dataset
2024-09-25 11:13:10,507:INFO:Defining folds
2024-09-25 11:13:10,507:INFO:Declaring metric variables
2024-09-25 11:13:10,509:INFO:Importing untrained model
2024-09-25 11:13:10,511:INFO:Ada Boost Classifier Imported successfully
2024-09-25 11:13:10,514:INFO:Starting cross validation
2024-09-25 11:13:10,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:13:10,582:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,610:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,663:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,707:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,741:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,822:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,878:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:10,936:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:15,110:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,204:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,226:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:15,264:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,323:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 11:13:15,476:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,506:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,685:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,726:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:15,762:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:17,711:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:17,758:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:13:17,780:INFO:Calculating mean and std
2024-09-25 11:13:17,781:INFO:Creating metrics dataframe
2024-09-25 11:13:17,782:INFO:Uploading results into container
2024-09-25 11:13:17,783:INFO:Uploading model into container now
2024-09-25 11:13:17,783:INFO:_master_model_container: 9
2024-09-25 11:13:17,783:INFO:_display_container: 2
2024-09-25 11:13:17,783:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-25 11:13:17,783:INFO:create_model() successfully completed......................................
2024-09-25 11:13:17,870:INFO:SubProcess create_model() end ==================================
2024-09-25 11:13:17,870:INFO:Creating metrics dataframe
2024-09-25 11:13:17,875:INFO:Initializing Gradient Boosting Classifier
2024-09-25 11:13:17,875:INFO:Total runtime is 1.1112538695335388 minutes
2024-09-25 11:13:17,876:INFO:SubProcess create_model() called ==================================
2024-09-25 11:13:17,876:INFO:Initializing create_model()
2024-09-25 11:13:17,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:13:17,877:INFO:Checking exceptions
2024-09-25 11:13:17,877:INFO:Importing libraries
2024-09-25 11:13:17,877:INFO:Copying training dataset
2024-09-25 11:13:17,920:INFO:Defining folds
2024-09-25 11:13:17,920:INFO:Declaring metric variables
2024-09-25 11:13:17,922:INFO:Importing untrained model
2024-09-25 11:13:17,924:INFO:Gradient Boosting Classifier Imported successfully
2024-09-25 11:13:17,927:INFO:Starting cross validation
2024-09-25 11:13:17,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:14:22,499:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,047:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,095:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,151:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,214:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,237:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,249:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:23,267:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:53,664:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,021:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,036:INFO:Calculating mean and std
2024-09-25 11:14:54,038:INFO:Creating metrics dataframe
2024-09-25 11:14:54,040:INFO:Uploading results into container
2024-09-25 11:14:54,040:INFO:Uploading model into container now
2024-09-25 11:14:54,041:INFO:_master_model_container: 10
2024-09-25 11:14:54,041:INFO:_display_container: 2
2024-09-25 11:14:54,041:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-25 11:14:54,042:INFO:create_model() successfully completed......................................
2024-09-25 11:14:54,163:INFO:SubProcess create_model() end ==================================
2024-09-25 11:14:54,163:INFO:Creating metrics dataframe
2024-09-25 11:14:54,168:INFO:Initializing Linear Discriminant Analysis
2024-09-25 11:14:54,168:INFO:Total runtime is 2.7161466002464296 minutes
2024-09-25 11:14:54,170:INFO:SubProcess create_model() called ==================================
2024-09-25 11:14:54,170:INFO:Initializing create_model()
2024-09-25 11:14:54,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:14:54,171:INFO:Checking exceptions
2024-09-25 11:14:54,171:INFO:Importing libraries
2024-09-25 11:14:54,171:INFO:Copying training dataset
2024-09-25 11:14:54,209:INFO:Defining folds
2024-09-25 11:14:54,209:INFO:Declaring metric variables
2024-09-25 11:14:54,212:INFO:Importing untrained model
2024-09-25 11:14:54,213:INFO:Linear Discriminant Analysis Imported successfully
2024-09-25 11:14:54,216:INFO:Starting cross validation
2024-09-25 11:14:54,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:14:54,340:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,364:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,402:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,422:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,474:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,500:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,542:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,590:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,632:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,664:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 11:14:54,686:INFO:Calculating mean and std
2024-09-25 11:14:54,687:INFO:Creating metrics dataframe
2024-09-25 11:14:54,688:INFO:Uploading results into container
2024-09-25 11:14:54,688:INFO:Uploading model into container now
2024-09-25 11:14:54,689:INFO:_master_model_container: 11
2024-09-25 11:14:54,689:INFO:_display_container: 2
2024-09-25 11:14:54,689:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-25 11:14:54,690:INFO:create_model() successfully completed......................................
2024-09-25 11:14:54,760:INFO:SubProcess create_model() end ==================================
2024-09-25 11:14:54,760:INFO:Creating metrics dataframe
2024-09-25 11:14:54,764:INFO:Initializing Extra Trees Classifier
2024-09-25 11:14:54,764:INFO:Total runtime is 2.726076153914134 minutes
2024-09-25 11:14:54,765:INFO:SubProcess create_model() called ==================================
2024-09-25 11:14:54,765:INFO:Initializing create_model()
2024-09-25 11:14:54,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:14:54,765:INFO:Checking exceptions
2024-09-25 11:14:54,765:INFO:Importing libraries
2024-09-25 11:14:54,766:INFO:Copying training dataset
2024-09-25 11:14:54,800:INFO:Defining folds
2024-09-25 11:14:54,800:INFO:Declaring metric variables
2024-09-25 11:14:54,802:INFO:Importing untrained model
2024-09-25 11:14:54,804:INFO:Extra Trees Classifier Imported successfully
2024-09-25 11:14:54,806:INFO:Starting cross validation
2024-09-25 11:14:54,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:15:07,431:INFO:Calculating mean and std
2024-09-25 11:15:07,434:INFO:Creating metrics dataframe
2024-09-25 11:15:07,439:INFO:Uploading results into container
2024-09-25 11:15:07,439:INFO:Uploading model into container now
2024-09-25 11:15:07,440:INFO:_master_model_container: 12
2024-09-25 11:15:07,440:INFO:_display_container: 2
2024-09-25 11:15:07,443:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-25 11:15:07,443:INFO:create_model() successfully completed......................................
2024-09-25 11:15:07,585:INFO:SubProcess create_model() end ==================================
2024-09-25 11:15:07,585:INFO:Creating metrics dataframe
2024-09-25 11:15:07,591:INFO:Initializing Extreme Gradient Boosting
2024-09-25 11:15:07,591:INFO:Total runtime is 2.9398671189943952 minutes
2024-09-25 11:15:07,594:INFO:SubProcess create_model() called ==================================
2024-09-25 11:15:07,594:INFO:Initializing create_model()
2024-09-25 11:15:07,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:15:07,594:INFO:Checking exceptions
2024-09-25 11:15:07,594:INFO:Importing libraries
2024-09-25 11:15:07,595:INFO:Copying training dataset
2024-09-25 11:15:07,658:INFO:Defining folds
2024-09-25 11:15:07,658:INFO:Declaring metric variables
2024-09-25 11:15:07,660:INFO:Importing untrained model
2024-09-25 11:15:07,664:INFO:Extreme Gradient Boosting Imported successfully
2024-09-25 11:15:07,667:INFO:Starting cross validation
2024-09-25 11:15:07,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:15:08,163:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-25 11:15:14,038:INFO:Calculating mean and std
2024-09-25 11:15:14,041:INFO:Creating metrics dataframe
2024-09-25 11:15:14,045:INFO:Uploading results into container
2024-09-25 11:15:14,046:INFO:Uploading model into container now
2024-09-25 11:15:14,047:INFO:_master_model_container: 13
2024-09-25 11:15:14,047:INFO:_display_container: 2
2024-09-25 11:15:14,049:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-25 11:15:14,049:INFO:create_model() successfully completed......................................
2024-09-25 11:15:14,183:INFO:SubProcess create_model() end ==================================
2024-09-25 11:15:14,183:INFO:Creating metrics dataframe
2024-09-25 11:15:14,194:INFO:Initializing Light Gradient Boosting Machine
2024-09-25 11:15:14,194:INFO:Total runtime is 3.0499155680338546 minutes
2024-09-25 11:15:14,200:INFO:SubProcess create_model() called ==================================
2024-09-25 11:15:14,200:INFO:Initializing create_model()
2024-09-25 11:15:14,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:15:14,200:INFO:Checking exceptions
2024-09-25 11:15:14,200:INFO:Importing libraries
2024-09-25 11:15:14,200:INFO:Copying training dataset
2024-09-25 11:15:14,336:INFO:Defining folds
2024-09-25 11:15:14,337:INFO:Declaring metric variables
2024-09-25 11:15:14,341:INFO:Importing untrained model
2024-09-25 11:15:14,345:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-25 11:15:14,355:INFO:Starting cross validation
2024-09-25 11:15:14,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:15:32,158:INFO:Calculating mean and std
2024-09-25 11:15:32,160:INFO:Creating metrics dataframe
2024-09-25 11:15:32,162:INFO:Uploading results into container
2024-09-25 11:15:32,162:INFO:Uploading model into container now
2024-09-25 11:15:32,163:INFO:_master_model_container: 14
2024-09-25 11:15:32,163:INFO:_display_container: 2
2024-09-25 11:15:32,163:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-25 11:15:32,163:INFO:create_model() successfully completed......................................
2024-09-25 11:15:32,252:INFO:SubProcess create_model() end ==================================
2024-09-25 11:15:32,252:INFO:Creating metrics dataframe
2024-09-25 11:15:32,259:INFO:Initializing Dummy Classifier
2024-09-25 11:15:32,259:INFO:Total runtime is 3.350990454355876 minutes
2024-09-25 11:15:32,262:INFO:SubProcess create_model() called ==================================
2024-09-25 11:15:32,262:INFO:Initializing create_model()
2024-09-25 11:15:32,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156cf5c90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:15:32,262:INFO:Checking exceptions
2024-09-25 11:15:32,262:INFO:Importing libraries
2024-09-25 11:15:32,262:INFO:Copying training dataset
2024-09-25 11:15:32,333:INFO:Defining folds
2024-09-25 11:15:32,333:INFO:Declaring metric variables
2024-09-25 11:15:32,335:INFO:Importing untrained model
2024-09-25 11:15:32,337:INFO:Dummy Classifier Imported successfully
2024-09-25 11:15:32,342:INFO:Starting cross validation
2024-09-25 11:15:32,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 11:15:32,437:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,465:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,504:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,535:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,566:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,598:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,629:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,664:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,691:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,713:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 11:15:32,729:INFO:Calculating mean and std
2024-09-25 11:15:32,730:INFO:Creating metrics dataframe
2024-09-25 11:15:32,731:INFO:Uploading results into container
2024-09-25 11:15:32,731:INFO:Uploading model into container now
2024-09-25 11:15:32,731:INFO:_master_model_container: 15
2024-09-25 11:15:32,731:INFO:_display_container: 2
2024-09-25 11:15:32,731:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-25 11:15:32,731:INFO:create_model() successfully completed......................................
2024-09-25 11:15:32,801:INFO:SubProcess create_model() end ==================================
2024-09-25 11:15:32,801:INFO:Creating metrics dataframe
2024-09-25 11:15:32,807:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-25 11:15:32,811:INFO:Initializing create_model()
2024-09-25 11:15:32,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156cf5c00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 11:15:32,811:INFO:Checking exceptions
2024-09-25 11:15:32,812:INFO:Importing libraries
2024-09-25 11:15:32,812:INFO:Copying training dataset
2024-09-25 11:15:32,848:INFO:Defining folds
2024-09-25 11:15:32,849:INFO:Declaring metric variables
2024-09-25 11:15:32,849:INFO:Importing untrained model
2024-09-25 11:15:32,849:INFO:Declaring custom model
2024-09-25 11:15:32,849:INFO:Random Forest Classifier Imported successfully
2024-09-25 11:15:32,849:INFO:Cross validation set to False
2024-09-25 11:15:32,849:INFO:Fitting Model
2024-09-25 11:15:35,249:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 11:15:35,249:INFO:create_model() successfully completed......................................
2024-09-25 11:15:35,361:INFO:_master_model_container: 15
2024-09-25 11:15:35,361:INFO:_display_container: 2
2024-09-25 11:15:35,362:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 11:15:35,362:INFO:compare_models() successfully completed......................................
2024-09-25 14:04:07,691:INFO:PyCaret ClassificationExperiment
2024-09-25 14:04:07,695:INFO:Logging name: clf-default-name
2024-09-25 14:04:07,695:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 14:04:07,695:INFO:version 3.3.2
2024-09-25 14:04:07,695:INFO:Initializing setup()
2024-09-25 14:04:07,695:INFO:self.USI: 0443
2024-09-25 14:04:07,695:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 14:04:07,695:INFO:Checking environment
2024-09-25 14:04:07,695:INFO:python_version: 3.10.14
2024-09-25 14:04:07,695:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 14:04:07,695:INFO:machine: arm64
2024-09-25 14:04:07,695:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 14:04:07,696:INFO:Memory: svmem(total=8589934592, available=1446395904, percent=83.2, used=2859302912, free=36306944, active=1419051008, inactive=1397473280, wired=1440251904)
2024-09-25 14:04:07,696:INFO:Physical Core: 8
2024-09-25 14:04:07,696:INFO:Logical Core: 8
2024-09-25 14:04:07,696:INFO:Checking libraries
2024-09-25 14:04:07,696:INFO:System:
2024-09-25 14:04:07,696:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 14:04:07,696:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 14:04:07,696:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 14:04:07,696:INFO:PyCaret required dependencies:
2024-09-25 14:04:07,697:INFO:                 pip: 24.2
2024-09-25 14:04:07,697:INFO:          setuptools: 72.1.0
2024-09-25 14:04:07,697:INFO:             pycaret: 3.3.2
2024-09-25 14:04:07,698:INFO:             IPython: 8.18.1
2024-09-25 14:04:07,698:INFO:          ipywidgets: 8.1.5
2024-09-25 14:04:07,698:INFO:                tqdm: 4.66.5
2024-09-25 14:04:07,698:INFO:               numpy: 1.26.4
2024-09-25 14:04:07,698:INFO:              pandas: 2.1.4
2024-09-25 14:04:07,698:INFO:              jinja2: 3.1.4
2024-09-25 14:04:07,698:INFO:               scipy: 1.11.4
2024-09-25 14:04:07,699:INFO:              joblib: 1.3.2
2024-09-25 14:04:07,699:INFO:             sklearn: 1.4.2
2024-09-25 14:04:07,699:INFO:                pyod: 2.0.2
2024-09-25 14:04:07,699:INFO:            imblearn: 0.12.3
2024-09-25 14:04:07,699:INFO:   category_encoders: 2.6.3
2024-09-25 14:04:07,699:INFO:            lightgbm: 4.5.0
2024-09-25 14:04:07,699:INFO:               numba: 0.60.0
2024-09-25 14:04:07,699:INFO:            requests: 2.32.3
2024-09-25 14:04:07,699:INFO:          matplotlib: 3.7.5
2024-09-25 14:04:07,699:INFO:          scikitplot: 0.3.7
2024-09-25 14:04:07,699:INFO:         yellowbrick: 1.5
2024-09-25 14:04:07,699:INFO:              plotly: 5.24.0
2024-09-25 14:04:07,699:INFO:    plotly-resampler: Not installed
2024-09-25 14:04:07,699:INFO:             kaleido: 0.2.1
2024-09-25 14:04:07,699:INFO:           schemdraw: 0.15
2024-09-25 14:04:07,699:INFO:         statsmodels: 0.14.3
2024-09-25 14:04:07,699:INFO:              sktime: 0.26.0
2024-09-25 14:04:07,699:INFO:               tbats: 1.1.3
2024-09-25 14:04:07,700:INFO:            pmdarima: 2.0.4
2024-09-25 14:04:07,700:INFO:              psutil: 5.9.0
2024-09-25 14:04:07,700:INFO:          markupsafe: 2.1.3
2024-09-25 14:04:07,700:INFO:             pickle5: Not installed
2024-09-25 14:04:07,700:INFO:         cloudpickle: 3.0.0
2024-09-25 14:04:07,700:INFO:         deprecation: 2.1.0
2024-09-25 14:04:07,700:INFO:              xxhash: 3.5.0
2024-09-25 14:04:07,700:INFO:           wurlitzer: 3.1.1
2024-09-25 14:04:07,700:INFO:PyCaret optional dependencies:
2024-09-25 14:04:07,700:INFO:                shap: 0.46.0
2024-09-25 14:04:07,700:INFO:           interpret: Not installed
2024-09-25 14:04:07,700:INFO:                umap: Not installed
2024-09-25 14:04:07,700:INFO:     ydata_profiling: Not installed
2024-09-25 14:04:07,700:INFO:  explainerdashboard: Not installed
2024-09-25 14:04:07,700:INFO:             autoviz: Not installed
2024-09-25 14:04:07,700:INFO:           fairlearn: Not installed
2024-09-25 14:04:07,700:INFO:          deepchecks: Not installed
2024-09-25 14:04:07,701:INFO:             xgboost: 2.1.1
2024-09-25 14:04:07,701:INFO:            catboost: Not installed
2024-09-25 14:04:07,701:INFO:              kmodes: Not installed
2024-09-25 14:04:07,701:INFO:             mlxtend: Not installed
2024-09-25 14:04:07,701:INFO:       statsforecast: Not installed
2024-09-25 14:04:07,701:INFO:        tune_sklearn: Not installed
2024-09-25 14:04:07,701:INFO:                 ray: Not installed
2024-09-25 14:04:07,701:INFO:            hyperopt: Not installed
2024-09-25 14:04:07,701:INFO:              optuna: 4.0.0
2024-09-25 14:04:07,701:INFO:               skopt: Not installed
2024-09-25 14:04:07,701:INFO:              mlflow: Not installed
2024-09-25 14:04:07,701:INFO:              gradio: Not installed
2024-09-25 14:04:07,701:INFO:             fastapi: Not installed
2024-09-25 14:04:07,701:INFO:             uvicorn: Not installed
2024-09-25 14:04:07,701:INFO:              m2cgen: Not installed
2024-09-25 14:04:07,701:INFO:           evidently: Not installed
2024-09-25 14:04:07,701:INFO:               fugue: Not installed
2024-09-25 14:04:07,701:INFO:           streamlit: 1.38.0
2024-09-25 14:04:07,701:INFO:             prophet: Not installed
2024-09-25 14:04:07,702:INFO:None
2024-09-25 14:04:07,702:INFO:Set up data.
2024-09-25 14:04:07,739:INFO:Set up folding strategy.
2024-09-25 14:04:07,739:INFO:Set up train/test split.
2024-09-25 14:04:07,780:INFO:Set up index.
2024-09-25 14:04:07,786:INFO:Assigning column types.
2024-09-25 14:04:07,812:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 14:04:07,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,834:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,847:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:07,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:07,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,882:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:07,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:07,884:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 14:04:07,907:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,923:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:07,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:07,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:07,964:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:07,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:08,041:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 14:04:08,073:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:08,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:08,106:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:08,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:08,112:INFO:Preparing preprocessing pipeline...
2024-09-25 14:04:08,118:INFO:Set up label encoding.
2024-09-25 14:04:08,118:INFO:Set up simple imputation.
2024-09-25 14:04:08,544:INFO:Finished creating preprocessing pipeline.
2024-09-25 14:04:08,546:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 14:04:08,546:INFO:Creating final display dataframe.
2024-09-25 14:04:09,514:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 13)
5        Transformed data shape       (100000, 13)
6   Transformed train set shape        (70000, 13)
7    Transformed test set shape        (30000, 13)
8              Numeric features                 12
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               0443
2024-09-25 14:04:09,554:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:09,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:09,589:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:09,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:09,591:INFO:setup() successfully completed in 1.91s...............
2024-09-25 14:04:09,604:INFO:Initializing compare_models()
2024-09-25 14:04:09,605:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 14:04:09,605:INFO:Checking exceptions
2024-09-25 14:04:09,632:INFO:Preparing display monitor
2024-09-25 14:04:09,647:INFO:Initializing Logistic Regression
2024-09-25 14:04:09,647:INFO:Total runtime is 1.7801920572916667e-06 minutes
2024-09-25 14:04:09,650:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:09,650:INFO:Initializing create_model()
2024-09-25 14:04:09,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156c4b6a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:09,650:INFO:Checking exceptions
2024-09-25 14:04:09,650:INFO:Importing libraries
2024-09-25 14:04:09,650:INFO:Copying training dataset
2024-09-25 14:04:09,699:INFO:Defining folds
2024-09-25 14:04:09,699:INFO:Declaring metric variables
2024-09-25 14:04:09,702:INFO:Importing untrained model
2024-09-25 14:04:09,704:INFO:Logistic Regression Imported successfully
2024-09-25 14:04:09,708:INFO:Starting cross validation
2024-09-25 14:04:09,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:21,805:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:21,839:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:21,948:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:21,986:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,097:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,097:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,133:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,137:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,180:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,223:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,239:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,284:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,400:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,406:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:22,427:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:22,431:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:26,904:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:26,934:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:26,964:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:26,982:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:27,006:INFO:Calculating mean and std
2024-09-25 14:04:27,008:INFO:Creating metrics dataframe
2024-09-25 14:04:27,013:INFO:Uploading results into container
2024-09-25 14:04:27,014:INFO:Uploading model into container now
2024-09-25 14:04:27,015:INFO:_master_model_container: 1
2024-09-25 14:04:27,015:INFO:_display_container: 2
2024-09-25 14:04:27,017:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 14:04:27,017:INFO:create_model() successfully completed......................................
2024-09-25 14:04:27,200:INFO:SubProcess create_model() end ==================================
2024-09-25 14:04:27,200:INFO:Creating metrics dataframe
2024-09-25 14:04:27,205:INFO:Initializing K Neighbors Classifier
2024-09-25 14:04:27,205:INFO:Total runtime is 0.2926256974538167 minutes
2024-09-25 14:04:27,207:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:27,207:INFO:Initializing create_model()
2024-09-25 14:04:27,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156c4b6a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:27,208:INFO:Checking exceptions
2024-09-25 14:04:27,208:INFO:Importing libraries
2024-09-25 14:04:27,208:INFO:Copying training dataset
2024-09-25 14:04:27,257:INFO:Defining folds
2024-09-25 14:04:27,257:INFO:Declaring metric variables
2024-09-25 14:04:27,259:INFO:Importing untrained model
2024-09-25 14:04:27,261:INFO:K Neighbors Classifier Imported successfully
2024-09-25 14:04:27,264:INFO:Starting cross validation
2024-09-25 14:04:27,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:28,216:INFO:Calculating mean and std
2024-09-25 14:04:28,218:INFO:Creating metrics dataframe
2024-09-25 14:04:28,221:INFO:Uploading results into container
2024-09-25 14:04:28,221:INFO:Uploading model into container now
2024-09-25 14:04:28,222:INFO:_master_model_container: 2
2024-09-25 14:04:28,223:INFO:_display_container: 2
2024-09-25 14:04:28,223:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 14:04:28,223:INFO:create_model() successfully completed......................................
2024-09-25 14:04:28,335:INFO:SubProcess create_model() end ==================================
2024-09-25 14:04:28,336:INFO:Creating metrics dataframe
2024-09-25 14:04:28,339:INFO:Initializing Naive Bayes
2024-09-25 14:04:28,339:INFO:Total runtime is 0.3115298628807068 minutes
2024-09-25 14:04:28,341:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:28,341:INFO:Initializing create_model()
2024-09-25 14:04:28,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156c4b6a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:28,341:INFO:Checking exceptions
2024-09-25 14:04:28,342:INFO:Importing libraries
2024-09-25 14:04:28,342:INFO:Copying training dataset
2024-09-25 14:04:28,386:INFO:Defining folds
2024-09-25 14:04:28,386:INFO:Declaring metric variables
2024-09-25 14:04:28,388:INFO:Importing untrained model
2024-09-25 14:04:28,390:INFO:Naive Bayes Imported successfully
2024-09-25 14:04:28,393:INFO:Starting cross validation
2024-09-25 14:04:28,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:28,823:INFO:Calculating mean and std
2024-09-25 14:04:28,824:INFO:Creating metrics dataframe
2024-09-25 14:04:28,824:INFO:Uploading results into container
2024-09-25 14:04:28,825:INFO:Uploading model into container now
2024-09-25 14:04:28,825:INFO:_master_model_container: 3
2024-09-25 14:04:28,825:INFO:_display_container: 2
2024-09-25 14:04:28,825:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 14:04:28,825:INFO:create_model() successfully completed......................................
2024-09-25 14:04:28,982:INFO:SubProcess create_model() end ==================================
2024-09-25 14:04:28,982:INFO:Creating metrics dataframe
2024-09-25 14:04:28,986:INFO:Initializing Decision Tree Classifier
2024-09-25 14:04:28,986:INFO:Total runtime is 0.3223138650258382 minutes
2024-09-25 14:04:28,987:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:28,987:INFO:Initializing create_model()
2024-09-25 14:04:28,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156c4b6a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:28,988:INFO:Checking exceptions
2024-09-25 14:04:28,988:INFO:Importing libraries
2024-09-25 14:04:28,988:INFO:Copying training dataset
2024-09-25 14:04:29,027:INFO:Defining folds
2024-09-25 14:04:29,027:INFO:Declaring metric variables
2024-09-25 14:04:29,029:INFO:Importing untrained model
2024-09-25 14:04:29,031:INFO:Decision Tree Classifier Imported successfully
2024-09-25 14:04:29,035:INFO:Starting cross validation
2024-09-25 14:04:29,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:30,851:INFO:Calculating mean and std
2024-09-25 14:04:30,855:INFO:Creating metrics dataframe
2024-09-25 14:04:30,859:INFO:Uploading results into container
2024-09-25 14:04:30,859:INFO:Uploading model into container now
2024-09-25 14:04:30,860:INFO:_master_model_container: 4
2024-09-25 14:04:30,860:INFO:_display_container: 2
2024-09-25 14:04:30,860:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 14:04:30,860:INFO:create_model() successfully completed......................................
2024-09-25 14:04:31,053:INFO:SubProcess create_model() end ==================================
2024-09-25 14:04:31,053:INFO:Creating metrics dataframe
2024-09-25 14:04:31,060:INFO:Initializing SVM - Linear Kernel
2024-09-25 14:04:31,060:INFO:Total runtime is 0.35687783161799114 minutes
2024-09-25 14:04:31,062:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:31,062:INFO:Initializing create_model()
2024-09-25 14:04:31,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x156b8b490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156c4b6a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:31,063:INFO:Checking exceptions
2024-09-25 14:04:31,063:INFO:Importing libraries
2024-09-25 14:04:31,063:INFO:Copying training dataset
2024-09-25 14:04:31,122:INFO:Defining folds
2024-09-25 14:04:31,122:INFO:Declaring metric variables
2024-09-25 14:04:31,125:INFO:Importing untrained model
2024-09-25 14:04:31,142:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 14:04:31,154:INFO:Starting cross validation
2024-09-25 14:04:31,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:38,736:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:38,742:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:04:39,029:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:42,543:INFO:PyCaret ClassificationExperiment
2024-09-25 14:04:42,551:INFO:Logging name: clf-default-name
2024-09-25 14:04:42,551:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-25 14:04:42,551:INFO:version 3.3.2
2024-09-25 14:04:42,551:INFO:Initializing setup()
2024-09-25 14:04:42,551:INFO:self.USI: 1e16
2024-09-25 14:04:42,551:INFO:self._variable_keys: {'exp_name_log', 'seed', 'X_train', 'y', 'is_multiclass', 'pipeline', 'target_param', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'exp_id', 'X_test', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'logging_param', 'memory', '_available_plots', 'log_plots_param', 'X', 'gpu_param', 'html_param', 'fix_imbalance', 'data', '_ml_usecase', 'USI', 'idx', 'y_train'}
2024-09-25 14:04:42,551:INFO:Checking environment
2024-09-25 14:04:42,551:INFO:python_version: 3.10.14
2024-09-25 14:04:42,551:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-25 14:04:42,551:INFO:machine: arm64
2024-09-25 14:04:42,551:INFO:platform: macOS-15.0-arm64-arm-64bit
2024-09-25 14:04:42,551:INFO:Memory: svmem(total=8589934592, available=2115452928, percent=75.4, used=3197239296, free=376127488, active=1757822976, inactive=1716797440, wired=1439416320)
2024-09-25 14:04:42,551:INFO:Physical Core: 8
2024-09-25 14:04:42,552:INFO:Logical Core: 8
2024-09-25 14:04:42,552:INFO:Checking libraries
2024-09-25 14:04:42,552:INFO:System:
2024-09-25 14:04:42,552:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-25 14:04:42,552:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-25 14:04:42,552:INFO:   machine: macOS-15.0-arm64-arm-64bit
2024-09-25 14:04:42,552:INFO:PyCaret required dependencies:
2024-09-25 14:04:42,552:INFO:                 pip: 24.2
2024-09-25 14:04:42,552:INFO:          setuptools: 72.1.0
2024-09-25 14:04:42,552:INFO:             pycaret: 3.3.2
2024-09-25 14:04:42,552:INFO:             IPython: 8.18.1
2024-09-25 14:04:42,552:INFO:          ipywidgets: 8.1.5
2024-09-25 14:04:42,552:INFO:                tqdm: 4.66.5
2024-09-25 14:04:42,552:INFO:               numpy: 1.26.4
2024-09-25 14:04:42,552:INFO:              pandas: 2.1.4
2024-09-25 14:04:42,552:INFO:              jinja2: 3.1.4
2024-09-25 14:04:42,552:INFO:               scipy: 1.11.4
2024-09-25 14:04:42,552:INFO:              joblib: 1.3.2
2024-09-25 14:04:42,552:INFO:             sklearn: 1.4.2
2024-09-25 14:04:42,553:INFO:                pyod: 2.0.2
2024-09-25 14:04:42,553:INFO:            imblearn: 0.12.3
2024-09-25 14:04:42,553:INFO:   category_encoders: 2.6.3
2024-09-25 14:04:42,553:INFO:            lightgbm: 4.5.0
2024-09-25 14:04:42,553:INFO:               numba: 0.60.0
2024-09-25 14:04:42,553:INFO:            requests: 2.32.3
2024-09-25 14:04:42,553:INFO:          matplotlib: 3.7.5
2024-09-25 14:04:42,553:INFO:          scikitplot: 0.3.7
2024-09-25 14:04:42,553:INFO:         yellowbrick: 1.5
2024-09-25 14:04:42,553:INFO:              plotly: 5.24.0
2024-09-25 14:04:42,553:INFO:    plotly-resampler: Not installed
2024-09-25 14:04:42,553:INFO:             kaleido: 0.2.1
2024-09-25 14:04:42,553:INFO:           schemdraw: 0.15
2024-09-25 14:04:42,553:INFO:         statsmodels: 0.14.3
2024-09-25 14:04:42,553:INFO:              sktime: 0.26.0
2024-09-25 14:04:42,553:INFO:               tbats: 1.1.3
2024-09-25 14:04:42,553:INFO:            pmdarima: 2.0.4
2024-09-25 14:04:42,553:INFO:              psutil: 5.9.0
2024-09-25 14:04:42,553:INFO:          markupsafe: 2.1.3
2024-09-25 14:04:42,553:INFO:             pickle5: Not installed
2024-09-25 14:04:42,553:INFO:         cloudpickle: 3.0.0
2024-09-25 14:04:42,553:INFO:         deprecation: 2.1.0
2024-09-25 14:04:42,553:INFO:              xxhash: 3.5.0
2024-09-25 14:04:42,553:INFO:           wurlitzer: 3.1.1
2024-09-25 14:04:42,553:INFO:PyCaret optional dependencies:
2024-09-25 14:04:42,553:INFO:                shap: 0.46.0
2024-09-25 14:04:42,553:INFO:           interpret: Not installed
2024-09-25 14:04:42,553:INFO:                umap: Not installed
2024-09-25 14:04:42,553:INFO:     ydata_profiling: Not installed
2024-09-25 14:04:42,553:INFO:  explainerdashboard: Not installed
2024-09-25 14:04:42,553:INFO:             autoviz: Not installed
2024-09-25 14:04:42,553:INFO:           fairlearn: Not installed
2024-09-25 14:04:42,553:INFO:          deepchecks: Not installed
2024-09-25 14:04:42,553:INFO:             xgboost: 2.1.1
2024-09-25 14:04:42,553:INFO:            catboost: Not installed
2024-09-25 14:04:42,553:INFO:              kmodes: Not installed
2024-09-25 14:04:42,553:INFO:             mlxtend: Not installed
2024-09-25 14:04:42,553:INFO:       statsforecast: Not installed
2024-09-25 14:04:42,553:INFO:        tune_sklearn: Not installed
2024-09-25 14:04:42,553:INFO:                 ray: Not installed
2024-09-25 14:04:42,553:INFO:            hyperopt: Not installed
2024-09-25 14:04:42,553:INFO:              optuna: 4.0.0
2024-09-25 14:04:42,553:INFO:               skopt: Not installed
2024-09-25 14:04:42,553:INFO:              mlflow: Not installed
2024-09-25 14:04:42,553:INFO:              gradio: Not installed
2024-09-25 14:04:42,553:INFO:             fastapi: Not installed
2024-09-25 14:04:42,553:INFO:             uvicorn: Not installed
2024-09-25 14:04:42,553:INFO:              m2cgen: Not installed
2024-09-25 14:04:42,553:INFO:           evidently: Not installed
2024-09-25 14:04:42,553:INFO:               fugue: Not installed
2024-09-25 14:04:42,553:INFO:           streamlit: 1.38.0
2024-09-25 14:04:42,553:INFO:             prophet: Not installed
2024-09-25 14:04:42,553:INFO:None
2024-09-25 14:04:42,553:INFO:Set up data.
2024-09-25 14:04:42,573:INFO:Set up folding strategy.
2024-09-25 14:04:42,573:INFO:Set up train/test split.
2024-09-25 14:04:42,604:INFO:Set up index.
2024-09-25 14:04:42,608:INFO:Assigning column types.
2024-09-25 14:04:42,619:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-25 14:04:42,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,638:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,650:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,681:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,682:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-25 14:04:42,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,712:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,732:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-25 14:04:42,743:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,744:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-25 14:04:42,774:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,805:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:42,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:42,807:INFO:Preparing preprocessing pipeline...
2024-09-25 14:04:42,809:INFO:Set up label encoding.
2024-09-25 14:04:42,809:INFO:Set up simple imputation.
2024-09-25 14:04:43,107:INFO:Finished creating preprocessing pipeline.
2024-09-25 14:04:43,109:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-09-25 14:04:43,109:INFO:Creating final display dataframe.
2024-09-25 14:04:43,553:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 13)
5        Transformed data shape       (100000, 13)
6   Transformed train set shape        (70000, 13)
7    Transformed test set shape        (30000, 13)
8              Numeric features                 12
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               1e16
2024-09-25 14:04:43,590:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:43,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:43,625:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-25 14:04:43,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-25 14:04:43,627:INFO:setup() successfully completed in 1.09s...............
2024-09-25 14:04:43,656:INFO:Initializing compare_models()
2024-09-25 14:04:43,656:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-25 14:04:43,656:INFO:Checking exceptions
2024-09-25 14:04:43,724:INFO:Preparing display monitor
2024-09-25 14:04:43,736:INFO:Initializing Logistic Regression
2024-09-25 14:04:43,736:INFO:Total runtime is 2.467632293701172e-06 minutes
2024-09-25 14:04:43,738:INFO:SubProcess create_model() called ==================================
2024-09-25 14:04:43,738:INFO:Initializing create_model()
2024-09-25 14:04:43,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:04:43,739:INFO:Checking exceptions
2024-09-25 14:04:43,739:INFO:Importing libraries
2024-09-25 14:04:43,739:INFO:Copying training dataset
2024-09-25 14:04:43,777:INFO:Defining folds
2024-09-25 14:04:43,777:INFO:Declaring metric variables
2024-09-25 14:04:43,778:INFO:Importing untrained model
2024-09-25 14:04:43,780:INFO:Logistic Regression Imported successfully
2024-09-25 14:04:43,783:INFO:Starting cross validation
2024-09-25 14:04:43,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:04:56,941:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:56,986:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,261:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,282:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,297:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,342:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,424:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,439:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,465:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,499:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,499:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,534:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,557:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,596:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:04:57,620:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:04:57,652:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:02,495:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:05:02,517:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:02,635:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-25 14:05:02,650:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:02,679:INFO:Calculating mean and std
2024-09-25 14:05:02,685:INFO:Creating metrics dataframe
2024-09-25 14:05:02,690:INFO:Uploading results into container
2024-09-25 14:05:02,690:INFO:Uploading model into container now
2024-09-25 14:05:02,691:INFO:_master_model_container: 1
2024-09-25 14:05:02,691:INFO:_display_container: 2
2024-09-25 14:05:02,692:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-25 14:05:02,693:INFO:create_model() successfully completed......................................
2024-09-25 14:05:02,890:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:02,890:INFO:Creating metrics dataframe
2024-09-25 14:05:02,893:INFO:Initializing K Neighbors Classifier
2024-09-25 14:05:02,893:INFO:Total runtime is 0.3192823171615601 minutes
2024-09-25 14:05:02,895:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:02,895:INFO:Initializing create_model()
2024-09-25 14:05:02,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:02,895:INFO:Checking exceptions
2024-09-25 14:05:02,895:INFO:Importing libraries
2024-09-25 14:05:02,895:INFO:Copying training dataset
2024-09-25 14:05:02,941:INFO:Defining folds
2024-09-25 14:05:02,941:INFO:Declaring metric variables
2024-09-25 14:05:02,943:INFO:Importing untrained model
2024-09-25 14:05:02,945:INFO:K Neighbors Classifier Imported successfully
2024-09-25 14:05:02,949:INFO:Starting cross validation
2024-09-25 14:05:02,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:04,367:INFO:Calculating mean and std
2024-09-25 14:05:04,375:INFO:Creating metrics dataframe
2024-09-25 14:05:04,385:INFO:Uploading results into container
2024-09-25 14:05:04,387:INFO:Uploading model into container now
2024-09-25 14:05:04,389:INFO:_master_model_container: 2
2024-09-25 14:05:04,389:INFO:_display_container: 2
2024-09-25 14:05:04,390:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-25 14:05:04,390:INFO:create_model() successfully completed......................................
2024-09-25 14:05:04,620:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:04,620:INFO:Creating metrics dataframe
2024-09-25 14:05:04,624:INFO:Initializing Naive Bayes
2024-09-25 14:05:04,624:INFO:Total runtime is 0.34813236792882285 minutes
2024-09-25 14:05:04,626:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:04,626:INFO:Initializing create_model()
2024-09-25 14:05:04,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:04,627:INFO:Checking exceptions
2024-09-25 14:05:04,627:INFO:Importing libraries
2024-09-25 14:05:04,627:INFO:Copying training dataset
2024-09-25 14:05:04,680:INFO:Defining folds
2024-09-25 14:05:04,680:INFO:Declaring metric variables
2024-09-25 14:05:04,683:INFO:Importing untrained model
2024-09-25 14:05:04,685:INFO:Naive Bayes Imported successfully
2024-09-25 14:05:04,688:INFO:Starting cross validation
2024-09-25 14:05:04,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:05,193:INFO:Calculating mean and std
2024-09-25 14:05:05,193:INFO:Creating metrics dataframe
2024-09-25 14:05:05,194:INFO:Uploading results into container
2024-09-25 14:05:05,194:INFO:Uploading model into container now
2024-09-25 14:05:05,195:INFO:_master_model_container: 3
2024-09-25 14:05:05,195:INFO:_display_container: 2
2024-09-25 14:05:05,195:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-25 14:05:05,195:INFO:create_model() successfully completed......................................
2024-09-25 14:05:05,286:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:05,286:INFO:Creating metrics dataframe
2024-09-25 14:05:05,291:INFO:Initializing Decision Tree Classifier
2024-09-25 14:05:05,291:INFO:Total runtime is 0.3592482328414917 minutes
2024-09-25 14:05:05,293:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:05,294:INFO:Initializing create_model()
2024-09-25 14:05:05,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:05,294:INFO:Checking exceptions
2024-09-25 14:05:05,294:INFO:Importing libraries
2024-09-25 14:05:05,294:INFO:Copying training dataset
2024-09-25 14:05:05,338:INFO:Defining folds
2024-09-25 14:05:05,338:INFO:Declaring metric variables
2024-09-25 14:05:05,339:INFO:Importing untrained model
2024-09-25 14:05:05,341:INFO:Decision Tree Classifier Imported successfully
2024-09-25 14:05:05,345:INFO:Starting cross validation
2024-09-25 14:05:05,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:07,211:INFO:Calculating mean and std
2024-09-25 14:05:07,214:INFO:Creating metrics dataframe
2024-09-25 14:05:07,217:INFO:Uploading results into container
2024-09-25 14:05:07,218:INFO:Uploading model into container now
2024-09-25 14:05:07,218:INFO:_master_model_container: 4
2024-09-25 14:05:07,218:INFO:_display_container: 2
2024-09-25 14:05:07,218:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-25 14:05:07,218:INFO:create_model() successfully completed......................................
2024-09-25 14:05:07,394:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:07,394:INFO:Creating metrics dataframe
2024-09-25 14:05:07,401:INFO:Initializing SVM - Linear Kernel
2024-09-25 14:05:07,401:INFO:Total runtime is 0.3944113334019979 minutes
2024-09-25 14:05:07,403:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:07,403:INFO:Initializing create_model()
2024-09-25 14:05:07,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:07,403:INFO:Checking exceptions
2024-09-25 14:05:07,404:INFO:Importing libraries
2024-09-25 14:05:07,404:INFO:Copying training dataset
2024-09-25 14:05:07,446:INFO:Defining folds
2024-09-25 14:05:07,446:INFO:Declaring metric variables
2024-09-25 14:05:07,448:INFO:Importing untrained model
2024-09-25 14:05:07,450:INFO:SVM - Linear Kernel Imported successfully
2024-09-25 14:05:07,453:INFO:Starting cross validation
2024-09-25 14:05:07,454:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:14,951:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:14,959:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:05:15,119:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:15,191:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:15,197:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:05:15,325:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:15,331:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:05:15,627:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:15,633:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:05:15,828:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:15,942:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:16,039:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,267:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,271:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:05:17,302:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,314:INFO:Calculating mean and std
2024-09-25 14:05:17,317:INFO:Creating metrics dataframe
2024-09-25 14:05:17,329:INFO:Uploading results into container
2024-09-25 14:05:17,331:INFO:Uploading model into container now
2024-09-25 14:05:17,332:INFO:_master_model_container: 5
2024-09-25 14:05:17,332:INFO:_display_container: 2
2024-09-25 14:05:17,332:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-25 14:05:17,332:INFO:create_model() successfully completed......................................
2024-09-25 14:05:17,500:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:17,500:INFO:Creating metrics dataframe
2024-09-25 14:05:17,503:INFO:Initializing Ridge Classifier
2024-09-25 14:05:17,503:INFO:Total runtime is 0.5627879540125529 minutes
2024-09-25 14:05:17,505:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:17,505:INFO:Initializing create_model()
2024-09-25 14:05:17,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:17,506:INFO:Checking exceptions
2024-09-25 14:05:17,506:INFO:Importing libraries
2024-09-25 14:05:17,506:INFO:Copying training dataset
2024-09-25 14:05:17,539:INFO:Defining folds
2024-09-25 14:05:17,539:INFO:Declaring metric variables
2024-09-25 14:05:17,540:INFO:Importing untrained model
2024-09-25 14:05:17,543:INFO:Ridge Classifier Imported successfully
2024-09-25 14:05:17,545:INFO:Starting cross validation
2024-09-25 14:05:17,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:17,642:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.25338e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,651:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,699:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.44292e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,708:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,730:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.29474e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,738:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,773:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.25455e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,785:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,818:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.46527e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,825:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,853:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.43336e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,863:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,900:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.46903e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,908:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.39837e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,938:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,958:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.19136e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,965:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:17,989:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.34182e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-25 14:05:17,996:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:18,017:INFO:Calculating mean and std
2024-09-25 14:05:18,018:INFO:Creating metrics dataframe
2024-09-25 14:05:18,019:INFO:Uploading results into container
2024-09-25 14:05:18,019:INFO:Uploading model into container now
2024-09-25 14:05:18,020:INFO:_master_model_container: 6
2024-09-25 14:05:18,020:INFO:_display_container: 2
2024-09-25 14:05:18,020:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-25 14:05:18,020:INFO:create_model() successfully completed......................................
2024-09-25 14:05:18,124:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:18,124:INFO:Creating metrics dataframe
2024-09-25 14:05:18,128:INFO:Initializing Random Forest Classifier
2024-09-25 14:05:18,128:INFO:Total runtime is 0.5731942494710286 minutes
2024-09-25 14:05:18,130:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:18,130:INFO:Initializing create_model()
2024-09-25 14:05:18,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:18,130:INFO:Checking exceptions
2024-09-25 14:05:18,130:INFO:Importing libraries
2024-09-25 14:05:18,130:INFO:Copying training dataset
2024-09-25 14:05:18,174:INFO:Defining folds
2024-09-25 14:05:18,175:INFO:Declaring metric variables
2024-09-25 14:05:18,177:INFO:Importing untrained model
2024-09-25 14:05:18,180:INFO:Random Forest Classifier Imported successfully
2024-09-25 14:05:18,186:INFO:Starting cross validation
2024-09-25 14:05:18,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:45,867:INFO:Calculating mean and std
2024-09-25 14:05:45,871:INFO:Creating metrics dataframe
2024-09-25 14:05:45,881:INFO:Uploading results into container
2024-09-25 14:05:45,881:INFO:Uploading model into container now
2024-09-25 14:05:45,882:INFO:_master_model_container: 7
2024-09-25 14:05:45,882:INFO:_display_container: 2
2024-09-25 14:05:45,884:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 14:05:45,884:INFO:create_model() successfully completed......................................
2024-09-25 14:05:46,092:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:46,093:INFO:Creating metrics dataframe
2024-09-25 14:05:46,099:INFO:Initializing Quadratic Discriminant Analysis
2024-09-25 14:05:46,099:INFO:Total runtime is 1.0393784006436666 minutes
2024-09-25 14:05:46,102:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:46,102:INFO:Initializing create_model()
2024-09-25 14:05:46,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:46,102:INFO:Checking exceptions
2024-09-25 14:05:46,102:INFO:Importing libraries
2024-09-25 14:05:46,103:INFO:Copying training dataset
2024-09-25 14:05:46,164:INFO:Defining folds
2024-09-25 14:05:46,164:INFO:Declaring metric variables
2024-09-25 14:05:46,168:INFO:Importing untrained model
2024-09-25 14:05:46,172:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-25 14:05:46,176:INFO:Starting cross validation
2024-09-25 14:05:46,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:46,329:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,364:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,422:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,474:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,525:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,587:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,619:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,657:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,697:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,735:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:46,749:INFO:Calculating mean and std
2024-09-25 14:05:46,750:INFO:Creating metrics dataframe
2024-09-25 14:05:46,751:INFO:Uploading results into container
2024-09-25 14:05:46,751:INFO:Uploading model into container now
2024-09-25 14:05:46,752:INFO:_master_model_container: 8
2024-09-25 14:05:46,752:INFO:_display_container: 2
2024-09-25 14:05:46,752:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-25 14:05:46,752:INFO:create_model() successfully completed......................................
2024-09-25 14:05:46,856:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:46,856:INFO:Creating metrics dataframe
2024-09-25 14:05:46,861:INFO:Initializing Ada Boost Classifier
2024-09-25 14:05:46,861:INFO:Total runtime is 1.0520855466524761 minutes
2024-09-25 14:05:46,863:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:46,863:INFO:Initializing create_model()
2024-09-25 14:05:46,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:46,864:INFO:Checking exceptions
2024-09-25 14:05:46,864:INFO:Importing libraries
2024-09-25 14:05:46,864:INFO:Copying training dataset
2024-09-25 14:05:46,905:INFO:Defining folds
2024-09-25 14:05:46,906:INFO:Declaring metric variables
2024-09-25 14:05:46,907:INFO:Importing untrained model
2024-09-25 14:05:46,911:INFO:Ada Boost Classifier Imported successfully
2024-09-25 14:05:46,914:INFO:Starting cross validation
2024-09-25 14:05:46,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:05:47,002:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,065:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,078:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,142:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,218:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,325:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,432:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:47,487:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:51,096:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,150:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,182:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,289:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:51,306:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,338:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-25 14:05:51,358:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,471:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,507:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:51,638:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:53,821:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:53,850:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:05:53,889:INFO:Calculating mean and std
2024-09-25 14:05:53,892:INFO:Creating metrics dataframe
2024-09-25 14:05:53,899:INFO:Uploading results into container
2024-09-25 14:05:53,900:INFO:Uploading model into container now
2024-09-25 14:05:53,902:INFO:_master_model_container: 9
2024-09-25 14:05:53,905:INFO:_display_container: 2
2024-09-25 14:05:53,906:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-25 14:05:53,906:INFO:create_model() successfully completed......................................
2024-09-25 14:05:54,100:INFO:SubProcess create_model() end ==================================
2024-09-25 14:05:54,100:INFO:Creating metrics dataframe
2024-09-25 14:05:54,105:INFO:Initializing Gradient Boosting Classifier
2024-09-25 14:05:54,105:INFO:Total runtime is 1.1728131532669068 minutes
2024-09-25 14:05:54,107:INFO:SubProcess create_model() called ==================================
2024-09-25 14:05:54,107:INFO:Initializing create_model()
2024-09-25 14:05:54,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:05:54,107:INFO:Checking exceptions
2024-09-25 14:05:54,107:INFO:Importing libraries
2024-09-25 14:05:54,108:INFO:Copying training dataset
2024-09-25 14:05:54,195:INFO:Defining folds
2024-09-25 14:05:54,195:INFO:Declaring metric variables
2024-09-25 14:05:54,197:INFO:Importing untrained model
2024-09-25 14:05:54,199:INFO:Gradient Boosting Classifier Imported successfully
2024-09-25 14:05:54,202:INFO:Starting cross validation
2024-09-25 14:05:54,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:06:43,438:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:43,556:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:43,633:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:43,776:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:44,124:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:44,162:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:44,302:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:06:44,378:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,241:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,278:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,304:INFO:Calculating mean and std
2024-09-25 14:07:15,309:INFO:Creating metrics dataframe
2024-09-25 14:07:15,313:INFO:Uploading results into container
2024-09-25 14:07:15,313:INFO:Uploading model into container now
2024-09-25 14:07:15,314:INFO:_master_model_container: 10
2024-09-25 14:07:15,314:INFO:_display_container: 2
2024-09-25 14:07:15,314:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-25 14:07:15,315:INFO:create_model() successfully completed......................................
2024-09-25 14:07:15,439:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:15,439:INFO:Creating metrics dataframe
2024-09-25 14:07:15,445:INFO:Initializing Linear Discriminant Analysis
2024-09-25 14:07:15,445:INFO:Total runtime is 2.5284879167874657 minutes
2024-09-25 14:07:15,447:INFO:SubProcess create_model() called ==================================
2024-09-25 14:07:15,447:INFO:Initializing create_model()
2024-09-25 14:07:15,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:15,447:INFO:Checking exceptions
2024-09-25 14:07:15,447:INFO:Importing libraries
2024-09-25 14:07:15,448:INFO:Copying training dataset
2024-09-25 14:07:15,485:INFO:Defining folds
2024-09-25 14:07:15,485:INFO:Declaring metric variables
2024-09-25 14:07:15,487:INFO:Importing untrained model
2024-09-25 14:07:15,488:INFO:Linear Discriminant Analysis Imported successfully
2024-09-25 14:07:15,491:INFO:Starting cross validation
2024-09-25 14:07:15,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:07:15,614:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,655:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,693:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,734:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,757:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,794:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,832:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,870:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,902:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,933:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-25 14:07:15,955:INFO:Calculating mean and std
2024-09-25 14:07:15,956:INFO:Creating metrics dataframe
2024-09-25 14:07:15,957:INFO:Uploading results into container
2024-09-25 14:07:15,957:INFO:Uploading model into container now
2024-09-25 14:07:15,957:INFO:_master_model_container: 11
2024-09-25 14:07:15,957:INFO:_display_container: 2
2024-09-25 14:07:15,957:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-25 14:07:15,957:INFO:create_model() successfully completed......................................
2024-09-25 14:07:16,049:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:16,049:INFO:Creating metrics dataframe
2024-09-25 14:07:16,054:INFO:Initializing Extra Trees Classifier
2024-09-25 14:07:16,054:INFO:Total runtime is 2.53862738609314 minutes
2024-09-25 14:07:16,055:INFO:SubProcess create_model() called ==================================
2024-09-25 14:07:16,055:INFO:Initializing create_model()
2024-09-25 14:07:16,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:16,055:INFO:Checking exceptions
2024-09-25 14:07:16,056:INFO:Importing libraries
2024-09-25 14:07:16,056:INFO:Copying training dataset
2024-09-25 14:07:16,089:INFO:Defining folds
2024-09-25 14:07:16,089:INFO:Declaring metric variables
2024-09-25 14:07:16,091:INFO:Importing untrained model
2024-09-25 14:07:16,093:INFO:Extra Trees Classifier Imported successfully
2024-09-25 14:07:16,095:INFO:Starting cross validation
2024-09-25 14:07:16,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:07:30,450:INFO:Calculating mean and std
2024-09-25 14:07:30,454:INFO:Creating metrics dataframe
2024-09-25 14:07:30,461:INFO:Uploading results into container
2024-09-25 14:07:30,462:INFO:Uploading model into container now
2024-09-25 14:07:30,463:INFO:_master_model_container: 12
2024-09-25 14:07:30,463:INFO:_display_container: 2
2024-09-25 14:07:30,466:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-25 14:07:30,466:INFO:create_model() successfully completed......................................
2024-09-25 14:07:30,637:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:30,637:INFO:Creating metrics dataframe
2024-09-25 14:07:30,643:INFO:Initializing Extreme Gradient Boosting
2024-09-25 14:07:30,643:INFO:Total runtime is 2.78177604675293 minutes
2024-09-25 14:07:30,646:INFO:SubProcess create_model() called ==================================
2024-09-25 14:07:30,646:INFO:Initializing create_model()
2024-09-25 14:07:30,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:30,646:INFO:Checking exceptions
2024-09-25 14:07:30,647:INFO:Importing libraries
2024-09-25 14:07:30,647:INFO:Copying training dataset
2024-09-25 14:07:30,713:INFO:Defining folds
2024-09-25 14:07:30,714:INFO:Declaring metric variables
2024-09-25 14:07:30,716:INFO:Importing untrained model
2024-09-25 14:07:30,721:INFO:Extreme Gradient Boosting Imported successfully
2024-09-25 14:07:30,725:INFO:Starting cross validation
2024-09-25 14:07:30,726:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:07:31,272:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-25 14:07:37,617:INFO:Calculating mean and std
2024-09-25 14:07:37,620:INFO:Creating metrics dataframe
2024-09-25 14:07:37,623:INFO:Uploading results into container
2024-09-25 14:07:37,624:INFO:Uploading model into container now
2024-09-25 14:07:37,625:INFO:_master_model_container: 13
2024-09-25 14:07:37,625:INFO:_display_container: 2
2024-09-25 14:07:37,627:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-25 14:07:37,627:INFO:create_model() successfully completed......................................
2024-09-25 14:07:37,762:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:37,764:INFO:Creating metrics dataframe
2024-09-25 14:07:37,771:INFO:Initializing Light Gradient Boosting Machine
2024-09-25 14:07:37,771:INFO:Total runtime is 2.9005782167116805 minutes
2024-09-25 14:07:37,773:INFO:SubProcess create_model() called ==================================
2024-09-25 14:07:37,773:INFO:Initializing create_model()
2024-09-25 14:07:37,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:37,774:INFO:Checking exceptions
2024-09-25 14:07:37,774:INFO:Importing libraries
2024-09-25 14:07:37,774:INFO:Copying training dataset
2024-09-25 14:07:37,829:INFO:Defining folds
2024-09-25 14:07:37,830:INFO:Declaring metric variables
2024-09-25 14:07:37,832:INFO:Importing untrained model
2024-09-25 14:07:37,836:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-25 14:07:37,841:INFO:Starting cross validation
2024-09-25 14:07:37,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:07:56,976:INFO:Calculating mean and std
2024-09-25 14:07:56,979:INFO:Creating metrics dataframe
2024-09-25 14:07:56,982:INFO:Uploading results into container
2024-09-25 14:07:56,983:INFO:Uploading model into container now
2024-09-25 14:07:56,984:INFO:_master_model_container: 14
2024-09-25 14:07:56,984:INFO:_display_container: 2
2024-09-25 14:07:56,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-25 14:07:56,985:INFO:create_model() successfully completed......................................
2024-09-25 14:07:57,155:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:57,155:INFO:Creating metrics dataframe
2024-09-25 14:07:57,161:INFO:Initializing Dummy Classifier
2024-09-25 14:07:57,161:INFO:Total runtime is 3.223740100860596 minutes
2024-09-25 14:07:57,162:INFO:SubProcess create_model() called ==================================
2024-09-25 14:07:57,163:INFO:Initializing create_model()
2024-09-25 14:07:57,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x156ecfdc0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:57,164:INFO:Checking exceptions
2024-09-25 14:07:57,164:INFO:Importing libraries
2024-09-25 14:07:57,167:INFO:Copying training dataset
2024-09-25 14:07:57,248:INFO:Defining folds
2024-09-25 14:07:57,248:INFO:Declaring metric variables
2024-09-25 14:07:57,250:INFO:Importing untrained model
2024-09-25 14:07:57,252:INFO:Dummy Classifier Imported successfully
2024-09-25 14:07:57,255:INFO:Starting cross validation
2024-09-25 14:07:57,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-25 14:07:57,345:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,377:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,406:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,432:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,465:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,501:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,535:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,567:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,600:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,631:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-25 14:07:57,643:INFO:Calculating mean and std
2024-09-25 14:07:57,644:INFO:Creating metrics dataframe
2024-09-25 14:07:57,645:INFO:Uploading results into container
2024-09-25 14:07:57,645:INFO:Uploading model into container now
2024-09-25 14:07:57,646:INFO:_master_model_container: 15
2024-09-25 14:07:57,646:INFO:_display_container: 2
2024-09-25 14:07:57,646:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-25 14:07:57,646:INFO:create_model() successfully completed......................................
2024-09-25 14:07:57,731:INFO:SubProcess create_model() end ==================================
2024-09-25 14:07:57,731:INFO:Creating metrics dataframe
2024-09-25 14:07:57,736:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-25 14:07:57,739:INFO:Initializing create_model()
2024-09-25 14:07:57,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x179d62860>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-25 14:07:57,739:INFO:Checking exceptions
2024-09-25 14:07:57,740:INFO:Importing libraries
2024-09-25 14:07:57,741:INFO:Copying training dataset
2024-09-25 14:07:57,771:INFO:Defining folds
2024-09-25 14:07:57,772:INFO:Declaring metric variables
2024-09-25 14:07:57,772:INFO:Importing untrained model
2024-09-25 14:07:57,772:INFO:Declaring custom model
2024-09-25 14:07:57,772:INFO:Random Forest Classifier Imported successfully
2024-09-25 14:07:57,772:INFO:Cross validation set to False
2024-09-25 14:07:57,772:INFO:Fitting Model
2024-09-25 14:08:00,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 14:08:00,564:INFO:create_model() successfully completed......................................
2024-09-25 14:08:00,750:INFO:_master_model_container: 15
2024-09-25 14:08:00,750:INFO:_display_container: 2
2024-09-25 14:08:00,750:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-25 14:08:00,751:INFO:compare_models() successfully completed......................................
