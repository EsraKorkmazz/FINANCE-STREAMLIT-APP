2024-09-17 13:24:29,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-17 13:24:29,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-17 13:24:29,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-17 13:24:29,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-17 13:24:31,233:INFO:PyCaret ClassificationExperiment
2024-09-17 13:24:31,233:INFO:Logging name: clf-default-name
2024-09-17 13:24:31,234:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-17 13:24:31,234:INFO:version 3.3.2
2024-09-17 13:24:31,234:INFO:Initializing setup()
2024-09-17 13:24:31,234:INFO:self.USI: 32b7
2024-09-17 13:24:31,234:INFO:self._variable_keys: {'gpu_n_jobs_param', 'fold_groups_param', 'fold_generator', 'X_train', 'y', 'pipeline', 'log_plots_param', 'is_multiclass', 'n_jobs_param', '_available_plots', 'y_train', 'exp_name_log', 'fold_shuffle_param', 'idx', 'html_param', 'USI', 'X_test', 'fix_imbalance', 'data', 'y_test', 'target_param', 'exp_id', 'logging_param', '_ml_usecase', 'gpu_param', 'memory', 'seed', 'X'}
2024-09-17 13:24:31,234:INFO:Checking environment
2024-09-17 13:24:31,234:INFO:python_version: 3.10.14
2024-09-17 13:24:31,235:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-17 13:24:31,235:INFO:machine: arm64
2024-09-17 13:24:31,235:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:24:31,235:INFO:Memory: svmem(total=8589934592, available=1821736960, percent=78.8, used=3459629056, free=103055360, active=1727512576, inactive=1661157376, wired=1732116480)
2024-09-17 13:24:31,235:INFO:Physical Core: 8
2024-09-17 13:24:31,236:INFO:Logical Core: 8
2024-09-17 13:24:31,236:INFO:Checking libraries
2024-09-17 13:24:31,236:INFO:System:
2024-09-17 13:24:31,236:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-17 13:24:31,236:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-17 13:24:31,236:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:24:31,236:INFO:PyCaret required dependencies:
2024-09-17 13:24:31,308:INFO:                 pip: 24.2
2024-09-17 13:24:31,308:INFO:          setuptools: 72.1.0
2024-09-17 13:24:31,308:INFO:             pycaret: 3.3.2
2024-09-17 13:24:31,308:INFO:             IPython: 8.18.1
2024-09-17 13:24:31,308:INFO:          ipywidgets: 8.1.5
2024-09-17 13:24:31,308:INFO:                tqdm: 4.66.5
2024-09-17 13:24:31,308:INFO:               numpy: 1.26.4
2024-09-17 13:24:31,308:INFO:              pandas: 2.1.4
2024-09-17 13:24:31,308:INFO:              jinja2: 3.1.4
2024-09-17 13:24:31,308:INFO:               scipy: 1.11.4
2024-09-17 13:24:31,308:INFO:              joblib: 1.3.2
2024-09-17 13:24:31,308:INFO:             sklearn: 1.4.2
2024-09-17 13:24:31,308:INFO:                pyod: 2.0.2
2024-09-17 13:24:31,308:INFO:            imblearn: 0.12.3
2024-09-17 13:24:31,308:INFO:   category_encoders: 2.6.3
2024-09-17 13:24:31,308:INFO:            lightgbm: 4.5.0
2024-09-17 13:24:31,308:INFO:               numba: 0.60.0
2024-09-17 13:24:31,308:INFO:            requests: 2.32.3
2024-09-17 13:24:31,308:INFO:          matplotlib: 3.7.5
2024-09-17 13:24:31,308:INFO:          scikitplot: 0.3.7
2024-09-17 13:24:31,308:INFO:         yellowbrick: 1.5
2024-09-17 13:24:31,308:INFO:              plotly: 5.24.0
2024-09-17 13:24:31,308:INFO:    plotly-resampler: Not installed
2024-09-17 13:24:31,309:INFO:             kaleido: 0.2.1
2024-09-17 13:24:31,309:INFO:           schemdraw: 0.15
2024-09-17 13:24:31,309:INFO:         statsmodels: 0.14.3
2024-09-17 13:24:31,309:INFO:              sktime: 0.26.0
2024-09-17 13:24:31,309:INFO:               tbats: 1.1.3
2024-09-17 13:24:31,309:INFO:            pmdarima: 2.0.4
2024-09-17 13:24:31,309:INFO:              psutil: 5.9.0
2024-09-17 13:24:31,309:INFO:          markupsafe: 2.1.5
2024-09-17 13:24:31,309:INFO:             pickle5: Not installed
2024-09-17 13:24:31,309:INFO:         cloudpickle: 3.0.0
2024-09-17 13:24:31,309:INFO:         deprecation: 2.1.0
2024-09-17 13:24:31,309:INFO:              xxhash: 3.5.0
2024-09-17 13:24:31,309:INFO:           wurlitzer: 3.1.1
2024-09-17 13:24:31,309:INFO:PyCaret optional dependencies:
2024-09-17 13:24:31,314:INFO:                shap: 0.46.0
2024-09-17 13:24:31,314:INFO:           interpret: Not installed
2024-09-17 13:24:31,314:INFO:                umap: Not installed
2024-09-17 13:24:31,314:INFO:     ydata_profiling: Not installed
2024-09-17 13:24:31,314:INFO:  explainerdashboard: Not installed
2024-09-17 13:24:31,314:INFO:             autoviz: Not installed
2024-09-17 13:24:31,314:INFO:           fairlearn: Not installed
2024-09-17 13:24:31,314:INFO:          deepchecks: Not installed
2024-09-17 13:24:31,314:INFO:             xgboost: 2.1.1
2024-09-17 13:24:31,314:INFO:            catboost: Not installed
2024-09-17 13:24:31,314:INFO:              kmodes: Not installed
2024-09-17 13:24:31,314:INFO:             mlxtend: Not installed
2024-09-17 13:24:31,314:INFO:       statsforecast: Not installed
2024-09-17 13:24:31,314:INFO:        tune_sklearn: Not installed
2024-09-17 13:24:31,314:INFO:                 ray: Not installed
2024-09-17 13:24:31,314:INFO:            hyperopt: Not installed
2024-09-17 13:24:31,314:INFO:              optuna: 4.0.0
2024-09-17 13:24:31,314:INFO:               skopt: Not installed
2024-09-17 13:24:31,314:INFO:              mlflow: Not installed
2024-09-17 13:24:31,314:INFO:              gradio: Not installed
2024-09-17 13:24:31,314:INFO:             fastapi: Not installed
2024-09-17 13:24:31,314:INFO:             uvicorn: Not installed
2024-09-17 13:24:31,314:INFO:              m2cgen: Not installed
2024-09-17 13:24:31,314:INFO:           evidently: Not installed
2024-09-17 13:24:31,314:INFO:               fugue: Not installed
2024-09-17 13:24:31,314:INFO:           streamlit: 1.38.0
2024-09-17 13:24:31,314:INFO:             prophet: Not installed
2024-09-17 13:24:31,314:INFO:None
2024-09-17 13:24:31,314:INFO:Set up data.
2024-09-17 13:24:31,348:INFO:Set up folding strategy.
2024-09-17 13:24:31,348:INFO:Set up train/test split.
2024-09-17 13:24:31,385:INFO:Set up index.
2024-09-17 13:24:31,387:INFO:Assigning column types.
2024-09-17 13:24:31,402:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-17 13:24:31,421:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,423:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,439:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,459:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,470:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,472:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-17 13:24:31,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,502:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:24:31,533:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,534:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-17 13:24:31,564:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,595:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:31,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:31,597:INFO:Preparing preprocessing pipeline...
2024-09-17 13:24:31,600:INFO:Set up label encoding.
2024-09-17 13:24:31,600:INFO:Set up simple imputation.
2024-09-17 13:24:31,602:INFO:Set up column name cleaning.
2024-09-17 13:24:32,249:INFO:Finished creating preprocessing pipeline.
2024-09-17 13:24:32,254:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-17 13:24:32,254:INFO:Creating final display dataframe.
2024-09-17 13:24:33,466:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               32b7
2024-09-17 13:24:33,504:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:33,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:33,536:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:24:33,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:24:33,537:INFO:setup() successfully completed in 2.31s...............
2024-09-17 13:24:36,519:INFO:Initializing compare_models()
2024-09-17 13:24:36,520:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-17 13:24:36,520:INFO:Checking exceptions
2024-09-17 13:24:36,558:INFO:Preparing display monitor
2024-09-17 13:24:36,632:INFO:Initializing Logistic Regression
2024-09-17 13:24:36,632:INFO:Total runtime is 7.617473602294922e-06 minutes
2024-09-17 13:24:36,633:INFO:SubProcess create_model() called ==================================
2024-09-17 13:24:36,634:INFO:Initializing create_model()
2024-09-17 13:24:36,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:24:36,634:INFO:Checking exceptions
2024-09-17 13:24:36,634:INFO:Importing libraries
2024-09-17 13:24:36,634:INFO:Copying training dataset
2024-09-17 13:24:36,688:INFO:Defining folds
2024-09-17 13:24:36,688:INFO:Declaring metric variables
2024-09-17 13:24:36,690:INFO:Importing untrained model
2024-09-17 13:24:36,691:INFO:Logistic Regression Imported successfully
2024-09-17 13:24:36,694:INFO:Starting cross validation
2024-09-17 13:24:36,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:24:50,104:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,140:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,193:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,205:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,230:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,270:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,287:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,315:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,345:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,369:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,409:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,414:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,432:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,500:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:50,672:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:50,713:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:55,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:55,575:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:55,603:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:24:55,631:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:24:55,655:INFO:Calculating mean and std
2024-09-17 13:24:55,658:INFO:Creating metrics dataframe
2024-09-17 13:24:55,662:INFO:Uploading results into container
2024-09-17 13:24:55,663:INFO:Uploading model into container now
2024-09-17 13:24:55,663:INFO:_master_model_container: 1
2024-09-17 13:24:55,663:INFO:_display_container: 2
2024-09-17 13:24:55,664:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-17 13:24:55,664:INFO:create_model() successfully completed......................................
2024-09-17 13:24:55,775:INFO:SubProcess create_model() end ==================================
2024-09-17 13:24:55,775:INFO:Creating metrics dataframe
2024-09-17 13:24:55,778:INFO:Initializing K Neighbors Classifier
2024-09-17 13:24:55,778:INFO:Total runtime is 0.31911446650822956 minutes
2024-09-17 13:24:55,780:INFO:SubProcess create_model() called ==================================
2024-09-17 13:24:55,780:INFO:Initializing create_model()
2024-09-17 13:24:55,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:24:55,780:INFO:Checking exceptions
2024-09-17 13:24:55,780:INFO:Importing libraries
2024-09-17 13:24:55,780:INFO:Copying training dataset
2024-09-17 13:24:55,825:INFO:Defining folds
2024-09-17 13:24:55,826:INFO:Declaring metric variables
2024-09-17 13:24:55,828:INFO:Importing untrained model
2024-09-17 13:24:55,830:INFO:K Neighbors Classifier Imported successfully
2024-09-17 13:24:55,835:INFO:Starting cross validation
2024-09-17 13:24:55,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:04,535:INFO:Calculating mean and std
2024-09-17 13:25:04,537:INFO:Creating metrics dataframe
2024-09-17 13:25:04,540:INFO:Uploading results into container
2024-09-17 13:25:04,540:INFO:Uploading model into container now
2024-09-17 13:25:04,541:INFO:_master_model_container: 2
2024-09-17 13:25:04,541:INFO:_display_container: 2
2024-09-17 13:25:04,541:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-17 13:25:04,541:INFO:create_model() successfully completed......................................
2024-09-17 13:25:04,651:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:04,651:INFO:Creating metrics dataframe
2024-09-17 13:25:04,655:INFO:Initializing Naive Bayes
2024-09-17 13:25:04,655:INFO:Total runtime is 0.46705127159754434 minutes
2024-09-17 13:25:04,656:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:04,656:INFO:Initializing create_model()
2024-09-17 13:25:04,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:04,656:INFO:Checking exceptions
2024-09-17 13:25:04,656:INFO:Importing libraries
2024-09-17 13:25:04,656:INFO:Copying training dataset
2024-09-17 13:25:04,700:INFO:Defining folds
2024-09-17 13:25:04,700:INFO:Declaring metric variables
2024-09-17 13:25:04,702:INFO:Importing untrained model
2024-09-17 13:25:04,704:INFO:Naive Bayes Imported successfully
2024-09-17 13:25:04,706:INFO:Starting cross validation
2024-09-17 13:25:04,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:05,419:INFO:Calculating mean and std
2024-09-17 13:25:05,421:INFO:Creating metrics dataframe
2024-09-17 13:25:05,425:INFO:Uploading results into container
2024-09-17 13:25:05,425:INFO:Uploading model into container now
2024-09-17 13:25:05,426:INFO:_master_model_container: 3
2024-09-17 13:25:05,426:INFO:_display_container: 2
2024-09-17 13:25:05,426:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-17 13:25:05,426:INFO:create_model() successfully completed......................................
2024-09-17 13:25:05,527:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:05,527:INFO:Creating metrics dataframe
2024-09-17 13:25:05,531:INFO:Initializing Decision Tree Classifier
2024-09-17 13:25:05,531:INFO:Total runtime is 0.481652820110321 minutes
2024-09-17 13:25:05,532:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:05,532:INFO:Initializing create_model()
2024-09-17 13:25:05,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:05,533:INFO:Checking exceptions
2024-09-17 13:25:05,533:INFO:Importing libraries
2024-09-17 13:25:05,533:INFO:Copying training dataset
2024-09-17 13:25:05,578:INFO:Defining folds
2024-09-17 13:25:05,578:INFO:Declaring metric variables
2024-09-17 13:25:05,583:INFO:Importing untrained model
2024-09-17 13:25:05,586:INFO:Decision Tree Classifier Imported successfully
2024-09-17 13:25:05,592:INFO:Starting cross validation
2024-09-17 13:25:05,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:07,811:INFO:Calculating mean and std
2024-09-17 13:25:07,815:INFO:Creating metrics dataframe
2024-09-17 13:25:07,818:INFO:Uploading results into container
2024-09-17 13:25:07,818:INFO:Uploading model into container now
2024-09-17 13:25:07,818:INFO:_master_model_container: 4
2024-09-17 13:25:07,818:INFO:_display_container: 2
2024-09-17 13:25:07,819:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-17 13:25:07,819:INFO:create_model() successfully completed......................................
2024-09-17 13:25:07,914:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:07,914:INFO:Creating metrics dataframe
2024-09-17 13:25:07,919:INFO:Initializing SVM - Linear Kernel
2024-09-17 13:25:07,919:INFO:Total runtime is 0.5214567025502522 minutes
2024-09-17 13:25:07,922:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:07,922:INFO:Initializing create_model()
2024-09-17 13:25:07,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:07,922:INFO:Checking exceptions
2024-09-17 13:25:07,922:INFO:Importing libraries
2024-09-17 13:25:07,922:INFO:Copying training dataset
2024-09-17 13:25:07,966:INFO:Defining folds
2024-09-17 13:25:07,966:INFO:Declaring metric variables
2024-09-17 13:25:07,969:INFO:Importing untrained model
2024-09-17 13:25:07,971:INFO:SVM - Linear Kernel Imported successfully
2024-09-17 13:25:07,993:INFO:Starting cross validation
2024-09-17 13:25:07,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:16,915:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:16,929:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:17,516:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:17,522:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:17,895:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:17,902:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:18,166:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:18,174:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:18,221:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:18,228:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:18,787:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:18,797:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:18,902:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:18,910:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:19,172:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,066:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,070:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:25:21,122:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,141:INFO:Calculating mean and std
2024-09-17 13:25:21,145:INFO:Creating metrics dataframe
2024-09-17 13:25:21,150:INFO:Uploading results into container
2024-09-17 13:25:21,151:INFO:Uploading model into container now
2024-09-17 13:25:21,152:INFO:_master_model_container: 5
2024-09-17 13:25:21,152:INFO:_display_container: 2
2024-09-17 13:25:21,153:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-17 13:25:21,153:INFO:create_model() successfully completed......................................
2024-09-17 13:25:21,266:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:21,266:INFO:Creating metrics dataframe
2024-09-17 13:25:21,270:INFO:Initializing Ridge Classifier
2024-09-17 13:25:21,270:INFO:Total runtime is 0.7439737002054849 minutes
2024-09-17 13:25:21,271:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:21,271:INFO:Initializing create_model()
2024-09-17 13:25:21,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:21,272:INFO:Checking exceptions
2024-09-17 13:25:21,272:INFO:Importing libraries
2024-09-17 13:25:21,272:INFO:Copying training dataset
2024-09-17 13:25:21,324:INFO:Defining folds
2024-09-17 13:25:21,324:INFO:Declaring metric variables
2024-09-17 13:25:21,326:INFO:Importing untrained model
2024-09-17 13:25:21,329:INFO:Ridge Classifier Imported successfully
2024-09-17 13:25:21,332:INFO:Starting cross validation
2024-09-17 13:25:21,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:21,588:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,631:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,650:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,683:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,697:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,766:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,795:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,811:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,837:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,870:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,890:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,928:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,942:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:21,987:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:21,987:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:22,020:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:22,027:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:22,058:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:22,077:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:25:22,101:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:22,118:INFO:Calculating mean and std
2024-09-17 13:25:22,118:INFO:Creating metrics dataframe
2024-09-17 13:25:22,120:INFO:Uploading results into container
2024-09-17 13:25:22,120:INFO:Uploading model into container now
2024-09-17 13:25:22,120:INFO:_master_model_container: 6
2024-09-17 13:25:22,120:INFO:_display_container: 2
2024-09-17 13:25:22,120:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-17 13:25:22,120:INFO:create_model() successfully completed......................................
2024-09-17 13:25:22,184:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:22,184:INFO:Creating metrics dataframe
2024-09-17 13:25:22,189:INFO:Initializing Random Forest Classifier
2024-09-17 13:25:22,190:INFO:Total runtime is 0.7593010862668355 minutes
2024-09-17 13:25:22,192:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:22,192:INFO:Initializing create_model()
2024-09-17 13:25:22,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:22,192:INFO:Checking exceptions
2024-09-17 13:25:22,192:INFO:Importing libraries
2024-09-17 13:25:22,192:INFO:Copying training dataset
2024-09-17 13:25:22,239:INFO:Defining folds
2024-09-17 13:25:22,240:INFO:Declaring metric variables
2024-09-17 13:25:22,242:INFO:Importing untrained model
2024-09-17 13:25:22,243:INFO:Random Forest Classifier Imported successfully
2024-09-17 13:25:22,247:INFO:Starting cross validation
2024-09-17 13:25:22,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:47,752:INFO:Calculating mean and std
2024-09-17 13:25:47,756:INFO:Creating metrics dataframe
2024-09-17 13:25:47,760:INFO:Uploading results into container
2024-09-17 13:25:47,761:INFO:Uploading model into container now
2024-09-17 13:25:47,763:INFO:_master_model_container: 7
2024-09-17 13:25:47,763:INFO:_display_container: 2
2024-09-17 13:25:47,765:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:25:47,765:INFO:create_model() successfully completed......................................
2024-09-17 13:25:47,889:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:47,889:INFO:Creating metrics dataframe
2024-09-17 13:25:47,893:INFO:Initializing Quadratic Discriminant Analysis
2024-09-17 13:25:47,893:INFO:Total runtime is 1.1876891215642291 minutes
2024-09-17 13:25:47,895:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:47,895:INFO:Initializing create_model()
2024-09-17 13:25:47,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:47,895:INFO:Checking exceptions
2024-09-17 13:25:47,895:INFO:Importing libraries
2024-09-17 13:25:47,895:INFO:Copying training dataset
2024-09-17 13:25:47,976:INFO:Defining folds
2024-09-17 13:25:47,976:INFO:Declaring metric variables
2024-09-17 13:25:47,981:INFO:Importing untrained model
2024-09-17 13:25:47,983:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-17 13:25:47,987:INFO:Starting cross validation
2024-09-17 13:25:47,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:48,372:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,380:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,488:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,557:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,622:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,735:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,763:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,787:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,839:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,893:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:48,905:INFO:Calculating mean and std
2024-09-17 13:25:48,906:INFO:Creating metrics dataframe
2024-09-17 13:25:48,907:INFO:Uploading results into container
2024-09-17 13:25:48,907:INFO:Uploading model into container now
2024-09-17 13:25:48,908:INFO:_master_model_container: 8
2024-09-17 13:25:48,908:INFO:_display_container: 2
2024-09-17 13:25:48,908:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-17 13:25:48,908:INFO:create_model() successfully completed......................................
2024-09-17 13:25:48,966:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:48,966:INFO:Creating metrics dataframe
2024-09-17 13:25:48,970:INFO:Initializing Ada Boost Classifier
2024-09-17 13:25:48,970:INFO:Total runtime is 1.2056419332822161 minutes
2024-09-17 13:25:48,971:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:48,972:INFO:Initializing create_model()
2024-09-17 13:25:48,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:48,972:INFO:Checking exceptions
2024-09-17 13:25:48,972:INFO:Importing libraries
2024-09-17 13:25:48,972:INFO:Copying training dataset
2024-09-17 13:25:49,030:INFO:Defining folds
2024-09-17 13:25:49,030:INFO:Declaring metric variables
2024-09-17 13:25:49,032:INFO:Importing untrained model
2024-09-17 13:25:49,034:INFO:Ada Boost Classifier Imported successfully
2024-09-17 13:25:49,036:INFO:Starting cross validation
2024-09-17 13:25:49,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:25:49,188:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,242:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,284:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,362:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,386:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,480:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,625:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:49,736:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:52,974:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,125:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,125:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,225:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,233:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:53,303:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,342:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,368:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:25:53,429:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:53,496:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:55,471:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:55,540:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:25:55,556:INFO:Calculating mean and std
2024-09-17 13:25:55,557:INFO:Creating metrics dataframe
2024-09-17 13:25:55,558:INFO:Uploading results into container
2024-09-17 13:25:55,558:INFO:Uploading model into container now
2024-09-17 13:25:55,559:INFO:_master_model_container: 9
2024-09-17 13:25:55,559:INFO:_display_container: 2
2024-09-17 13:25:55,560:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-17 13:25:55,560:INFO:create_model() successfully completed......................................
2024-09-17 13:25:55,625:INFO:SubProcess create_model() end ==================================
2024-09-17 13:25:55,625:INFO:Creating metrics dataframe
2024-09-17 13:25:55,629:INFO:Initializing Gradient Boosting Classifier
2024-09-17 13:25:55,629:INFO:Total runtime is 1.316619519392649 minutes
2024-09-17 13:25:55,630:INFO:SubProcess create_model() called ==================================
2024-09-17 13:25:55,630:INFO:Initializing create_model()
2024-09-17 13:25:55,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:25:55,630:INFO:Checking exceptions
2024-09-17 13:25:55,630:INFO:Importing libraries
2024-09-17 13:25:55,631:INFO:Copying training dataset
2024-09-17 13:25:55,698:INFO:Defining folds
2024-09-17 13:25:55,698:INFO:Declaring metric variables
2024-09-17 13:25:55,700:INFO:Importing untrained model
2024-09-17 13:25:55,702:INFO:Gradient Boosting Classifier Imported successfully
2024-09-17 13:25:55,705:INFO:Starting cross validation
2024-09-17 13:25:55,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:26:42,041:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,115:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,224:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,311:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,366:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,520:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,523:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:26:42,524:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:10,624:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:10,675:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:10,692:INFO:Calculating mean and std
2024-09-17 13:27:10,694:INFO:Creating metrics dataframe
2024-09-17 13:27:10,696:INFO:Uploading results into container
2024-09-17 13:27:10,696:INFO:Uploading model into container now
2024-09-17 13:27:10,697:INFO:_master_model_container: 10
2024-09-17 13:27:10,697:INFO:_display_container: 2
2024-09-17 13:27:10,698:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-17 13:27:10,698:INFO:create_model() successfully completed......................................
2024-09-17 13:27:10,799:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:10,799:INFO:Creating metrics dataframe
2024-09-17 13:27:10,806:INFO:Initializing Linear Discriminant Analysis
2024-09-17 13:27:10,806:INFO:Total runtime is 2.569569687048594 minutes
2024-09-17 13:27:10,809:INFO:SubProcess create_model() called ==================================
2024-09-17 13:27:10,809:INFO:Initializing create_model()
2024-09-17 13:27:10,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:10,809:INFO:Checking exceptions
2024-09-17 13:27:10,809:INFO:Importing libraries
2024-09-17 13:27:10,809:INFO:Copying training dataset
2024-09-17 13:27:10,863:INFO:Defining folds
2024-09-17 13:27:10,864:INFO:Declaring metric variables
2024-09-17 13:27:10,865:INFO:Importing untrained model
2024-09-17 13:27:10,867:INFO:Linear Discriminant Analysis Imported successfully
2024-09-17 13:27:10,870:INFO:Starting cross validation
2024-09-17 13:27:10,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:27:11,152:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,156:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,241:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,283:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,344:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,414:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,424:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,491:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,534:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,575:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:27:11,590:INFO:Calculating mean and std
2024-09-17 13:27:11,591:INFO:Creating metrics dataframe
2024-09-17 13:27:11,592:INFO:Uploading results into container
2024-09-17 13:27:11,592:INFO:Uploading model into container now
2024-09-17 13:27:11,592:INFO:_master_model_container: 11
2024-09-17 13:27:11,592:INFO:_display_container: 2
2024-09-17 13:27:11,593:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-17 13:27:11,593:INFO:create_model() successfully completed......................................
2024-09-17 13:27:11,651:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:11,651:INFO:Creating metrics dataframe
2024-09-17 13:27:11,655:INFO:Initializing Extra Trees Classifier
2024-09-17 13:27:11,656:INFO:Total runtime is 2.5837334394454956 minutes
2024-09-17 13:27:11,657:INFO:SubProcess create_model() called ==================================
2024-09-17 13:27:11,657:INFO:Initializing create_model()
2024-09-17 13:27:11,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:11,657:INFO:Checking exceptions
2024-09-17 13:27:11,657:INFO:Importing libraries
2024-09-17 13:27:11,657:INFO:Copying training dataset
2024-09-17 13:27:11,701:INFO:Defining folds
2024-09-17 13:27:11,701:INFO:Declaring metric variables
2024-09-17 13:27:11,703:INFO:Importing untrained model
2024-09-17 13:27:11,706:INFO:Extra Trees Classifier Imported successfully
2024-09-17 13:27:11,709:INFO:Starting cross validation
2024-09-17 13:27:11,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:27:26,119:INFO:Calculating mean and std
2024-09-17 13:27:26,123:INFO:Creating metrics dataframe
2024-09-17 13:27:26,128:INFO:Uploading results into container
2024-09-17 13:27:26,128:INFO:Uploading model into container now
2024-09-17 13:27:26,129:INFO:_master_model_container: 12
2024-09-17 13:27:26,129:INFO:_display_container: 2
2024-09-17 13:27:26,130:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-17 13:27:26,130:INFO:create_model() successfully completed......................................
2024-09-17 13:27:26,235:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:26,235:INFO:Creating metrics dataframe
2024-09-17 13:27:26,242:INFO:Initializing Extreme Gradient Boosting
2024-09-17 13:27:26,242:INFO:Total runtime is 2.8268436868985494 minutes
2024-09-17 13:27:26,245:INFO:SubProcess create_model() called ==================================
2024-09-17 13:27:26,245:INFO:Initializing create_model()
2024-09-17 13:27:26,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:26,246:INFO:Checking exceptions
2024-09-17 13:27:26,246:INFO:Importing libraries
2024-09-17 13:27:26,246:INFO:Copying training dataset
2024-09-17 13:27:26,318:INFO:Defining folds
2024-09-17 13:27:26,318:INFO:Declaring metric variables
2024-09-17 13:27:26,324:INFO:Importing untrained model
2024-09-17 13:27:26,327:INFO:Extreme Gradient Boosting Imported successfully
2024-09-17 13:27:26,331:INFO:Starting cross validation
2024-09-17 13:27:26,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:27:26,843:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-17 13:27:33,505:INFO:Calculating mean and std
2024-09-17 13:27:33,507:INFO:Creating metrics dataframe
2024-09-17 13:27:33,510:INFO:Uploading results into container
2024-09-17 13:27:33,510:INFO:Uploading model into container now
2024-09-17 13:27:33,511:INFO:_master_model_container: 13
2024-09-17 13:27:33,512:INFO:_display_container: 2
2024-09-17 13:27:33,513:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-17 13:27:33,513:INFO:create_model() successfully completed......................................
2024-09-17 13:27:33,599:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:33,600:INFO:Creating metrics dataframe
2024-09-17 13:27:33,605:INFO:Initializing Light Gradient Boosting Machine
2024-09-17 13:27:33,606:INFO:Total runtime is 2.949567770957947 minutes
2024-09-17 13:27:33,609:INFO:SubProcess create_model() called ==================================
2024-09-17 13:27:33,609:INFO:Initializing create_model()
2024-09-17 13:27:33,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:33,609:INFO:Checking exceptions
2024-09-17 13:27:33,609:INFO:Importing libraries
2024-09-17 13:27:33,609:INFO:Copying training dataset
2024-09-17 13:27:33,667:INFO:Defining folds
2024-09-17 13:27:33,667:INFO:Declaring metric variables
2024-09-17 13:27:33,669:INFO:Importing untrained model
2024-09-17 13:27:33,672:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-17 13:27:33,675:INFO:Starting cross validation
2024-09-17 13:27:33,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:27:49,452:INFO:Calculating mean and std
2024-09-17 13:27:49,453:INFO:Creating metrics dataframe
2024-09-17 13:27:49,454:INFO:Uploading results into container
2024-09-17 13:27:49,455:INFO:Uploading model into container now
2024-09-17 13:27:49,455:INFO:_master_model_container: 14
2024-09-17 13:27:49,455:INFO:_display_container: 2
2024-09-17 13:27:49,455:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-17 13:27:49,456:INFO:create_model() successfully completed......................................
2024-09-17 13:27:49,525:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:49,525:INFO:Creating metrics dataframe
2024-09-17 13:27:49,531:INFO:Initializing Dummy Classifier
2024-09-17 13:27:49,531:INFO:Total runtime is 3.2149956901868184 minutes
2024-09-17 13:27:49,533:INFO:SubProcess create_model() called ==================================
2024-09-17 13:27:49,533:INFO:Initializing create_model()
2024-09-17 13:27:49,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x328b65840>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:49,534:INFO:Checking exceptions
2024-09-17 13:27:49,534:INFO:Importing libraries
2024-09-17 13:27:49,534:INFO:Copying training dataset
2024-09-17 13:27:49,598:INFO:Defining folds
2024-09-17 13:27:49,598:INFO:Declaring metric variables
2024-09-17 13:27:49,602:INFO:Importing untrained model
2024-09-17 13:27:49,604:INFO:Dummy Classifier Imported successfully
2024-09-17 13:27:49,608:INFO:Starting cross validation
2024-09-17 13:27:49,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:27:49,825:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:49,870:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:49,906:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:49,935:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:49,970:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,015:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,095:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,101:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,154:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,159:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:27:50,178:INFO:Calculating mean and std
2024-09-17 13:27:50,178:INFO:Creating metrics dataframe
2024-09-17 13:27:50,179:INFO:Uploading results into container
2024-09-17 13:27:50,180:INFO:Uploading model into container now
2024-09-17 13:27:50,180:INFO:_master_model_container: 15
2024-09-17 13:27:50,180:INFO:_display_container: 2
2024-09-17 13:27:50,181:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-17 13:27:50,181:INFO:create_model() successfully completed......................................
2024-09-17 13:27:50,241:INFO:SubProcess create_model() end ==================================
2024-09-17 13:27:50,242:INFO:Creating metrics dataframe
2024-09-17 13:27:50,249:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-17 13:27:50,252:INFO:Initializing create_model()
2024-09-17 13:27:50,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x3440d70a0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:27:50,252:INFO:Checking exceptions
2024-09-17 13:27:50,254:INFO:Importing libraries
2024-09-17 13:27:50,254:INFO:Copying training dataset
2024-09-17 13:27:50,315:INFO:Defining folds
2024-09-17 13:27:50,315:INFO:Declaring metric variables
2024-09-17 13:27:50,316:INFO:Importing untrained model
2024-09-17 13:27:50,316:INFO:Declaring custom model
2024-09-17 13:27:50,316:INFO:Random Forest Classifier Imported successfully
2024-09-17 13:27:50,316:INFO:Cross validation set to False
2024-09-17 13:27:50,316:INFO:Fitting Model
2024-09-17 13:27:52,694:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:27:52,694:INFO:create_model() successfully completed......................................
2024-09-17 13:27:52,772:INFO:_master_model_container: 15
2024-09-17 13:27:52,773:INFO:_display_container: 2
2024-09-17 13:27:52,773:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:27:52,773:INFO:compare_models() successfully completed......................................
2024-09-17 13:27:52,846:WARNING:/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/ipykernel_69031/1780357158.py:5: ExperimentalWarning: plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.
  optuna.visualization.matplotlib.plot_optimization_history(study)

2024-09-17 13:48:16,310:INFO:PyCaret ClassificationExperiment
2024-09-17 13:48:16,312:INFO:Logging name: clf-default-name
2024-09-17 13:48:16,312:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-17 13:48:16,312:INFO:version 3.3.2
2024-09-17 13:48:16,312:INFO:Initializing setup()
2024-09-17 13:48:16,312:INFO:self.USI: c4c4
2024-09-17 13:48:16,312:INFO:self._variable_keys: {'gpu_n_jobs_param', 'fold_groups_param', 'fold_generator', 'X_train', 'y', 'pipeline', 'log_plots_param', 'is_multiclass', 'n_jobs_param', '_available_plots', 'y_train', 'exp_name_log', 'fold_shuffle_param', 'idx', 'html_param', 'USI', 'X_test', 'fix_imbalance', 'data', 'y_test', 'target_param', 'exp_id', 'logging_param', '_ml_usecase', 'gpu_param', 'memory', 'seed', 'X'}
2024-09-17 13:48:16,312:INFO:Checking environment
2024-09-17 13:48:16,312:INFO:python_version: 3.10.14
2024-09-17 13:48:16,312:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-17 13:48:16,312:INFO:machine: arm64
2024-09-17 13:48:16,313:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:48:16,313:INFO:Memory: svmem(total=8589934592, available=2082275328, percent=75.8, used=3531931648, free=204587008, active=1884372992, inactive=1868759040, wired=1647558656)
2024-09-17 13:48:16,313:INFO:Physical Core: 8
2024-09-17 13:48:16,313:INFO:Logical Core: 8
2024-09-17 13:48:16,313:INFO:Checking libraries
2024-09-17 13:48:16,313:INFO:System:
2024-09-17 13:48:16,313:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-17 13:48:16,313:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-17 13:48:16,314:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:48:16,314:INFO:PyCaret required dependencies:
2024-09-17 13:48:16,314:INFO:                 pip: 24.2
2024-09-17 13:48:16,314:INFO:          setuptools: 72.1.0
2024-09-17 13:48:16,314:INFO:             pycaret: 3.3.2
2024-09-17 13:48:16,314:INFO:             IPython: 8.18.1
2024-09-17 13:48:16,314:INFO:          ipywidgets: 8.1.5
2024-09-17 13:48:16,314:INFO:                tqdm: 4.66.5
2024-09-17 13:48:16,314:INFO:               numpy: 1.26.4
2024-09-17 13:48:16,314:INFO:              pandas: 2.1.4
2024-09-17 13:48:16,314:INFO:              jinja2: 3.1.4
2024-09-17 13:48:16,314:INFO:               scipy: 1.11.4
2024-09-17 13:48:16,314:INFO:              joblib: 1.3.2
2024-09-17 13:48:16,314:INFO:             sklearn: 1.4.2
2024-09-17 13:48:16,314:INFO:                pyod: 2.0.2
2024-09-17 13:48:16,314:INFO:            imblearn: 0.12.3
2024-09-17 13:48:16,314:INFO:   category_encoders: 2.6.3
2024-09-17 13:48:16,314:INFO:            lightgbm: 4.5.0
2024-09-17 13:48:16,314:INFO:               numba: 0.60.0
2024-09-17 13:48:16,314:INFO:            requests: 2.32.3
2024-09-17 13:48:16,314:INFO:          matplotlib: 3.7.5
2024-09-17 13:48:16,314:INFO:          scikitplot: 0.3.7
2024-09-17 13:48:16,314:INFO:         yellowbrick: 1.5
2024-09-17 13:48:16,314:INFO:              plotly: 5.24.0
2024-09-17 13:48:16,314:INFO:    plotly-resampler: Not installed
2024-09-17 13:48:16,314:INFO:             kaleido: 0.2.1
2024-09-17 13:48:16,314:INFO:           schemdraw: 0.15
2024-09-17 13:48:16,314:INFO:         statsmodels: 0.14.3
2024-09-17 13:48:16,314:INFO:              sktime: 0.26.0
2024-09-17 13:48:16,314:INFO:               tbats: 1.1.3
2024-09-17 13:48:16,314:INFO:            pmdarima: 2.0.4
2024-09-17 13:48:16,314:INFO:              psutil: 5.9.0
2024-09-17 13:48:16,314:INFO:          markupsafe: 2.1.5
2024-09-17 13:48:16,314:INFO:             pickle5: Not installed
2024-09-17 13:48:16,314:INFO:         cloudpickle: 3.0.0
2024-09-17 13:48:16,314:INFO:         deprecation: 2.1.0
2024-09-17 13:48:16,314:INFO:              xxhash: 3.5.0
2024-09-17 13:48:16,314:INFO:           wurlitzer: 3.1.1
2024-09-17 13:48:16,315:INFO:PyCaret optional dependencies:
2024-09-17 13:48:16,315:INFO:                shap: 0.46.0
2024-09-17 13:48:16,315:INFO:           interpret: Not installed
2024-09-17 13:48:16,315:INFO:                umap: Not installed
2024-09-17 13:48:16,315:INFO:     ydata_profiling: Not installed
2024-09-17 13:48:16,315:INFO:  explainerdashboard: Not installed
2024-09-17 13:48:16,315:INFO:             autoviz: Not installed
2024-09-17 13:48:16,315:INFO:           fairlearn: Not installed
2024-09-17 13:48:16,315:INFO:          deepchecks: Not installed
2024-09-17 13:48:16,315:INFO:             xgboost: 2.1.1
2024-09-17 13:48:16,315:INFO:            catboost: Not installed
2024-09-17 13:48:16,315:INFO:              kmodes: Not installed
2024-09-17 13:48:16,315:INFO:             mlxtend: Not installed
2024-09-17 13:48:16,315:INFO:       statsforecast: Not installed
2024-09-17 13:48:16,315:INFO:        tune_sklearn: Not installed
2024-09-17 13:48:16,315:INFO:                 ray: Not installed
2024-09-17 13:48:16,315:INFO:            hyperopt: Not installed
2024-09-17 13:48:16,315:INFO:              optuna: 4.0.0
2024-09-17 13:48:16,315:INFO:               skopt: Not installed
2024-09-17 13:48:16,315:INFO:              mlflow: Not installed
2024-09-17 13:48:16,315:INFO:              gradio: Not installed
2024-09-17 13:48:16,315:INFO:             fastapi: Not installed
2024-09-17 13:48:16,315:INFO:             uvicorn: Not installed
2024-09-17 13:48:16,315:INFO:              m2cgen: Not installed
2024-09-17 13:48:16,315:INFO:           evidently: Not installed
2024-09-17 13:48:16,315:INFO:               fugue: Not installed
2024-09-17 13:48:16,315:INFO:           streamlit: 1.38.0
2024-09-17 13:48:16,315:INFO:             prophet: Not installed
2024-09-17 13:48:16,315:INFO:None
2024-09-17 13:48:16,315:INFO:Set up data.
2024-09-17 13:48:16,348:INFO:Set up folding strategy.
2024-09-17 13:48:16,348:INFO:Set up train/test split.
2024-09-17 13:48:16,386:INFO:Set up index.
2024-09-17 13:48:16,389:INFO:Assigning column types.
2024-09-17 13:48:16,404:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-17 13:48:16,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,423:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,435:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,466:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,467:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-17 13:48:16,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,497:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:48:16,529:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,530:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,530:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-17 13:48:16,561:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,591:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:16,594:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:16,594:INFO:Preparing preprocessing pipeline...
2024-09-17 13:48:16,598:INFO:Set up label encoding.
2024-09-17 13:48:16,598:INFO:Set up simple imputation.
2024-09-17 13:48:16,601:INFO:Set up column name cleaning.
2024-09-17 13:48:17,277:INFO:Finished creating preprocessing pipeline.
2024-09-17 13:48:17,279:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-17 13:48:17,279:INFO:Creating final display dataframe.
2024-09-17 13:48:17,788:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               c4c4
2024-09-17 13:48:17,823:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:17,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:17,855:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:48:17,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:48:17,856:INFO:setup() successfully completed in 1.55s...............
2024-09-17 13:48:17,870:INFO:Initializing compare_models()
2024-09-17 13:48:17,870:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-17 13:48:17,870:INFO:Checking exceptions
2024-09-17 13:48:17,892:INFO:Preparing display monitor
2024-09-17 13:48:17,904:INFO:Initializing Logistic Regression
2024-09-17 13:48:17,904:INFO:Total runtime is 2.4318695068359373e-06 minutes
2024-09-17 13:48:17,905:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:17,905:INFO:Initializing create_model()
2024-09-17 13:48:17,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:17,906:INFO:Checking exceptions
2024-09-17 13:48:17,906:INFO:Importing libraries
2024-09-17 13:48:17,906:INFO:Copying training dataset
2024-09-17 13:48:17,971:INFO:Defining folds
2024-09-17 13:48:17,971:INFO:Declaring metric variables
2024-09-17 13:48:17,973:INFO:Importing untrained model
2024-09-17 13:48:17,975:INFO:Logistic Regression Imported successfully
2024-09-17 13:48:17,979:INFO:Starting cross validation
2024-09-17 13:48:17,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:30,518:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:30,596:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:30,769:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:30,806:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:30,832:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:30,852:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:30,906:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:30,948:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:30,951:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:31,027:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:31,140:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:31,252:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:31,376:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:31,385:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:31,433:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:31,436:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:36,053:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:36,054:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:48:36,082:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:36,082:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:36,146:INFO:Calculating mean and std
2024-09-17 13:48:36,151:INFO:Creating metrics dataframe
2024-09-17 13:48:36,156:INFO:Uploading results into container
2024-09-17 13:48:36,156:INFO:Uploading model into container now
2024-09-17 13:48:36,157:INFO:_master_model_container: 1
2024-09-17 13:48:36,157:INFO:_display_container: 2
2024-09-17 13:48:36,158:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-17 13:48:36,159:INFO:create_model() successfully completed......................................
2024-09-17 13:48:36,288:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:36,288:INFO:Creating metrics dataframe
2024-09-17 13:48:36,291:INFO:Initializing K Neighbors Classifier
2024-09-17 13:48:36,291:INFO:Total runtime is 0.3064560015996297 minutes
2024-09-17 13:48:36,292:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:36,293:INFO:Initializing create_model()
2024-09-17 13:48:36,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:36,293:INFO:Checking exceptions
2024-09-17 13:48:36,293:INFO:Importing libraries
2024-09-17 13:48:36,293:INFO:Copying training dataset
2024-09-17 13:48:36,337:INFO:Defining folds
2024-09-17 13:48:36,337:INFO:Declaring metric variables
2024-09-17 13:48:36,339:INFO:Importing untrained model
2024-09-17 13:48:36,341:INFO:K Neighbors Classifier Imported successfully
2024-09-17 13:48:36,344:INFO:Starting cross validation
2024-09-17 13:48:36,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:44,472:INFO:Calculating mean and std
2024-09-17 13:48:44,474:INFO:Creating metrics dataframe
2024-09-17 13:48:44,477:INFO:Uploading results into container
2024-09-17 13:48:44,477:INFO:Uploading model into container now
2024-09-17 13:48:44,478:INFO:_master_model_container: 2
2024-09-17 13:48:44,478:INFO:_display_container: 2
2024-09-17 13:48:44,478:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-17 13:48:44,478:INFO:create_model() successfully completed......................................
2024-09-17 13:48:44,603:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:44,604:INFO:Creating metrics dataframe
2024-09-17 13:48:44,608:INFO:Initializing Naive Bayes
2024-09-17 13:48:44,608:INFO:Total runtime is 0.44507086674372354 minutes
2024-09-17 13:48:44,610:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:44,610:INFO:Initializing create_model()
2024-09-17 13:48:44,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:44,611:INFO:Checking exceptions
2024-09-17 13:48:44,611:INFO:Importing libraries
2024-09-17 13:48:44,611:INFO:Copying training dataset
2024-09-17 13:48:44,654:INFO:Defining folds
2024-09-17 13:48:44,654:INFO:Declaring metric variables
2024-09-17 13:48:44,656:INFO:Importing untrained model
2024-09-17 13:48:44,658:INFO:Naive Bayes Imported successfully
2024-09-17 13:48:44,661:INFO:Starting cross validation
2024-09-17 13:48:44,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:45,257:INFO:Calculating mean and std
2024-09-17 13:48:45,258:INFO:Creating metrics dataframe
2024-09-17 13:48:45,259:INFO:Uploading results into container
2024-09-17 13:48:45,260:INFO:Uploading model into container now
2024-09-17 13:48:45,260:INFO:_master_model_container: 3
2024-09-17 13:48:45,260:INFO:_display_container: 2
2024-09-17 13:48:45,260:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-17 13:48:45,260:INFO:create_model() successfully completed......................................
2024-09-17 13:48:45,335:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:45,335:INFO:Creating metrics dataframe
2024-09-17 13:48:45,338:INFO:Initializing Decision Tree Classifier
2024-09-17 13:48:45,338:INFO:Total runtime is 0.4572420318921407 minutes
2024-09-17 13:48:45,340:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:45,340:INFO:Initializing create_model()
2024-09-17 13:48:45,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:45,340:INFO:Checking exceptions
2024-09-17 13:48:45,340:INFO:Importing libraries
2024-09-17 13:48:45,340:INFO:Copying training dataset
2024-09-17 13:48:45,380:INFO:Defining folds
2024-09-17 13:48:45,380:INFO:Declaring metric variables
2024-09-17 13:48:45,381:INFO:Importing untrained model
2024-09-17 13:48:45,384:INFO:Decision Tree Classifier Imported successfully
2024-09-17 13:48:45,386:INFO:Starting cross validation
2024-09-17 13:48:45,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:47,297:INFO:Calculating mean and std
2024-09-17 13:48:47,298:INFO:Creating metrics dataframe
2024-09-17 13:48:47,301:INFO:Uploading results into container
2024-09-17 13:48:47,301:INFO:Uploading model into container now
2024-09-17 13:48:47,302:INFO:_master_model_container: 4
2024-09-17 13:48:47,302:INFO:_display_container: 2
2024-09-17 13:48:47,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-17 13:48:47,302:INFO:create_model() successfully completed......................................
2024-09-17 13:48:47,432:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:47,432:INFO:Creating metrics dataframe
2024-09-17 13:48:47,436:INFO:Initializing SVM - Linear Kernel
2024-09-17 13:48:47,436:INFO:Total runtime is 0.49220944643020625 minutes
2024-09-17 13:48:47,438:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:47,438:INFO:Initializing create_model()
2024-09-17 13:48:47,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:47,438:INFO:Checking exceptions
2024-09-17 13:48:47,438:INFO:Importing libraries
2024-09-17 13:48:47,438:INFO:Copying training dataset
2024-09-17 13:48:47,481:INFO:Defining folds
2024-09-17 13:48:47,481:INFO:Declaring metric variables
2024-09-17 13:48:47,483:INFO:Importing untrained model
2024-09-17 13:48:47,486:INFO:SVM - Linear Kernel Imported successfully
2024-09-17 13:48:47,489:INFO:Starting cross validation
2024-09-17 13:48:47,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:55,469:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:55,476:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:56,012:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:56,017:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:56,611:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:56,616:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:56,809:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:56,814:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:56,975:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:56,980:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:57,394:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:57,401:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:57,629:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:57,635:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:57,712:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:58,797:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:58,803:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:48:58,864:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:58,876:INFO:Calculating mean and std
2024-09-17 13:48:58,878:INFO:Creating metrics dataframe
2024-09-17 13:48:58,881:INFO:Uploading results into container
2024-09-17 13:48:58,882:INFO:Uploading model into container now
2024-09-17 13:48:58,882:INFO:_master_model_container: 5
2024-09-17 13:48:58,882:INFO:_display_container: 2
2024-09-17 13:48:58,883:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-17 13:48:58,883:INFO:create_model() successfully completed......................................
2024-09-17 13:48:59,016:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:59,016:INFO:Creating metrics dataframe
2024-09-17 13:48:59,021:INFO:Initializing Ridge Classifier
2024-09-17 13:48:59,021:INFO:Total runtime is 0.685284932454427 minutes
2024-09-17 13:48:59,023:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:59,023:INFO:Initializing create_model()
2024-09-17 13:48:59,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:59,023:INFO:Checking exceptions
2024-09-17 13:48:59,023:INFO:Importing libraries
2024-09-17 13:48:59,023:INFO:Copying training dataset
2024-09-17 13:48:59,074:INFO:Defining folds
2024-09-17 13:48:59,075:INFO:Declaring metric variables
2024-09-17 13:48:59,077:INFO:Importing untrained model
2024-09-17 13:48:59,079:INFO:Ridge Classifier Imported successfully
2024-09-17 13:48:59,081:INFO:Starting cross validation
2024-09-17 13:48:59,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:48:59,299:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,306:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,371:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,373:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,380:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,416:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,437:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,463:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,477:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,528:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,550:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,611:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,631:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,658:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,676:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,676:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,691:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,703:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:48:59,710:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,728:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:48:59,746:INFO:Calculating mean and std
2024-09-17 13:48:59,747:INFO:Creating metrics dataframe
2024-09-17 13:48:59,748:INFO:Uploading results into container
2024-09-17 13:48:59,749:INFO:Uploading model into container now
2024-09-17 13:48:59,749:INFO:_master_model_container: 6
2024-09-17 13:48:59,749:INFO:_display_container: 2
2024-09-17 13:48:59,749:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-17 13:48:59,749:INFO:create_model() successfully completed......................................
2024-09-17 13:48:59,832:INFO:SubProcess create_model() end ==================================
2024-09-17 13:48:59,832:INFO:Creating metrics dataframe
2024-09-17 13:48:59,836:INFO:Initializing Random Forest Classifier
2024-09-17 13:48:59,836:INFO:Total runtime is 0.6988687674204508 minutes
2024-09-17 13:48:59,837:INFO:SubProcess create_model() called ==================================
2024-09-17 13:48:59,837:INFO:Initializing create_model()
2024-09-17 13:48:59,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:48:59,837:INFO:Checking exceptions
2024-09-17 13:48:59,837:INFO:Importing libraries
2024-09-17 13:48:59,838:INFO:Copying training dataset
2024-09-17 13:48:59,877:INFO:Defining folds
2024-09-17 13:48:59,877:INFO:Declaring metric variables
2024-09-17 13:48:59,879:INFO:Importing untrained model
2024-09-17 13:48:59,881:INFO:Random Forest Classifier Imported successfully
2024-09-17 13:48:59,884:INFO:Starting cross validation
2024-09-17 13:48:59,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:49:23,645:INFO:Calculating mean and std
2024-09-17 13:49:23,648:INFO:Creating metrics dataframe
2024-09-17 13:49:23,654:INFO:Uploading results into container
2024-09-17 13:49:23,654:INFO:Uploading model into container now
2024-09-17 13:49:23,655:INFO:_master_model_container: 7
2024-09-17 13:49:23,656:INFO:_display_container: 2
2024-09-17 13:49:23,657:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:49:23,657:INFO:create_model() successfully completed......................................
2024-09-17 13:49:23,812:INFO:SubProcess create_model() end ==================================
2024-09-17 13:49:23,812:INFO:Creating metrics dataframe
2024-09-17 13:49:23,816:INFO:Initializing Quadratic Discriminant Analysis
2024-09-17 13:49:23,816:INFO:Total runtime is 1.098542586962382 minutes
2024-09-17 13:49:23,818:INFO:SubProcess create_model() called ==================================
2024-09-17 13:49:23,818:INFO:Initializing create_model()
2024-09-17 13:49:23,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:49:23,818:INFO:Checking exceptions
2024-09-17 13:49:23,818:INFO:Importing libraries
2024-09-17 13:49:23,818:INFO:Copying training dataset
2024-09-17 13:49:23,865:INFO:Defining folds
2024-09-17 13:49:23,866:INFO:Declaring metric variables
2024-09-17 13:49:23,868:INFO:Importing untrained model
2024-09-17 13:49:23,871:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-17 13:49:23,875:INFO:Starting cross validation
2024-09-17 13:49:23,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:49:24,155:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,246:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,294:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,368:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,398:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,437:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,494:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,558:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,570:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,618:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:24,634:INFO:Calculating mean and std
2024-09-17 13:49:24,635:INFO:Creating metrics dataframe
2024-09-17 13:49:24,636:INFO:Uploading results into container
2024-09-17 13:49:24,636:INFO:Uploading model into container now
2024-09-17 13:49:24,636:INFO:_master_model_container: 8
2024-09-17 13:49:24,636:INFO:_display_container: 2
2024-09-17 13:49:24,636:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-17 13:49:24,637:INFO:create_model() successfully completed......................................
2024-09-17 13:49:24,711:INFO:SubProcess create_model() end ==================================
2024-09-17 13:49:24,711:INFO:Creating metrics dataframe
2024-09-17 13:49:24,715:INFO:Initializing Ada Boost Classifier
2024-09-17 13:49:24,715:INFO:Total runtime is 1.1135159174601237 minutes
2024-09-17 13:49:24,716:INFO:SubProcess create_model() called ==================================
2024-09-17 13:49:24,716:INFO:Initializing create_model()
2024-09-17 13:49:24,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:49:24,716:INFO:Checking exceptions
2024-09-17 13:49:24,716:INFO:Importing libraries
2024-09-17 13:49:24,716:INFO:Copying training dataset
2024-09-17 13:49:24,757:INFO:Defining folds
2024-09-17 13:49:24,757:INFO:Declaring metric variables
2024-09-17 13:49:24,758:INFO:Importing untrained model
2024-09-17 13:49:24,760:INFO:Ada Boost Classifier Imported successfully
2024-09-17 13:49:24,763:INFO:Starting cross validation
2024-09-17 13:49:24,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:49:24,903:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:24,921:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:24,984:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:25,002:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:25,070:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:25,126:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:25,151:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:25,188:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:28,209:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,228:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,314:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,428:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,444:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,451:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,482:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:28,494:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:28,514:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:49:28,559:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:30,564:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:30,575:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:49:30,590:INFO:Calculating mean and std
2024-09-17 13:49:30,591:INFO:Creating metrics dataframe
2024-09-17 13:49:30,592:INFO:Uploading results into container
2024-09-17 13:49:30,592:INFO:Uploading model into container now
2024-09-17 13:49:30,592:INFO:_master_model_container: 9
2024-09-17 13:49:30,592:INFO:_display_container: 2
2024-09-17 13:49:30,592:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-17 13:49:30,592:INFO:create_model() successfully completed......................................
2024-09-17 13:49:30,666:INFO:SubProcess create_model() end ==================================
2024-09-17 13:49:30,667:INFO:Creating metrics dataframe
2024-09-17 13:49:30,670:INFO:Initializing Gradient Boosting Classifier
2024-09-17 13:49:30,670:INFO:Total runtime is 1.2127766172091166 minutes
2024-09-17 13:49:30,672:INFO:SubProcess create_model() called ==================================
2024-09-17 13:49:30,672:INFO:Initializing create_model()
2024-09-17 13:49:30,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x151b1fb80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x30e941a20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:49:30,672:INFO:Checking exceptions
2024-09-17 13:49:30,672:INFO:Importing libraries
2024-09-17 13:49:30,672:INFO:Copying training dataset
2024-09-17 13:49:30,712:INFO:Defining folds
2024-09-17 13:49:30,712:INFO:Declaring metric variables
2024-09-17 13:49:30,713:INFO:Importing untrained model
2024-09-17 13:49:30,715:INFO:Gradient Boosting Classifier Imported successfully
2024-09-17 13:49:30,718:INFO:Starting cross validation
2024-09-17 13:49:30,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:49:55,630:INFO:PyCaret ClassificationExperiment
2024-09-17 13:49:55,630:INFO:Logging name: clf-default-name
2024-09-17 13:49:55,630:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-17 13:49:55,630:INFO:version 3.3.2
2024-09-17 13:49:55,630:INFO:Initializing setup()
2024-09-17 13:49:55,630:INFO:self.USI: 2726
2024-09-17 13:49:55,630:INFO:self._variable_keys: {'gpu_n_jobs_param', 'fold_groups_param', 'fold_generator', 'X_train', 'y', 'pipeline', 'log_plots_param', 'is_multiclass', 'n_jobs_param', '_available_plots', 'y_train', 'exp_name_log', 'fold_shuffle_param', 'idx', 'html_param', 'USI', 'X_test', 'fix_imbalance', 'data', 'y_test', 'target_param', 'exp_id', 'logging_param', '_ml_usecase', 'gpu_param', 'memory', 'seed', 'X'}
2024-09-17 13:49:55,630:INFO:Checking environment
2024-09-17 13:49:55,630:INFO:python_version: 3.10.14
2024-09-17 13:49:55,631:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-17 13:49:55,631:INFO:machine: arm64
2024-09-17 13:49:55,631:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:49:55,631:INFO:Memory: svmem(total=8589934592, available=3019145216, percent=64.9, used=3293413376, free=1378631680, active=1649065984, inactive=1617526784, wired=1644347392)
2024-09-17 13:49:55,631:INFO:Physical Core: 8
2024-09-17 13:49:55,631:INFO:Logical Core: 8
2024-09-17 13:49:55,631:INFO:Checking libraries
2024-09-17 13:49:55,631:INFO:System:
2024-09-17 13:49:55,631:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-17 13:49:55,631:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-17 13:49:55,631:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-17 13:49:55,631:INFO:PyCaret required dependencies:
2024-09-17 13:49:55,631:INFO:                 pip: 24.2
2024-09-17 13:49:55,631:INFO:          setuptools: 72.1.0
2024-09-17 13:49:55,631:INFO:             pycaret: 3.3.2
2024-09-17 13:49:55,631:INFO:             IPython: 8.18.1
2024-09-17 13:49:55,631:INFO:          ipywidgets: 8.1.5
2024-09-17 13:49:55,631:INFO:                tqdm: 4.66.5
2024-09-17 13:49:55,631:INFO:               numpy: 1.26.4
2024-09-17 13:49:55,631:INFO:              pandas: 2.1.4
2024-09-17 13:49:55,631:INFO:              jinja2: 3.1.4
2024-09-17 13:49:55,631:INFO:               scipy: 1.11.4
2024-09-17 13:49:55,631:INFO:              joblib: 1.3.2
2024-09-17 13:49:55,631:INFO:             sklearn: 1.4.2
2024-09-17 13:49:55,631:INFO:                pyod: 2.0.2
2024-09-17 13:49:55,631:INFO:            imblearn: 0.12.3
2024-09-17 13:49:55,631:INFO:   category_encoders: 2.6.3
2024-09-17 13:49:55,632:INFO:            lightgbm: 4.5.0
2024-09-17 13:49:55,632:INFO:               numba: 0.60.0
2024-09-17 13:49:55,632:INFO:            requests: 2.32.3
2024-09-17 13:49:55,632:INFO:          matplotlib: 3.7.5
2024-09-17 13:49:55,632:INFO:          scikitplot: 0.3.7
2024-09-17 13:49:55,632:INFO:         yellowbrick: 1.5
2024-09-17 13:49:55,632:INFO:              plotly: 5.24.0
2024-09-17 13:49:55,632:INFO:    plotly-resampler: Not installed
2024-09-17 13:49:55,632:INFO:             kaleido: 0.2.1
2024-09-17 13:49:55,632:INFO:           schemdraw: 0.15
2024-09-17 13:49:55,632:INFO:         statsmodels: 0.14.3
2024-09-17 13:49:55,632:INFO:              sktime: 0.26.0
2024-09-17 13:49:55,632:INFO:               tbats: 1.1.3
2024-09-17 13:49:55,632:INFO:            pmdarima: 2.0.4
2024-09-17 13:49:55,632:INFO:              psutil: 5.9.0
2024-09-17 13:49:55,632:INFO:          markupsafe: 2.1.5
2024-09-17 13:49:55,632:INFO:             pickle5: Not installed
2024-09-17 13:49:55,632:INFO:         cloudpickle: 3.0.0
2024-09-17 13:49:55,632:INFO:         deprecation: 2.1.0
2024-09-17 13:49:55,632:INFO:              xxhash: 3.5.0
2024-09-17 13:49:55,632:INFO:           wurlitzer: 3.1.1
2024-09-17 13:49:55,632:INFO:PyCaret optional dependencies:
2024-09-17 13:49:55,632:INFO:                shap: 0.46.0
2024-09-17 13:49:55,632:INFO:           interpret: Not installed
2024-09-17 13:49:55,632:INFO:                umap: Not installed
2024-09-17 13:49:55,632:INFO:     ydata_profiling: Not installed
2024-09-17 13:49:55,632:INFO:  explainerdashboard: Not installed
2024-09-17 13:49:55,632:INFO:             autoviz: Not installed
2024-09-17 13:49:55,632:INFO:           fairlearn: Not installed
2024-09-17 13:49:55,632:INFO:          deepchecks: Not installed
2024-09-17 13:49:55,632:INFO:             xgboost: 2.1.1
2024-09-17 13:49:55,632:INFO:            catboost: Not installed
2024-09-17 13:49:55,632:INFO:              kmodes: Not installed
2024-09-17 13:49:55,632:INFO:             mlxtend: Not installed
2024-09-17 13:49:55,632:INFO:       statsforecast: Not installed
2024-09-17 13:49:55,632:INFO:        tune_sklearn: Not installed
2024-09-17 13:49:55,632:INFO:                 ray: Not installed
2024-09-17 13:49:55,632:INFO:            hyperopt: Not installed
2024-09-17 13:49:55,632:INFO:              optuna: 4.0.0
2024-09-17 13:49:55,632:INFO:               skopt: Not installed
2024-09-17 13:49:55,632:INFO:              mlflow: Not installed
2024-09-17 13:49:55,633:INFO:              gradio: Not installed
2024-09-17 13:49:55,633:INFO:             fastapi: Not installed
2024-09-17 13:49:55,633:INFO:             uvicorn: Not installed
2024-09-17 13:49:55,633:INFO:              m2cgen: Not installed
2024-09-17 13:49:55,633:INFO:           evidently: Not installed
2024-09-17 13:49:55,633:INFO:               fugue: Not installed
2024-09-17 13:49:55,633:INFO:           streamlit: 1.38.0
2024-09-17 13:49:55,633:INFO:             prophet: Not installed
2024-09-17 13:49:55,633:INFO:None
2024-09-17 13:49:55,633:INFO:Set up data.
2024-09-17 13:49:55,659:INFO:Set up folding strategy.
2024-09-17 13:49:55,659:INFO:Set up train/test split.
2024-09-17 13:49:55,697:INFO:Set up index.
2024-09-17 13:49:55,700:INFO:Assigning column types.
2024-09-17 13:49:55,716:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-17 13:49:55,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,747:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,778:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,779:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-17 13:49:55,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,809:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,829:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-17 13:49:55,840:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,841:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-17 13:49:55,872:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,903:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:55,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:55,904:INFO:Preparing preprocessing pipeline...
2024-09-17 13:49:55,908:INFO:Set up label encoding.
2024-09-17 13:49:55,908:INFO:Set up simple imputation.
2024-09-17 13:49:55,910:INFO:Set up column name cleaning.
2024-09-17 13:49:56,540:INFO:Finished creating preprocessing pipeline.
2024-09-17 13:49:56,542:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-17 13:49:56,542:INFO:Creating final display dataframe.
2024-09-17 13:49:57,054:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               2726
2024-09-17 13:49:57,089:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:57,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:57,122:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-17 13:49:57,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-17 13:49:57,124:INFO:setup() successfully completed in 1.5s...............
2024-09-17 13:49:59,463:INFO:Initializing compare_models()
2024-09-17 13:49:59,464:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-17 13:49:59,464:INFO:Checking exceptions
2024-09-17 13:49:59,496:INFO:Preparing display monitor
2024-09-17 13:49:59,509:INFO:Initializing Logistic Regression
2024-09-17 13:49:59,509:INFO:Total runtime is 2.7855237325032553e-06 minutes
2024-09-17 13:49:59,512:INFO:SubProcess create_model() called ==================================
2024-09-17 13:49:59,512:INFO:Initializing create_model()
2024-09-17 13:49:59,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:49:59,512:INFO:Checking exceptions
2024-09-17 13:49:59,512:INFO:Importing libraries
2024-09-17 13:49:59,512:INFO:Copying training dataset
2024-09-17 13:49:59,559:INFO:Defining folds
2024-09-17 13:49:59,559:INFO:Declaring metric variables
2024-09-17 13:49:59,561:INFO:Importing untrained model
2024-09-17 13:49:59,562:INFO:Logistic Regression Imported successfully
2024-09-17 13:49:59,565:INFO:Starting cross validation
2024-09-17 13:49:59,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:13,143:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,157:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,203:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,208:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,296:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,299:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,364:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,368:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,450:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,464:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,499:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,542:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,610:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,693:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:13,705:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:13,749:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:19,253:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:19,281:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:19,318:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-17 13:50:19,339:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:19,356:INFO:Calculating mean and std
2024-09-17 13:50:19,358:INFO:Creating metrics dataframe
2024-09-17 13:50:19,360:INFO:Uploading results into container
2024-09-17 13:50:19,360:INFO:Uploading model into container now
2024-09-17 13:50:19,360:INFO:_master_model_container: 1
2024-09-17 13:50:19,360:INFO:_display_container: 2
2024-09-17 13:50:19,361:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-17 13:50:19,361:INFO:create_model() successfully completed......................................
2024-09-17 13:50:19,473:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:19,473:INFO:Creating metrics dataframe
2024-09-17 13:50:19,477:INFO:Initializing K Neighbors Classifier
2024-09-17 13:50:19,477:INFO:Total runtime is 0.33279903332392374 minutes
2024-09-17 13:50:19,479:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:19,479:INFO:Initializing create_model()
2024-09-17 13:50:19,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:19,479:INFO:Checking exceptions
2024-09-17 13:50:19,479:INFO:Importing libraries
2024-09-17 13:50:19,479:INFO:Copying training dataset
2024-09-17 13:50:19,525:INFO:Defining folds
2024-09-17 13:50:19,525:INFO:Declaring metric variables
2024-09-17 13:50:19,527:INFO:Importing untrained model
2024-09-17 13:50:19,529:INFO:K Neighbors Classifier Imported successfully
2024-09-17 13:50:19,531:INFO:Starting cross validation
2024-09-17 13:50:19,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:28,624:INFO:Calculating mean and std
2024-09-17 13:50:28,626:INFO:Creating metrics dataframe
2024-09-17 13:50:28,629:INFO:Uploading results into container
2024-09-17 13:50:28,629:INFO:Uploading model into container now
2024-09-17 13:50:28,630:INFO:_master_model_container: 2
2024-09-17 13:50:28,631:INFO:_display_container: 2
2024-09-17 13:50:28,632:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-17 13:50:28,632:INFO:create_model() successfully completed......................................
2024-09-17 13:50:28,768:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:28,768:INFO:Creating metrics dataframe
2024-09-17 13:50:28,772:INFO:Initializing Naive Bayes
2024-09-17 13:50:28,772:INFO:Total runtime is 0.48772000074386596 minutes
2024-09-17 13:50:28,775:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:28,775:INFO:Initializing create_model()
2024-09-17 13:50:28,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:28,776:INFO:Checking exceptions
2024-09-17 13:50:28,776:INFO:Importing libraries
2024-09-17 13:50:28,776:INFO:Copying training dataset
2024-09-17 13:50:28,824:INFO:Defining folds
2024-09-17 13:50:28,824:INFO:Declaring metric variables
2024-09-17 13:50:28,827:INFO:Importing untrained model
2024-09-17 13:50:28,829:INFO:Naive Bayes Imported successfully
2024-09-17 13:50:28,831:INFO:Starting cross validation
2024-09-17 13:50:28,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:29,494:INFO:Calculating mean and std
2024-09-17 13:50:29,495:INFO:Creating metrics dataframe
2024-09-17 13:50:29,496:INFO:Uploading results into container
2024-09-17 13:50:29,496:INFO:Uploading model into container now
2024-09-17 13:50:29,496:INFO:_master_model_container: 3
2024-09-17 13:50:29,496:INFO:_display_container: 2
2024-09-17 13:50:29,496:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-17 13:50:29,496:INFO:create_model() successfully completed......................................
2024-09-17 13:50:29,585:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:29,586:INFO:Creating metrics dataframe
2024-09-17 13:50:29,591:INFO:Initializing Decision Tree Classifier
2024-09-17 13:50:29,591:INFO:Total runtime is 0.5013683994611104 minutes
2024-09-17 13:50:29,594:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:29,595:INFO:Initializing create_model()
2024-09-17 13:50:29,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:29,595:INFO:Checking exceptions
2024-09-17 13:50:29,595:INFO:Importing libraries
2024-09-17 13:50:29,595:INFO:Copying training dataset
2024-09-17 13:50:29,642:INFO:Defining folds
2024-09-17 13:50:29,642:INFO:Declaring metric variables
2024-09-17 13:50:29,644:INFO:Importing untrained model
2024-09-17 13:50:29,646:INFO:Decision Tree Classifier Imported successfully
2024-09-17 13:50:29,648:INFO:Starting cross validation
2024-09-17 13:50:29,649:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:31,710:INFO:Calculating mean and std
2024-09-17 13:50:31,711:INFO:Creating metrics dataframe
2024-09-17 13:50:31,712:INFO:Uploading results into container
2024-09-17 13:50:31,712:INFO:Uploading model into container now
2024-09-17 13:50:31,712:INFO:_master_model_container: 4
2024-09-17 13:50:31,712:INFO:_display_container: 2
2024-09-17 13:50:31,712:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-17 13:50:31,712:INFO:create_model() successfully completed......................................
2024-09-17 13:50:31,802:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:31,803:INFO:Creating metrics dataframe
2024-09-17 13:50:31,806:INFO:Initializing SVM - Linear Kernel
2024-09-17 13:50:31,806:INFO:Total runtime is 0.5382871826489767 minutes
2024-09-17 13:50:31,808:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:31,808:INFO:Initializing create_model()
2024-09-17 13:50:31,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:31,808:INFO:Checking exceptions
2024-09-17 13:50:31,808:INFO:Importing libraries
2024-09-17 13:50:31,808:INFO:Copying training dataset
2024-09-17 13:50:31,849:INFO:Defining folds
2024-09-17 13:50:31,849:INFO:Declaring metric variables
2024-09-17 13:50:31,851:INFO:Importing untrained model
2024-09-17 13:50:31,854:INFO:SVM - Linear Kernel Imported successfully
2024-09-17 13:50:31,857:INFO:Starting cross validation
2024-09-17 13:50:31,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:41,550:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:41,564:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:42,043:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:42,054:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:42,633:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:42,642:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:42,645:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:42,651:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:42,853:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:42,861:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:43,335:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:43,344:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:43,683:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:43,683:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:43,692:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:45,225:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,232:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:50:45,290:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,304:INFO:Calculating mean and std
2024-09-17 13:50:45,307:INFO:Creating metrics dataframe
2024-09-17 13:50:45,310:INFO:Uploading results into container
2024-09-17 13:50:45,310:INFO:Uploading model into container now
2024-09-17 13:50:45,311:INFO:_master_model_container: 5
2024-09-17 13:50:45,311:INFO:_display_container: 2
2024-09-17 13:50:45,312:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-17 13:50:45,312:INFO:create_model() successfully completed......................................
2024-09-17 13:50:45,464:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:45,464:INFO:Creating metrics dataframe
2024-09-17 13:50:45,469:INFO:Initializing Ridge Classifier
2024-09-17 13:50:45,469:INFO:Total runtime is 0.7659923156102499 minutes
2024-09-17 13:50:45,471:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:45,471:INFO:Initializing create_model()
2024-09-17 13:50:45,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:45,471:INFO:Checking exceptions
2024-09-17 13:50:45,472:INFO:Importing libraries
2024-09-17 13:50:45,472:INFO:Copying training dataset
2024-09-17 13:50:45,517:INFO:Defining folds
2024-09-17 13:50:45,517:INFO:Declaring metric variables
2024-09-17 13:50:45,518:INFO:Importing untrained model
2024-09-17 13:50:45,521:INFO:Ridge Classifier Imported successfully
2024-09-17 13:50:45,525:INFO:Starting cross validation
2024-09-17 13:50:45,526:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:50:45,705:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,739:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,755:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,796:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,805:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,840:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,863:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,883:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,899:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,944:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,946:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,953:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:45,995:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:45,996:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:46,039:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:46,066:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:46,071:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:46,097:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:46,109:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-17 13:50:46,133:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:50:46,157:INFO:Calculating mean and std
2024-09-17 13:50:46,157:INFO:Creating metrics dataframe
2024-09-17 13:50:46,158:INFO:Uploading results into container
2024-09-17 13:50:46,159:INFO:Uploading model into container now
2024-09-17 13:50:46,159:INFO:_master_model_container: 6
2024-09-17 13:50:46,159:INFO:_display_container: 2
2024-09-17 13:50:46,160:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-17 13:50:46,160:INFO:create_model() successfully completed......................................
2024-09-17 13:50:46,309:INFO:SubProcess create_model() end ==================================
2024-09-17 13:50:46,309:INFO:Creating metrics dataframe
2024-09-17 13:50:46,312:INFO:Initializing Random Forest Classifier
2024-09-17 13:50:46,312:INFO:Total runtime is 0.7800506671269736 minutes
2024-09-17 13:50:46,313:INFO:SubProcess create_model() called ==================================
2024-09-17 13:50:46,314:INFO:Initializing create_model()
2024-09-17 13:50:46,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:50:46,314:INFO:Checking exceptions
2024-09-17 13:50:46,314:INFO:Importing libraries
2024-09-17 13:50:46,314:INFO:Copying training dataset
2024-09-17 13:50:46,358:INFO:Defining folds
2024-09-17 13:50:46,358:INFO:Declaring metric variables
2024-09-17 13:50:46,360:INFO:Importing untrained model
2024-09-17 13:50:46,362:INFO:Random Forest Classifier Imported successfully
2024-09-17 13:50:46,367:INFO:Starting cross validation
2024-09-17 13:50:46,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:51:11,120:INFO:Calculating mean and std
2024-09-17 13:51:11,123:INFO:Creating metrics dataframe
2024-09-17 13:51:11,128:INFO:Uploading results into container
2024-09-17 13:51:11,128:INFO:Uploading model into container now
2024-09-17 13:51:11,129:INFO:_master_model_container: 7
2024-09-17 13:51:11,130:INFO:_display_container: 2
2024-09-17 13:51:11,131:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:51:11,131:INFO:create_model() successfully completed......................................
2024-09-17 13:51:11,321:INFO:SubProcess create_model() end ==================================
2024-09-17 13:51:11,321:INFO:Creating metrics dataframe
2024-09-17 13:51:11,326:INFO:Initializing Quadratic Discriminant Analysis
2024-09-17 13:51:11,326:INFO:Total runtime is 1.1969545165697735 minutes
2024-09-17 13:51:11,328:INFO:SubProcess create_model() called ==================================
2024-09-17 13:51:11,329:INFO:Initializing create_model()
2024-09-17 13:51:11,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:51:11,329:INFO:Checking exceptions
2024-09-17 13:51:11,329:INFO:Importing libraries
2024-09-17 13:51:11,330:INFO:Copying training dataset
2024-09-17 13:51:11,402:INFO:Defining folds
2024-09-17 13:51:11,403:INFO:Declaring metric variables
2024-09-17 13:51:11,405:INFO:Importing untrained model
2024-09-17 13:51:11,408:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-17 13:51:11,412:INFO:Starting cross validation
2024-09-17 13:51:11,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:51:11,758:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:11,810:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:11,851:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:11,886:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:11,982:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,040:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,050:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,112:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,135:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,157:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:12,182:INFO:Calculating mean and std
2024-09-17 13:51:12,182:INFO:Creating metrics dataframe
2024-09-17 13:51:12,183:INFO:Uploading results into container
2024-09-17 13:51:12,183:INFO:Uploading model into container now
2024-09-17 13:51:12,184:INFO:_master_model_container: 8
2024-09-17 13:51:12,184:INFO:_display_container: 2
2024-09-17 13:51:12,184:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-17 13:51:12,184:INFO:create_model() successfully completed......................................
2024-09-17 13:51:12,269:INFO:SubProcess create_model() end ==================================
2024-09-17 13:51:12,269:INFO:Creating metrics dataframe
2024-09-17 13:51:12,274:INFO:Initializing Ada Boost Classifier
2024-09-17 13:51:12,274:INFO:Total runtime is 1.2127450823783876 minutes
2024-09-17 13:51:12,275:INFO:SubProcess create_model() called ==================================
2024-09-17 13:51:12,275:INFO:Initializing create_model()
2024-09-17 13:51:12,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:51:12,275:INFO:Checking exceptions
2024-09-17 13:51:12,276:INFO:Importing libraries
2024-09-17 13:51:12,276:INFO:Copying training dataset
2024-09-17 13:51:12,317:INFO:Defining folds
2024-09-17 13:51:12,317:INFO:Declaring metric variables
2024-09-17 13:51:12,320:INFO:Importing untrained model
2024-09-17 13:51:12,322:INFO:Ada Boost Classifier Imported successfully
2024-09-17 13:51:12,324:INFO:Starting cross validation
2024-09-17 13:51:12,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:51:12,473:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,517:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,559:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,591:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,641:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,681:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,720:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:12,793:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:16,053:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,118:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,124:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,128:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,175:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,204:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,246:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:16,268:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,301:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:16,312:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-17 13:51:18,467:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:18,538:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:51:18,563:INFO:Calculating mean and std
2024-09-17 13:51:18,564:INFO:Creating metrics dataframe
2024-09-17 13:51:18,565:INFO:Uploading results into container
2024-09-17 13:51:18,565:INFO:Uploading model into container now
2024-09-17 13:51:18,566:INFO:_master_model_container: 9
2024-09-17 13:51:18,566:INFO:_display_container: 2
2024-09-17 13:51:18,566:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-17 13:51:18,566:INFO:create_model() successfully completed......................................
2024-09-17 13:51:18,657:INFO:SubProcess create_model() end ==================================
2024-09-17 13:51:18,657:INFO:Creating metrics dataframe
2024-09-17 13:51:18,661:INFO:Initializing Gradient Boosting Classifier
2024-09-17 13:51:18,662:INFO:Total runtime is 1.3192060828208925 minutes
2024-09-17 13:51:18,663:INFO:SubProcess create_model() called ==================================
2024-09-17 13:51:18,663:INFO:Initializing create_model()
2024-09-17 13:51:18,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:51:18,663:INFO:Checking exceptions
2024-09-17 13:51:18,663:INFO:Importing libraries
2024-09-17 13:51:18,663:INFO:Copying training dataset
2024-09-17 13:51:18,712:INFO:Defining folds
2024-09-17 13:51:18,712:INFO:Declaring metric variables
2024-09-17 13:51:18,716:INFO:Importing untrained model
2024-09-17 13:51:18,726:INFO:Gradient Boosting Classifier Imported successfully
2024-09-17 13:51:18,736:INFO:Starting cross validation
2024-09-17 13:51:18,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:52:07,988:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,181:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,280:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,397:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,609:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,636:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,673:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:08,716:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:36,642:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:36,774:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:36,788:INFO:Calculating mean and std
2024-09-17 13:52:36,790:INFO:Creating metrics dataframe
2024-09-17 13:52:36,792:INFO:Uploading results into container
2024-09-17 13:52:36,793:INFO:Uploading model into container now
2024-09-17 13:52:36,793:INFO:_master_model_container: 10
2024-09-17 13:52:36,793:INFO:_display_container: 2
2024-09-17 13:52:36,794:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-17 13:52:36,794:INFO:create_model() successfully completed......................................
2024-09-17 13:52:36,909:INFO:SubProcess create_model() end ==================================
2024-09-17 13:52:36,909:INFO:Creating metrics dataframe
2024-09-17 13:52:36,915:INFO:Initializing Linear Discriminant Analysis
2024-09-17 13:52:36,915:INFO:Total runtime is 2.6234323143959046 minutes
2024-09-17 13:52:36,917:INFO:SubProcess create_model() called ==================================
2024-09-17 13:52:36,917:INFO:Initializing create_model()
2024-09-17 13:52:36,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:52:36,917:INFO:Checking exceptions
2024-09-17 13:52:36,917:INFO:Importing libraries
2024-09-17 13:52:36,917:INFO:Copying training dataset
2024-09-17 13:52:36,990:INFO:Defining folds
2024-09-17 13:52:36,990:INFO:Declaring metric variables
2024-09-17 13:52:36,992:INFO:Importing untrained model
2024-09-17 13:52:36,994:INFO:Linear Discriminant Analysis Imported successfully
2024-09-17 13:52:36,996:INFO:Starting cross validation
2024-09-17 13:52:36,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:52:37,274:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,310:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,332:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,432:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,439:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,473:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,513:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,531:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,568:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,602:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-17 13:52:37,623:INFO:Calculating mean and std
2024-09-17 13:52:37,623:INFO:Creating metrics dataframe
2024-09-17 13:52:37,624:INFO:Uploading results into container
2024-09-17 13:52:37,624:INFO:Uploading model into container now
2024-09-17 13:52:37,625:INFO:_master_model_container: 11
2024-09-17 13:52:37,625:INFO:_display_container: 2
2024-09-17 13:52:37,625:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-17 13:52:37,625:INFO:create_model() successfully completed......................................
2024-09-17 13:52:37,709:INFO:SubProcess create_model() end ==================================
2024-09-17 13:52:37,709:INFO:Creating metrics dataframe
2024-09-17 13:52:37,713:INFO:Initializing Extra Trees Classifier
2024-09-17 13:52:37,713:INFO:Total runtime is 2.636735781033834 minutes
2024-09-17 13:52:37,715:INFO:SubProcess create_model() called ==================================
2024-09-17 13:52:37,715:INFO:Initializing create_model()
2024-09-17 13:52:37,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:52:37,715:INFO:Checking exceptions
2024-09-17 13:52:37,715:INFO:Importing libraries
2024-09-17 13:52:37,715:INFO:Copying training dataset
2024-09-17 13:52:37,756:INFO:Defining folds
2024-09-17 13:52:37,756:INFO:Declaring metric variables
2024-09-17 13:52:37,758:INFO:Importing untrained model
2024-09-17 13:52:37,759:INFO:Extra Trees Classifier Imported successfully
2024-09-17 13:52:37,763:INFO:Starting cross validation
2024-09-17 13:52:37,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:52:51,059:INFO:Calculating mean and std
2024-09-17 13:52:51,063:INFO:Creating metrics dataframe
2024-09-17 13:52:51,067:INFO:Uploading results into container
2024-09-17 13:52:51,068:INFO:Uploading model into container now
2024-09-17 13:52:51,069:INFO:_master_model_container: 12
2024-09-17 13:52:51,069:INFO:_display_container: 2
2024-09-17 13:52:51,070:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-17 13:52:51,070:INFO:create_model() successfully completed......................................
2024-09-17 13:52:51,207:INFO:SubProcess create_model() end ==================================
2024-09-17 13:52:51,207:INFO:Creating metrics dataframe
2024-09-17 13:52:51,212:INFO:Initializing Extreme Gradient Boosting
2024-09-17 13:52:51,212:INFO:Total runtime is 2.8617117524147035 minutes
2024-09-17 13:52:51,214:INFO:SubProcess create_model() called ==================================
2024-09-17 13:52:51,215:INFO:Initializing create_model()
2024-09-17 13:52:51,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:52:51,215:INFO:Checking exceptions
2024-09-17 13:52:51,215:INFO:Importing libraries
2024-09-17 13:52:51,215:INFO:Copying training dataset
2024-09-17 13:52:51,270:INFO:Defining folds
2024-09-17 13:52:51,270:INFO:Declaring metric variables
2024-09-17 13:52:51,272:INFO:Importing untrained model
2024-09-17 13:52:51,275:INFO:Extreme Gradient Boosting Imported successfully
2024-09-17 13:52:51,278:INFO:Starting cross validation
2024-09-17 13:52:51,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:52:51,745:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning:

A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.


2024-09-17 13:52:57,734:INFO:Calculating mean and std
2024-09-17 13:52:57,736:INFO:Creating metrics dataframe
2024-09-17 13:52:57,739:INFO:Uploading results into container
2024-09-17 13:52:57,739:INFO:Uploading model into container now
2024-09-17 13:52:57,741:INFO:_master_model_container: 13
2024-09-17 13:52:57,741:INFO:_display_container: 2
2024-09-17 13:52:57,742:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-17 13:52:57,742:INFO:create_model() successfully completed......................................
2024-09-17 13:52:57,837:INFO:SubProcess create_model() end ==================================
2024-09-17 13:52:57,837:INFO:Creating metrics dataframe
2024-09-17 13:52:57,841:INFO:Initializing Light Gradient Boosting Machine
2024-09-17 13:52:57,841:INFO:Total runtime is 2.9722021857897443 minutes
2024-09-17 13:52:57,843:INFO:SubProcess create_model() called ==================================
2024-09-17 13:52:57,843:INFO:Initializing create_model()
2024-09-17 13:52:57,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:52:57,843:INFO:Checking exceptions
2024-09-17 13:52:57,843:INFO:Importing libraries
2024-09-17 13:52:57,843:INFO:Copying training dataset
2024-09-17 13:52:57,884:INFO:Defining folds
2024-09-17 13:52:57,884:INFO:Declaring metric variables
2024-09-17 13:52:57,886:INFO:Importing untrained model
2024-09-17 13:52:57,887:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-17 13:52:57,890:INFO:Starting cross validation
2024-09-17 13:52:57,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:53:13,358:INFO:Calculating mean and std
2024-09-17 13:53:13,359:INFO:Creating metrics dataframe
2024-09-17 13:53:13,360:INFO:Uploading results into container
2024-09-17 13:53:13,361:INFO:Uploading model into container now
2024-09-17 13:53:13,362:INFO:_master_model_container: 14
2024-09-17 13:53:13,362:INFO:_display_container: 2
2024-09-17 13:53:13,363:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-17 13:53:13,363:INFO:create_model() successfully completed......................................
2024-09-17 13:53:13,462:INFO:SubProcess create_model() end ==================================
2024-09-17 13:53:13,462:INFO:Creating metrics dataframe
2024-09-17 13:53:13,468:INFO:Initializing Dummy Classifier
2024-09-17 13:53:13,468:INFO:Total runtime is 3.23264749844869 minutes
2024-09-17 13:53:13,470:INFO:SubProcess create_model() called ==================================
2024-09-17 13:53:13,470:INFO:Initializing create_model()
2024-09-17 13:53:13,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x151a6b850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:53:13,470:INFO:Checking exceptions
2024-09-17 13:53:13,471:INFO:Importing libraries
2024-09-17 13:53:13,471:INFO:Copying training dataset
2024-09-17 13:53:13,526:INFO:Defining folds
2024-09-17 13:53:13,526:INFO:Declaring metric variables
2024-09-17 13:53:13,529:INFO:Importing untrained model
2024-09-17 13:53:13,532:INFO:Dummy Classifier Imported successfully
2024-09-17 13:53:13,535:INFO:Starting cross validation
2024-09-17 13:53:13,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-17 13:53:13,760:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,809:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,812:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,851:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,889:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,953:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:13,982:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:14,009:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:14,025:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:14,050:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-17 13:53:14,071:INFO:Calculating mean and std
2024-09-17 13:53:14,072:INFO:Creating metrics dataframe
2024-09-17 13:53:14,073:INFO:Uploading results into container
2024-09-17 13:53:14,075:INFO:Uploading model into container now
2024-09-17 13:53:14,075:INFO:_master_model_container: 15
2024-09-17 13:53:14,075:INFO:_display_container: 2
2024-09-17 13:53:14,075:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-17 13:53:14,075:INFO:create_model() successfully completed......................................
2024-09-17 13:53:14,160:INFO:SubProcess create_model() end ==================================
2024-09-17 13:53:14,161:INFO:Creating metrics dataframe
2024-09-17 13:53:14,165:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning:

Styler.applymap has been deprecated. Use Styler.map instead.


2024-09-17 13:53:14,168:INFO:Initializing create_model()
2024-09-17 13:53:14,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1772efa30>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-17 13:53:14,169:INFO:Checking exceptions
2024-09-17 13:53:14,170:INFO:Importing libraries
2024-09-17 13:53:14,170:INFO:Copying training dataset
2024-09-17 13:53:14,210:INFO:Defining folds
2024-09-17 13:53:14,210:INFO:Declaring metric variables
2024-09-17 13:53:14,211:INFO:Importing untrained model
2024-09-17 13:53:14,211:INFO:Declaring custom model
2024-09-17 13:53:14,211:INFO:Random Forest Classifier Imported successfully
2024-09-17 13:53:14,212:INFO:Cross validation set to False
2024-09-17 13:53:14,212:INFO:Fitting Model
2024-09-17 13:53:16,499:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:53:16,499:INFO:create_model() successfully completed......................................
2024-09-17 13:53:16,613:INFO:_master_model_container: 15
2024-09-17 13:53:16,613:INFO:_display_container: 2
2024-09-17 13:53:16,614:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-17 13:53:16,614:INFO:compare_models() successfully completed......................................
2024-09-19 20:07:35,030:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-19 20:07:35,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-19 20:07:35,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-19 20:07:35,035:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-19 20:07:35,308:INFO:PyCaret ClassificationExperiment
2024-09-19 20:07:35,308:INFO:Logging name: clf-default-name
2024-09-19 20:07:35,308:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-19 20:07:35,308:INFO:version 3.3.2
2024-09-19 20:07:35,308:INFO:Initializing setup()
2024-09-19 20:07:35,308:INFO:self.USI: 6948
2024-09-19 20:07:35,308:INFO:self._variable_keys: {'pipeline', 'X', 'fold_shuffle_param', 'fold_groups_param', 'exp_name_log', 'is_multiclass', 'target_param', 'logging_param', 'exp_id', 'seed', 'fold_generator', 'X_test', '_available_plots', 'gpu_param', 'log_plots_param', 'html_param', 'y_test', 'y_train', 'idx', 'memory', 'USI', 'X_train', 'fix_imbalance', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'data'}
2024-09-19 20:07:35,308:INFO:Checking environment
2024-09-19 20:07:35,308:INFO:python_version: 3.10.14
2024-09-19 20:07:35,308:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-19 20:07:35,308:INFO:machine: arm64
2024-09-19 20:07:35,308:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-19 20:07:35,309:INFO:Memory: svmem(total=8589934592, available=1446035456, percent=83.2, used=3043590144, free=89587712, active=1366949888, inactive=1323073536, wired=1676640256)
2024-09-19 20:07:35,309:INFO:Physical Core: 8
2024-09-19 20:07:35,309:INFO:Logical Core: 8
2024-09-19 20:07:35,309:INFO:Checking libraries
2024-09-19 20:07:35,309:INFO:System:
2024-09-19 20:07:35,309:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-19 20:07:35,309:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-19 20:07:35,309:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-19 20:07:35,309:INFO:PyCaret required dependencies:
2024-09-19 20:07:35,518:INFO:                 pip: 24.2
2024-09-19 20:07:35,519:INFO:          setuptools: 72.1.0
2024-09-19 20:07:35,519:INFO:             pycaret: 3.3.2
2024-09-19 20:07:35,519:INFO:             IPython: 8.18.1
2024-09-19 20:07:35,519:INFO:          ipywidgets: 8.1.5
2024-09-19 20:07:35,519:INFO:                tqdm: 4.66.5
2024-09-19 20:07:35,519:INFO:               numpy: 1.26.4
2024-09-19 20:07:35,519:INFO:              pandas: 2.1.4
2024-09-19 20:07:35,519:INFO:              jinja2: 3.1.4
2024-09-19 20:07:35,519:INFO:               scipy: 1.11.4
2024-09-19 20:07:35,519:INFO:              joblib: 1.3.2
2024-09-19 20:07:35,519:INFO:             sklearn: 1.4.2
2024-09-19 20:07:35,519:INFO:                pyod: 2.0.2
2024-09-19 20:07:35,519:INFO:            imblearn: 0.12.3
2024-09-19 20:07:35,519:INFO:   category_encoders: 2.6.3
2024-09-19 20:07:35,519:INFO:            lightgbm: 4.5.0
2024-09-19 20:07:35,519:INFO:               numba: 0.60.0
2024-09-19 20:07:35,519:INFO:            requests: 2.32.3
2024-09-19 20:07:35,519:INFO:          matplotlib: 3.7.5
2024-09-19 20:07:35,519:INFO:          scikitplot: 0.3.7
2024-09-19 20:07:35,519:INFO:         yellowbrick: 1.5
2024-09-19 20:07:35,519:INFO:              plotly: 5.24.0
2024-09-19 20:07:35,519:INFO:    plotly-resampler: Not installed
2024-09-19 20:07:35,519:INFO:             kaleido: 0.2.1
2024-09-19 20:07:35,519:INFO:           schemdraw: 0.15
2024-09-19 20:07:35,519:INFO:         statsmodels: 0.14.3
2024-09-19 20:07:35,519:INFO:              sktime: 0.26.0
2024-09-19 20:07:35,519:INFO:               tbats: 1.1.3
2024-09-19 20:07:35,519:INFO:            pmdarima: 2.0.4
2024-09-19 20:07:35,519:INFO:              psutil: 5.9.0
2024-09-19 20:07:35,519:INFO:          markupsafe: 2.1.5
2024-09-19 20:07:35,519:INFO:             pickle5: Not installed
2024-09-19 20:07:35,519:INFO:         cloudpickle: 3.0.0
2024-09-19 20:07:35,519:INFO:         deprecation: 2.1.0
2024-09-19 20:07:35,519:INFO:              xxhash: 3.5.0
2024-09-19 20:07:35,519:INFO:           wurlitzer: 3.1.1
2024-09-19 20:07:35,519:INFO:PyCaret optional dependencies:
2024-09-19 20:07:35,525:INFO:                shap: 0.46.0
2024-09-19 20:07:35,525:INFO:           interpret: Not installed
2024-09-19 20:07:35,525:INFO:                umap: Not installed
2024-09-19 20:07:35,526:INFO:     ydata_profiling: Not installed
2024-09-19 20:07:35,526:INFO:  explainerdashboard: Not installed
2024-09-19 20:07:35,526:INFO:             autoviz: Not installed
2024-09-19 20:07:35,526:INFO:           fairlearn: Not installed
2024-09-19 20:07:35,526:INFO:          deepchecks: Not installed
2024-09-19 20:07:35,526:INFO:             xgboost: 2.1.1
2024-09-19 20:07:35,526:INFO:            catboost: Not installed
2024-09-19 20:07:35,526:INFO:              kmodes: Not installed
2024-09-19 20:07:35,526:INFO:             mlxtend: Not installed
2024-09-19 20:07:35,526:INFO:       statsforecast: Not installed
2024-09-19 20:07:35,526:INFO:        tune_sklearn: Not installed
2024-09-19 20:07:35,526:INFO:                 ray: Not installed
2024-09-19 20:07:35,526:INFO:            hyperopt: Not installed
2024-09-19 20:07:35,526:INFO:              optuna: 4.0.0
2024-09-19 20:07:35,526:INFO:               skopt: Not installed
2024-09-19 20:07:35,526:INFO:              mlflow: Not installed
2024-09-19 20:07:35,526:INFO:              gradio: Not installed
2024-09-19 20:07:35,526:INFO:             fastapi: Not installed
2024-09-19 20:07:35,526:INFO:             uvicorn: Not installed
2024-09-19 20:07:35,526:INFO:              m2cgen: Not installed
2024-09-19 20:07:35,526:INFO:           evidently: Not installed
2024-09-19 20:07:35,526:INFO:               fugue: Not installed
2024-09-19 20:07:35,526:INFO:           streamlit: 1.38.0
2024-09-19 20:07:35,526:INFO:             prophet: Not installed
2024-09-19 20:07:35,526:INFO:None
2024-09-19 20:07:35,526:INFO:Set up data.
2024-09-19 20:07:35,567:INFO:Set up folding strategy.
2024-09-19 20:07:35,567:INFO:Set up train/test split.
2024-09-19 20:07:35,604:INFO:Set up index.
2024-09-19 20:07:35,609:INFO:Assigning column types.
2024-09-19 20:07:35,626:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-19 20:07:35,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,647:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,662:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,693:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,694:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-19 20:07:35,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,725:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,745:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:07:35,756:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,758:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-19 20:07:35,788:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,819:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:35,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:35,822:INFO:Preparing preprocessing pipeline...
2024-09-19 20:07:35,825:INFO:Set up label encoding.
2024-09-19 20:07:35,825:INFO:Set up simple imputation.
2024-09-19 20:07:35,828:INFO:Set up column name cleaning.
2024-09-19 20:07:36,408:INFO:Finished creating preprocessing pipeline.
2024-09-19 20:07:36,412:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-19 20:07:36,412:INFO:Creating final display dataframe.
2024-09-19 20:07:36,958:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               6948
2024-09-19 20:07:36,994:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:36,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:37,027:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:07:37,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:07:37,029:INFO:setup() successfully completed in 1.73s...............
2024-09-19 20:07:37,034:INFO:Initializing compare_models()
2024-09-19 20:07:37,034:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-19 20:07:37,034:INFO:Checking exceptions
2024-09-19 20:07:37,056:INFO:Preparing display monitor
2024-09-19 20:07:37,099:INFO:Initializing Logistic Regression
2024-09-19 20:07:37,099:INFO:Total runtime is 5.4836273193359375e-06 minutes
2024-09-19 20:07:37,101:INFO:SubProcess create_model() called ==================================
2024-09-19 20:07:37,101:INFO:Initializing create_model()
2024-09-19 20:07:37,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:07:37,102:INFO:Checking exceptions
2024-09-19 20:07:37,102:INFO:Importing libraries
2024-09-19 20:07:37,102:INFO:Copying training dataset
2024-09-19 20:07:37,151:INFO:Defining folds
2024-09-19 20:07:37,151:INFO:Declaring metric variables
2024-09-19 20:07:37,152:INFO:Importing untrained model
2024-09-19 20:07:37,154:INFO:Logistic Regression Imported successfully
2024-09-19 20:07:37,157:INFO:Starting cross validation
2024-09-19 20:07:37,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:07:51,816:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:51,874:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,105:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,155:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,220:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,232:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,240:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,337:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,402:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,486:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,513:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,600:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,703:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,729:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:52,776:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:52,793:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:58,322:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:58,366:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:58,376:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:07:58,409:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:07:58,426:INFO:Calculating mean and std
2024-09-19 20:07:58,429:INFO:Creating metrics dataframe
2024-09-19 20:07:58,443:INFO:Uploading results into container
2024-09-19 20:07:58,444:INFO:Uploading model into container now
2024-09-19 20:07:58,445:INFO:_master_model_container: 1
2024-09-19 20:07:58,445:INFO:_display_container: 2
2024-09-19 20:07:58,446:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-19 20:07:58,446:INFO:create_model() successfully completed......................................
2024-09-19 20:07:58,546:INFO:SubProcess create_model() end ==================================
2024-09-19 20:07:58,546:INFO:Creating metrics dataframe
2024-09-19 20:07:58,549:INFO:Initializing K Neighbors Classifier
2024-09-19 20:07:58,549:INFO:Total runtime is 0.35751278400421144 minutes
2024-09-19 20:07:58,551:INFO:SubProcess create_model() called ==================================
2024-09-19 20:07:58,552:INFO:Initializing create_model()
2024-09-19 20:07:58,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:07:58,552:INFO:Checking exceptions
2024-09-19 20:07:58,552:INFO:Importing libraries
2024-09-19 20:07:58,552:INFO:Copying training dataset
2024-09-19 20:07:58,608:INFO:Defining folds
2024-09-19 20:07:58,608:INFO:Declaring metric variables
2024-09-19 20:07:58,610:INFO:Importing untrained model
2024-09-19 20:07:58,612:INFO:K Neighbors Classifier Imported successfully
2024-09-19 20:07:58,615:INFO:Starting cross validation
2024-09-19 20:07:58,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:07,349:INFO:Calculating mean and std
2024-09-19 20:08:07,351:INFO:Creating metrics dataframe
2024-09-19 20:08:07,354:INFO:Uploading results into container
2024-09-19 20:08:07,355:INFO:Uploading model into container now
2024-09-19 20:08:07,356:INFO:_master_model_container: 2
2024-09-19 20:08:07,356:INFO:_display_container: 2
2024-09-19 20:08:07,356:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-19 20:08:07,356:INFO:create_model() successfully completed......................................
2024-09-19 20:08:07,452:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:07,452:INFO:Creating metrics dataframe
2024-09-19 20:08:07,456:INFO:Initializing Naive Bayes
2024-09-19 20:08:07,456:INFO:Total runtime is 0.5059621493021648 minutes
2024-09-19 20:08:07,458:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:07,458:INFO:Initializing create_model()
2024-09-19 20:08:07,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:07,459:INFO:Checking exceptions
2024-09-19 20:08:07,459:INFO:Importing libraries
2024-09-19 20:08:07,459:INFO:Copying training dataset
2024-09-19 20:08:07,511:INFO:Defining folds
2024-09-19 20:08:07,511:INFO:Declaring metric variables
2024-09-19 20:08:07,512:INFO:Importing untrained model
2024-09-19 20:08:07,515:INFO:Naive Bayes Imported successfully
2024-09-19 20:08:07,519:INFO:Starting cross validation
2024-09-19 20:08:07,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:08,244:INFO:Calculating mean and std
2024-09-19 20:08:08,245:INFO:Creating metrics dataframe
2024-09-19 20:08:08,246:INFO:Uploading results into container
2024-09-19 20:08:08,246:INFO:Uploading model into container now
2024-09-19 20:08:08,246:INFO:_master_model_container: 3
2024-09-19 20:08:08,246:INFO:_display_container: 2
2024-09-19 20:08:08,246:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-19 20:08:08,246:INFO:create_model() successfully completed......................................
2024-09-19 20:08:08,299:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:08,300:INFO:Creating metrics dataframe
2024-09-19 20:08:08,303:INFO:Initializing Decision Tree Classifier
2024-09-19 20:08:08,304:INFO:Total runtime is 0.520083216826121 minutes
2024-09-19 20:08:08,306:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:08,307:INFO:Initializing create_model()
2024-09-19 20:08:08,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:08,307:INFO:Checking exceptions
2024-09-19 20:08:08,307:INFO:Importing libraries
2024-09-19 20:08:08,307:INFO:Copying training dataset
2024-09-19 20:08:08,350:INFO:Defining folds
2024-09-19 20:08:08,351:INFO:Declaring metric variables
2024-09-19 20:08:08,352:INFO:Importing untrained model
2024-09-19 20:08:08,355:INFO:Decision Tree Classifier Imported successfully
2024-09-19 20:08:08,358:INFO:Starting cross validation
2024-09-19 20:08:08,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:10,476:INFO:Calculating mean and std
2024-09-19 20:08:10,480:INFO:Creating metrics dataframe
2024-09-19 20:08:10,483:INFO:Uploading results into container
2024-09-19 20:08:10,484:INFO:Uploading model into container now
2024-09-19 20:08:10,484:INFO:_master_model_container: 4
2024-09-19 20:08:10,484:INFO:_display_container: 2
2024-09-19 20:08:10,485:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-19 20:08:10,485:INFO:create_model() successfully completed......................................
2024-09-19 20:08:10,567:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:10,567:INFO:Creating metrics dataframe
2024-09-19 20:08:10,570:INFO:Initializing SVM - Linear Kernel
2024-09-19 20:08:10,570:INFO:Total runtime is 0.5578567862510682 minutes
2024-09-19 20:08:10,571:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:10,572:INFO:Initializing create_model()
2024-09-19 20:08:10,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:10,572:INFO:Checking exceptions
2024-09-19 20:08:10,572:INFO:Importing libraries
2024-09-19 20:08:10,572:INFO:Copying training dataset
2024-09-19 20:08:10,614:INFO:Defining folds
2024-09-19 20:08:10,615:INFO:Declaring metric variables
2024-09-19 20:08:10,616:INFO:Importing untrained model
2024-09-19 20:08:10,619:INFO:SVM - Linear Kernel Imported successfully
2024-09-19 20:08:10,621:INFO:Starting cross validation
2024-09-19 20:08:10,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:18,576:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:18,582:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:19,258:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:19,263:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:19,366:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:19,372:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:19,653:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:19,659:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:19,711:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:19,717:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:20,220:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:20,226:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:20,344:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:20,352:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:20,583:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:21,783:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:21,789:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:08:21,984:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,009:INFO:Calculating mean and std
2024-09-19 20:08:22,012:INFO:Creating metrics dataframe
2024-09-19 20:08:22,016:INFO:Uploading results into container
2024-09-19 20:08:22,017:INFO:Uploading model into container now
2024-09-19 20:08:22,018:INFO:_master_model_container: 5
2024-09-19 20:08:22,018:INFO:_display_container: 2
2024-09-19 20:08:22,020:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-19 20:08:22,020:INFO:create_model() successfully completed......................................
2024-09-19 20:08:22,111:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:22,111:INFO:Creating metrics dataframe
2024-09-19 20:08:22,115:INFO:Initializing Ridge Classifier
2024-09-19 20:08:22,115:INFO:Total runtime is 0.7502744674682618 minutes
2024-09-19 20:08:22,117:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:22,117:INFO:Initializing create_model()
2024-09-19 20:08:22,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:22,117:INFO:Checking exceptions
2024-09-19 20:08:22,117:INFO:Importing libraries
2024-09-19 20:08:22,118:INFO:Copying training dataset
2024-09-19 20:08:22,178:INFO:Defining folds
2024-09-19 20:08:22,178:INFO:Declaring metric variables
2024-09-19 20:08:22,180:INFO:Importing untrained model
2024-09-19 20:08:22,183:INFO:Ridge Classifier Imported successfully
2024-09-19 20:08:22,186:INFO:Starting cross validation
2024-09-19 20:08:22,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:22,441:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,447:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,527:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,550:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,571:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,594:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,596:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,622:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,667:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,709:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,748:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,757:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,780:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,828:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,829:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,875:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,899:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:08:22,908:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:22,955:INFO:Calculating mean and std
2024-09-19 20:08:22,957:INFO:Creating metrics dataframe
2024-09-19 20:08:22,958:INFO:Uploading results into container
2024-09-19 20:08:22,959:INFO:Uploading model into container now
2024-09-19 20:08:22,960:INFO:_master_model_container: 6
2024-09-19 20:08:22,960:INFO:_display_container: 2
2024-09-19 20:08:22,960:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-19 20:08:22,961:INFO:create_model() successfully completed......................................
2024-09-19 20:08:23,017:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:23,017:INFO:Creating metrics dataframe
2024-09-19 20:08:23,021:INFO:Initializing Random Forest Classifier
2024-09-19 20:08:23,021:INFO:Total runtime is 0.765372363726298 minutes
2024-09-19 20:08:23,024:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:23,024:INFO:Initializing create_model()
2024-09-19 20:08:23,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:23,024:INFO:Checking exceptions
2024-09-19 20:08:23,024:INFO:Importing libraries
2024-09-19 20:08:23,024:INFO:Copying training dataset
2024-09-19 20:08:23,077:INFO:Defining folds
2024-09-19 20:08:23,077:INFO:Declaring metric variables
2024-09-19 20:08:23,079:INFO:Importing untrained model
2024-09-19 20:08:23,082:INFO:Random Forest Classifier Imported successfully
2024-09-19 20:08:23,085:INFO:Starting cross validation
2024-09-19 20:08:23,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:44,553:INFO:Calculating mean and std
2024-09-19 20:08:44,555:INFO:Creating metrics dataframe
2024-09-19 20:08:44,558:INFO:Uploading results into container
2024-09-19 20:08:44,559:INFO:Uploading model into container now
2024-09-19 20:08:44,560:INFO:_master_model_container: 7
2024-09-19 20:08:44,560:INFO:_display_container: 2
2024-09-19 20:08:44,560:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:08:44,560:INFO:create_model() successfully completed......................................
2024-09-19 20:08:44,659:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:44,659:INFO:Creating metrics dataframe
2024-09-19 20:08:44,663:INFO:Initializing Quadratic Discriminant Analysis
2024-09-19 20:08:44,663:INFO:Total runtime is 1.1260706981023152 minutes
2024-09-19 20:08:44,664:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:44,665:INFO:Initializing create_model()
2024-09-19 20:08:44,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:44,665:INFO:Checking exceptions
2024-09-19 20:08:44,665:INFO:Importing libraries
2024-09-19 20:08:44,665:INFO:Copying training dataset
2024-09-19 20:08:44,720:INFO:Defining folds
2024-09-19 20:08:44,720:INFO:Declaring metric variables
2024-09-19 20:08:44,722:INFO:Importing untrained model
2024-09-19 20:08:44,724:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-19 20:08:44,727:INFO:Starting cross validation
2024-09-19 20:08:44,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:45,087:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,223:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,281:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,347:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,394:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,447:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,523:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,547:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,604:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,648:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:45,669:INFO:Calculating mean and std
2024-09-19 20:08:45,670:INFO:Creating metrics dataframe
2024-09-19 20:08:45,671:INFO:Uploading results into container
2024-09-19 20:08:45,671:INFO:Uploading model into container now
2024-09-19 20:08:45,671:INFO:_master_model_container: 8
2024-09-19 20:08:45,671:INFO:_display_container: 2
2024-09-19 20:08:45,672:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-19 20:08:45,672:INFO:create_model() successfully completed......................................
2024-09-19 20:08:45,722:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:45,722:INFO:Creating metrics dataframe
2024-09-19 20:08:45,726:INFO:Initializing Ada Boost Classifier
2024-09-19 20:08:45,726:INFO:Total runtime is 1.143783684571584 minutes
2024-09-19 20:08:45,727:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:45,727:INFO:Initializing create_model()
2024-09-19 20:08:45,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:45,727:INFO:Checking exceptions
2024-09-19 20:08:45,727:INFO:Importing libraries
2024-09-19 20:08:45,727:INFO:Copying training dataset
2024-09-19 20:08:45,769:INFO:Defining folds
2024-09-19 20:08:45,769:INFO:Declaring metric variables
2024-09-19 20:08:45,771:INFO:Importing untrained model
2024-09-19 20:08:45,772:INFO:Ada Boost Classifier Imported successfully
2024-09-19 20:08:45,776:INFO:Starting cross validation
2024-09-19 20:08:45,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:08:45,928:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:45,979:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,023:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,034:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,192:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,192:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,215:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:46,227:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:49,775:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,853:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,886:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,889:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,928:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,964:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:49,975:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:50,002:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:50,010:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:50,048:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:08:52,224:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:52,260:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:08:52,272:INFO:Calculating mean and std
2024-09-19 20:08:52,273:INFO:Creating metrics dataframe
2024-09-19 20:08:52,275:INFO:Uploading results into container
2024-09-19 20:08:52,275:INFO:Uploading model into container now
2024-09-19 20:08:52,275:INFO:_master_model_container: 9
2024-09-19 20:08:52,275:INFO:_display_container: 2
2024-09-19 20:08:52,276:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-19 20:08:52,276:INFO:create_model() successfully completed......................................
2024-09-19 20:08:52,333:INFO:SubProcess create_model() end ==================================
2024-09-19 20:08:52,334:INFO:Creating metrics dataframe
2024-09-19 20:08:52,338:INFO:Initializing Gradient Boosting Classifier
2024-09-19 20:08:52,338:INFO:Total runtime is 1.2539851665496826 minutes
2024-09-19 20:08:52,339:INFO:SubProcess create_model() called ==================================
2024-09-19 20:08:52,339:INFO:Initializing create_model()
2024-09-19 20:08:52,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:08:52,340:INFO:Checking exceptions
2024-09-19 20:08:52,340:INFO:Importing libraries
2024-09-19 20:08:52,340:INFO:Copying training dataset
2024-09-19 20:08:52,381:INFO:Defining folds
2024-09-19 20:08:52,381:INFO:Declaring metric variables
2024-09-19 20:08:52,383:INFO:Importing untrained model
2024-09-19 20:08:52,384:INFO:Gradient Boosting Classifier Imported successfully
2024-09-19 20:08:52,388:INFO:Starting cross validation
2024-09-19 20:08:52,389:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:09:40,830:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:40,874:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,151:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,201:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,425:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,441:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,465:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:09:41,514:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,174:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,227:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,244:INFO:Calculating mean and std
2024-09-19 20:10:08,246:INFO:Creating metrics dataframe
2024-09-19 20:10:08,248:INFO:Uploading results into container
2024-09-19 20:10:08,249:INFO:Uploading model into container now
2024-09-19 20:10:08,249:INFO:_master_model_container: 10
2024-09-19 20:10:08,250:INFO:_display_container: 2
2024-09-19 20:10:08,250:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-19 20:10:08,250:INFO:create_model() successfully completed......................................
2024-09-19 20:10:08,337:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:08,337:INFO:Creating metrics dataframe
2024-09-19 20:10:08,341:INFO:Initializing Linear Discriminant Analysis
2024-09-19 20:10:08,342:INFO:Total runtime is 2.5207138657569885 minutes
2024-09-19 20:10:08,343:INFO:SubProcess create_model() called ==================================
2024-09-19 20:10:08,343:INFO:Initializing create_model()
2024-09-19 20:10:08,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:08,344:INFO:Checking exceptions
2024-09-19 20:10:08,344:INFO:Importing libraries
2024-09-19 20:10:08,344:INFO:Copying training dataset
2024-09-19 20:10:08,397:INFO:Defining folds
2024-09-19 20:10:08,397:INFO:Declaring metric variables
2024-09-19 20:10:08,398:INFO:Importing untrained model
2024-09-19 20:10:08,400:INFO:Linear Discriminant Analysis Imported successfully
2024-09-19 20:10:08,403:INFO:Starting cross validation
2024-09-19 20:10:08,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:10:08,667:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,786:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,795:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,833:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,873:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,905:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,969:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:08,997:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:09,018:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:09,045:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:10:09,068:INFO:Calculating mean and std
2024-09-19 20:10:09,069:INFO:Creating metrics dataframe
2024-09-19 20:10:09,070:INFO:Uploading results into container
2024-09-19 20:10:09,070:INFO:Uploading model into container now
2024-09-19 20:10:09,071:INFO:_master_model_container: 11
2024-09-19 20:10:09,071:INFO:_display_container: 2
2024-09-19 20:10:09,071:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-19 20:10:09,071:INFO:create_model() successfully completed......................................
2024-09-19 20:10:09,121:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:09,121:INFO:Creating metrics dataframe
2024-09-19 20:10:09,125:INFO:Initializing Extra Trees Classifier
2024-09-19 20:10:09,126:INFO:Total runtime is 2.5337813178698223 minutes
2024-09-19 20:10:09,127:INFO:SubProcess create_model() called ==================================
2024-09-19 20:10:09,127:INFO:Initializing create_model()
2024-09-19 20:10:09,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:09,127:INFO:Checking exceptions
2024-09-19 20:10:09,127:INFO:Importing libraries
2024-09-19 20:10:09,127:INFO:Copying training dataset
2024-09-19 20:10:09,203:INFO:Defining folds
2024-09-19 20:10:09,203:INFO:Declaring metric variables
2024-09-19 20:10:09,205:INFO:Importing untrained model
2024-09-19 20:10:09,206:INFO:Extra Trees Classifier Imported successfully
2024-09-19 20:10:09,209:INFO:Starting cross validation
2024-09-19 20:10:09,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:10:24,478:INFO:Calculating mean and std
2024-09-19 20:10:24,487:INFO:Creating metrics dataframe
2024-09-19 20:10:24,492:INFO:Uploading results into container
2024-09-19 20:10:24,493:INFO:Uploading model into container now
2024-09-19 20:10:24,495:INFO:_master_model_container: 12
2024-09-19 20:10:24,495:INFO:_display_container: 2
2024-09-19 20:10:24,497:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-19 20:10:24,498:INFO:create_model() successfully completed......................................
2024-09-19 20:10:24,612:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:24,633:INFO:Creating metrics dataframe
2024-09-19 20:10:24,639:INFO:Initializing Extreme Gradient Boosting
2024-09-19 20:10:24,639:INFO:Total runtime is 2.7923363327980044 minutes
2024-09-19 20:10:24,642:INFO:SubProcess create_model() called ==================================
2024-09-19 20:10:24,642:INFO:Initializing create_model()
2024-09-19 20:10:24,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:24,643:INFO:Checking exceptions
2024-09-19 20:10:24,643:INFO:Importing libraries
2024-09-19 20:10:24,643:INFO:Copying training dataset
2024-09-19 20:10:24,710:INFO:Defining folds
2024-09-19 20:10:24,710:INFO:Declaring metric variables
2024-09-19 20:10:24,713:INFO:Importing untrained model
2024-09-19 20:10:24,715:INFO:Extreme Gradient Boosting Imported successfully
2024-09-19 20:10:24,720:INFO:Starting cross validation
2024-09-19 20:10:24,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:10:25,284:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-19 20:10:31,508:INFO:Calculating mean and std
2024-09-19 20:10:31,511:INFO:Creating metrics dataframe
2024-09-19 20:10:31,514:INFO:Uploading results into container
2024-09-19 20:10:31,515:INFO:Uploading model into container now
2024-09-19 20:10:31,515:INFO:_master_model_container: 13
2024-09-19 20:10:31,515:INFO:_display_container: 2
2024-09-19 20:10:31,517:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-19 20:10:31,517:INFO:create_model() successfully completed......................................
2024-09-19 20:10:31,592:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:31,592:INFO:Creating metrics dataframe
2024-09-19 20:10:31,599:INFO:Initializing Light Gradient Boosting Machine
2024-09-19 20:10:31,599:INFO:Total runtime is 2.908335614204407 minutes
2024-09-19 20:10:31,602:INFO:SubProcess create_model() called ==================================
2024-09-19 20:10:31,602:INFO:Initializing create_model()
2024-09-19 20:10:31,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:31,602:INFO:Checking exceptions
2024-09-19 20:10:31,602:INFO:Importing libraries
2024-09-19 20:10:31,602:INFO:Copying training dataset
2024-09-19 20:10:31,664:INFO:Defining folds
2024-09-19 20:10:31,664:INFO:Declaring metric variables
2024-09-19 20:10:31,666:INFO:Importing untrained model
2024-09-19 20:10:31,669:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-19 20:10:31,673:INFO:Starting cross validation
2024-09-19 20:10:31,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:10:49,373:INFO:Calculating mean and std
2024-09-19 20:10:49,377:INFO:Creating metrics dataframe
2024-09-19 20:10:49,379:INFO:Uploading results into container
2024-09-19 20:10:49,380:INFO:Uploading model into container now
2024-09-19 20:10:49,381:INFO:_master_model_container: 14
2024-09-19 20:10:49,381:INFO:_display_container: 2
2024-09-19 20:10:49,382:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-19 20:10:49,382:INFO:create_model() successfully completed......................................
2024-09-19 20:10:49,483:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:49,483:INFO:Creating metrics dataframe
2024-09-19 20:10:49,491:INFO:Initializing Dummy Classifier
2024-09-19 20:10:49,491:INFO:Total runtime is 3.2065322001775107 minutes
2024-09-19 20:10:49,493:INFO:SubProcess create_model() called ==================================
2024-09-19 20:10:49,493:INFO:Initializing create_model()
2024-09-19 20:10:49,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x33758d300>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:49,494:INFO:Checking exceptions
2024-09-19 20:10:49,494:INFO:Importing libraries
2024-09-19 20:10:49,494:INFO:Copying training dataset
2024-09-19 20:10:49,550:INFO:Defining folds
2024-09-19 20:10:49,551:INFO:Declaring metric variables
2024-09-19 20:10:49,553:INFO:Importing untrained model
2024-09-19 20:10:49,556:INFO:Dummy Classifier Imported successfully
2024-09-19 20:10:49,559:INFO:Starting cross validation
2024-09-19 20:10:49,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:10:49,789:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:49,849:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:49,888:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:49,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:49,967:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:49,994:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:50,041:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:50,076:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:50,086:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:50,121:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:10:50,139:INFO:Calculating mean and std
2024-09-19 20:10:50,140:INFO:Creating metrics dataframe
2024-09-19 20:10:50,141:INFO:Uploading results into container
2024-09-19 20:10:50,141:INFO:Uploading model into container now
2024-09-19 20:10:50,141:INFO:_master_model_container: 15
2024-09-19 20:10:50,141:INFO:_display_container: 2
2024-09-19 20:10:50,141:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-19 20:10:50,141:INFO:create_model() successfully completed......................................
2024-09-19 20:10:50,192:INFO:SubProcess create_model() end ==================================
2024-09-19 20:10:50,192:INFO:Creating metrics dataframe
2024-09-19 20:10:50,198:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-19 20:10:50,202:INFO:Initializing create_model()
2024-09-19 20:10:50,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x336fc0730>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:10:50,202:INFO:Checking exceptions
2024-09-19 20:10:50,203:INFO:Importing libraries
2024-09-19 20:10:50,203:INFO:Copying training dataset
2024-09-19 20:10:50,242:INFO:Defining folds
2024-09-19 20:10:50,242:INFO:Declaring metric variables
2024-09-19 20:10:50,242:INFO:Importing untrained model
2024-09-19 20:10:50,242:INFO:Declaring custom model
2024-09-19 20:10:50,243:INFO:Random Forest Classifier Imported successfully
2024-09-19 20:10:50,243:INFO:Cross validation set to False
2024-09-19 20:10:50,243:INFO:Fitting Model
2024-09-19 20:10:53,023:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:10:53,023:INFO:create_model() successfully completed......................................
2024-09-19 20:10:53,092:INFO:_master_model_container: 15
2024-09-19 20:10:53,092:INFO:_display_container: 2
2024-09-19 20:10:53,093:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:10:53,093:INFO:compare_models() successfully completed......................................
2024-09-19 20:26:19,865:INFO:PyCaret ClassificationExperiment
2024-09-19 20:26:19,872:INFO:Logging name: clf-default-name
2024-09-19 20:26:19,873:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-19 20:26:19,873:INFO:version 3.3.2
2024-09-19 20:26:19,873:INFO:Initializing setup()
2024-09-19 20:26:19,873:INFO:self.USI: a45f
2024-09-19 20:26:19,873:INFO:self._variable_keys: {'pipeline', 'X', 'fold_shuffle_param', 'fold_groups_param', 'exp_name_log', 'is_multiclass', 'target_param', 'logging_param', 'exp_id', 'seed', 'fold_generator', 'X_test', '_available_plots', 'gpu_param', 'log_plots_param', 'html_param', 'y_test', 'y_train', 'idx', 'memory', 'USI', 'X_train', 'fix_imbalance', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'data'}
2024-09-19 20:26:19,873:INFO:Checking environment
2024-09-19 20:26:19,873:INFO:python_version: 3.10.14
2024-09-19 20:26:19,873:INFO:python_build: ('main', 'May  6 2024 14:42:37')
2024-09-19 20:26:19,873:INFO:machine: arm64
2024-09-19 20:26:19,873:INFO:platform: macOS-14.6.1-arm64-arm-64bit
2024-09-19 20:26:19,875:INFO:Memory: svmem(total=8589934592, available=1448968192, percent=83.1, used=2990915584, free=66912256, active=1400995840, inactive=1361346560, wired=1589919744)
2024-09-19 20:26:19,875:INFO:Physical Core: 8
2024-09-19 20:26:19,875:INFO:Logical Core: 8
2024-09-19 20:26:19,875:INFO:Checking libraries
2024-09-19 20:26:19,875:INFO:System:
2024-09-19 20:26:19,875:INFO:    python: 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]
2024-09-19 20:26:19,875:INFO:executable: /opt/anaconda3/envs/finance/bin/python
2024-09-19 20:26:19,875:INFO:   machine: macOS-14.6.1-arm64-arm-64bit
2024-09-19 20:26:19,875:INFO:PyCaret required dependencies:
2024-09-19 20:26:19,875:INFO:                 pip: 24.2
2024-09-19 20:26:19,875:INFO:          setuptools: 72.1.0
2024-09-19 20:26:19,875:INFO:             pycaret: 3.3.2
2024-09-19 20:26:19,875:INFO:             IPython: 8.18.1
2024-09-19 20:26:19,875:INFO:          ipywidgets: 8.1.5
2024-09-19 20:26:19,875:INFO:                tqdm: 4.66.5
2024-09-19 20:26:19,875:INFO:               numpy: 1.26.4
2024-09-19 20:26:19,875:INFO:              pandas: 2.1.4
2024-09-19 20:26:19,875:INFO:              jinja2: 3.1.4
2024-09-19 20:26:19,875:INFO:               scipy: 1.11.4
2024-09-19 20:26:19,875:INFO:              joblib: 1.3.2
2024-09-19 20:26:19,875:INFO:             sklearn: 1.4.2
2024-09-19 20:26:19,875:INFO:                pyod: 2.0.2
2024-09-19 20:26:19,875:INFO:            imblearn: 0.12.3
2024-09-19 20:26:19,875:INFO:   category_encoders: 2.6.3
2024-09-19 20:26:19,875:INFO:            lightgbm: 4.5.0
2024-09-19 20:26:19,875:INFO:               numba: 0.60.0
2024-09-19 20:26:19,875:INFO:            requests: 2.32.3
2024-09-19 20:26:19,875:INFO:          matplotlib: 3.7.5
2024-09-19 20:26:19,875:INFO:          scikitplot: 0.3.7
2024-09-19 20:26:19,875:INFO:         yellowbrick: 1.5
2024-09-19 20:26:19,875:INFO:              plotly: 5.24.0
2024-09-19 20:26:19,875:INFO:    plotly-resampler: Not installed
2024-09-19 20:26:19,875:INFO:             kaleido: 0.2.1
2024-09-19 20:26:19,875:INFO:           schemdraw: 0.15
2024-09-19 20:26:19,875:INFO:         statsmodels: 0.14.3
2024-09-19 20:26:19,875:INFO:              sktime: 0.26.0
2024-09-19 20:26:19,875:INFO:               tbats: 1.1.3
2024-09-19 20:26:19,875:INFO:            pmdarima: 2.0.4
2024-09-19 20:26:19,876:INFO:              psutil: 5.9.0
2024-09-19 20:26:19,876:INFO:          markupsafe: 2.1.5
2024-09-19 20:26:19,876:INFO:             pickle5: Not installed
2024-09-19 20:26:19,876:INFO:         cloudpickle: 3.0.0
2024-09-19 20:26:19,876:INFO:         deprecation: 2.1.0
2024-09-19 20:26:19,876:INFO:              xxhash: 3.5.0
2024-09-19 20:26:19,876:INFO:           wurlitzer: 3.1.1
2024-09-19 20:26:19,876:INFO:PyCaret optional dependencies:
2024-09-19 20:26:19,876:INFO:                shap: 0.46.0
2024-09-19 20:26:19,876:INFO:           interpret: Not installed
2024-09-19 20:26:19,876:INFO:                umap: Not installed
2024-09-19 20:26:19,876:INFO:     ydata_profiling: Not installed
2024-09-19 20:26:19,876:INFO:  explainerdashboard: Not installed
2024-09-19 20:26:19,876:INFO:             autoviz: Not installed
2024-09-19 20:26:19,876:INFO:           fairlearn: Not installed
2024-09-19 20:26:19,876:INFO:          deepchecks: Not installed
2024-09-19 20:26:19,876:INFO:             xgboost: 2.1.1
2024-09-19 20:26:19,876:INFO:            catboost: Not installed
2024-09-19 20:26:19,876:INFO:              kmodes: Not installed
2024-09-19 20:26:19,876:INFO:             mlxtend: Not installed
2024-09-19 20:26:19,876:INFO:       statsforecast: Not installed
2024-09-19 20:26:19,876:INFO:        tune_sklearn: Not installed
2024-09-19 20:26:19,876:INFO:                 ray: Not installed
2024-09-19 20:26:19,876:INFO:            hyperopt: Not installed
2024-09-19 20:26:19,876:INFO:              optuna: 4.0.0
2024-09-19 20:26:19,876:INFO:               skopt: Not installed
2024-09-19 20:26:19,876:INFO:              mlflow: Not installed
2024-09-19 20:26:19,876:INFO:              gradio: Not installed
2024-09-19 20:26:19,876:INFO:             fastapi: Not installed
2024-09-19 20:26:19,876:INFO:             uvicorn: Not installed
2024-09-19 20:26:19,876:INFO:              m2cgen: Not installed
2024-09-19 20:26:19,876:INFO:           evidently: Not installed
2024-09-19 20:26:19,876:INFO:               fugue: Not installed
2024-09-19 20:26:19,876:INFO:           streamlit: 1.38.0
2024-09-19 20:26:19,876:INFO:             prophet: Not installed
2024-09-19 20:26:19,876:INFO:None
2024-09-19 20:26:19,876:INFO:Set up data.
2024-09-19 20:26:19,908:INFO:Set up folding strategy.
2024-09-19 20:26:19,908:INFO:Set up train/test split.
2024-09-19 20:26:19,946:INFO:Set up index.
2024-09-19 20:26:19,949:INFO:Assigning column types.
2024-09-19 20:26:19,963:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-19 20:26:19,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-19 20:26:19,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:26:19,995:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:19,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-19 20:26:20,016:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:26:20,028:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:20,029:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,029:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-19 20:26:20,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:26:20,060:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:20,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-19 20:26:20,091:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:20,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,092:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-19 20:26:20,122:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:20,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,152:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:20,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:20,154:INFO:Preparing preprocessing pipeline...
2024-09-19 20:26:20,158:INFO:Set up label encoding.
2024-09-19 20:26:20,158:INFO:Set up simple imputation.
2024-09-19 20:26:20,161:INFO:Set up column name cleaning.
2024-09-19 20:26:20,712:INFO:Finished creating preprocessing pipeline.
2024-09-19 20:26:20,714:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/lg/dgwnwk9d0d3874nd4j_wdz080000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Annual_Income',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card',
                                             'Num_of_Delayed_Payment',...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-19 20:26:20,714:INFO:Creating final display dataframe.
2024-09-19 20:26:21,359:INFO:Setup _display_container:                     Description              Value
0                    Session id                 42
1                        Target       Credit_Score
2                   Target type         Multiclass
3                Target mapping  -1: 0, 0: 1, 1: 2
4           Original data shape       (100000, 19)
5        Transformed data shape       (100000, 19)
6   Transformed train set shape        (70000, 19)
7    Transformed test set shape        (30000, 19)
8              Numeric features                 17
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13               Fold Generator    StratifiedKFold
14                  Fold Number                 10
15                     CPU Jobs                 -1
16                      Use GPU              False
17               Log Experiment              False
18              Experiment Name   clf-default-name
19                          USI               a45f
2024-09-19 20:26:21,393:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:21,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:21,425:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-19 20:26:21,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-19 20:26:21,427:INFO:setup() successfully completed in 1.57s...............
2024-09-19 20:26:21,448:INFO:Initializing compare_models()
2024-09-19 20:26:21,448:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-09-19 20:26:21,448:INFO:Checking exceptions
2024-09-19 20:26:21,468:INFO:Preparing display monitor
2024-09-19 20:26:21,479:INFO:Initializing Logistic Regression
2024-09-19 20:26:21,486:INFO:Total runtime is 0.00011513233184814453 minutes
2024-09-19 20:26:21,488:INFO:SubProcess create_model() called ==================================
2024-09-19 20:26:21,488:INFO:Initializing create_model()
2024-09-19 20:26:21,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:26:21,488:INFO:Checking exceptions
2024-09-19 20:26:21,488:INFO:Importing libraries
2024-09-19 20:26:21,488:INFO:Copying training dataset
2024-09-19 20:26:21,529:INFO:Defining folds
2024-09-19 20:26:21,529:INFO:Declaring metric variables
2024-09-19 20:26:21,530:INFO:Importing untrained model
2024-09-19 20:26:21,532:INFO:Logistic Regression Imported successfully
2024-09-19 20:26:21,534:INFO:Starting cross validation
2024-09-19 20:26:21,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:26:35,934:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:35,986:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,033:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,042:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,088:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,142:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,197:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,198:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,198:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,307:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,320:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,322:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,329:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,409:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:36,418:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:36,521:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:42,712:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:42,744:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:42,749:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-19 20:26:42,774:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:26:42,792:INFO:Calculating mean and std
2024-09-19 20:26:42,795:INFO:Creating metrics dataframe
2024-09-19 20:26:42,799:INFO:Uploading results into container
2024-09-19 20:26:42,799:INFO:Uploading model into container now
2024-09-19 20:26:42,799:INFO:_master_model_container: 1
2024-09-19 20:26:42,799:INFO:_display_container: 2
2024-09-19 20:26:42,800:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-19 20:26:42,800:INFO:create_model() successfully completed......................................
2024-09-19 20:26:42,915:INFO:SubProcess create_model() end ==================================
2024-09-19 20:26:42,915:INFO:Creating metrics dataframe
2024-09-19 20:26:42,919:INFO:Initializing K Neighbors Classifier
2024-09-19 20:26:42,919:INFO:Total runtime is 0.3573398987452189 minutes
2024-09-19 20:26:42,921:INFO:SubProcess create_model() called ==================================
2024-09-19 20:26:42,922:INFO:Initializing create_model()
2024-09-19 20:26:42,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:26:42,922:INFO:Checking exceptions
2024-09-19 20:26:42,922:INFO:Importing libraries
2024-09-19 20:26:42,922:INFO:Copying training dataset
2024-09-19 20:26:42,966:INFO:Defining folds
2024-09-19 20:26:42,966:INFO:Declaring metric variables
2024-09-19 20:26:42,968:INFO:Importing untrained model
2024-09-19 20:26:42,969:INFO:K Neighbors Classifier Imported successfully
2024-09-19 20:26:42,971:INFO:Starting cross validation
2024-09-19 20:26:42,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:26:52,320:INFO:Calculating mean and std
2024-09-19 20:26:52,323:INFO:Creating metrics dataframe
2024-09-19 20:26:52,327:INFO:Uploading results into container
2024-09-19 20:26:52,328:INFO:Uploading model into container now
2024-09-19 20:26:52,328:INFO:_master_model_container: 2
2024-09-19 20:26:52,328:INFO:_display_container: 2
2024-09-19 20:26:52,329:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-19 20:26:52,329:INFO:create_model() successfully completed......................................
2024-09-19 20:26:52,451:INFO:SubProcess create_model() end ==================================
2024-09-19 20:26:52,451:INFO:Creating metrics dataframe
2024-09-19 20:26:52,454:INFO:Initializing Naive Bayes
2024-09-19 20:26:52,454:INFO:Total runtime is 0.5162495493888855 minutes
2024-09-19 20:26:52,455:INFO:SubProcess create_model() called ==================================
2024-09-19 20:26:52,456:INFO:Initializing create_model()
2024-09-19 20:26:52,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:26:52,456:INFO:Checking exceptions
2024-09-19 20:26:52,456:INFO:Importing libraries
2024-09-19 20:26:52,456:INFO:Copying training dataset
2024-09-19 20:26:52,503:INFO:Defining folds
2024-09-19 20:26:52,503:INFO:Declaring metric variables
2024-09-19 20:26:52,505:INFO:Importing untrained model
2024-09-19 20:26:52,507:INFO:Naive Bayes Imported successfully
2024-09-19 20:26:52,511:INFO:Starting cross validation
2024-09-19 20:26:52,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:26:53,312:INFO:Calculating mean and std
2024-09-19 20:26:53,315:INFO:Creating metrics dataframe
2024-09-19 20:26:53,319:INFO:Uploading results into container
2024-09-19 20:26:53,319:INFO:Uploading model into container now
2024-09-19 20:26:53,320:INFO:_master_model_container: 3
2024-09-19 20:26:53,320:INFO:_display_container: 2
2024-09-19 20:26:53,320:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-19 20:26:53,321:INFO:create_model() successfully completed......................................
2024-09-19 20:26:53,435:INFO:SubProcess create_model() end ==================================
2024-09-19 20:26:53,436:INFO:Creating metrics dataframe
2024-09-19 20:26:53,439:INFO:Initializing Decision Tree Classifier
2024-09-19 20:26:53,439:INFO:Total runtime is 0.5326739986737569 minutes
2024-09-19 20:26:53,441:INFO:SubProcess create_model() called ==================================
2024-09-19 20:26:53,441:INFO:Initializing create_model()
2024-09-19 20:26:53,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:26:53,441:INFO:Checking exceptions
2024-09-19 20:26:53,442:INFO:Importing libraries
2024-09-19 20:26:53,442:INFO:Copying training dataset
2024-09-19 20:26:53,491:INFO:Defining folds
2024-09-19 20:26:53,491:INFO:Declaring metric variables
2024-09-19 20:26:53,494:INFO:Importing untrained model
2024-09-19 20:26:53,496:INFO:Decision Tree Classifier Imported successfully
2024-09-19 20:26:53,500:INFO:Starting cross validation
2024-09-19 20:26:53,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:26:55,913:INFO:Calculating mean and std
2024-09-19 20:26:55,919:INFO:Creating metrics dataframe
2024-09-19 20:26:55,923:INFO:Uploading results into container
2024-09-19 20:26:55,924:INFO:Uploading model into container now
2024-09-19 20:26:55,925:INFO:_master_model_container: 4
2024-09-19 20:26:55,925:INFO:_display_container: 2
2024-09-19 20:26:55,926:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2024-09-19 20:26:55,927:INFO:create_model() successfully completed......................................
2024-09-19 20:26:56,090:INFO:SubProcess create_model() end ==================================
2024-09-19 20:26:56,090:INFO:Creating metrics dataframe
2024-09-19 20:26:56,095:INFO:Initializing SVM - Linear Kernel
2024-09-19 20:26:56,096:INFO:Total runtime is 0.5769434491793314 minutes
2024-09-19 20:26:56,100:INFO:SubProcess create_model() called ==================================
2024-09-19 20:26:56,101:INFO:Initializing create_model()
2024-09-19 20:26:56,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:26:56,101:INFO:Checking exceptions
2024-09-19 20:26:56,102:INFO:Importing libraries
2024-09-19 20:26:56,102:INFO:Copying training dataset
2024-09-19 20:26:56,171:INFO:Defining folds
2024-09-19 20:26:56,171:INFO:Declaring metric variables
2024-09-19 20:26:56,175:INFO:Importing untrained model
2024-09-19 20:26:56,178:INFO:SVM - Linear Kernel Imported successfully
2024-09-19 20:26:56,193:INFO:Starting cross validation
2024-09-19 20:26:56,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:27:04,720:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:04,726:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:04,966:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:04,977:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:05,410:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:05,417:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:05,657:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:05,662:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:05,930:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:05,937:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:06,389:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:06,395:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:06,459:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:06,473:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:06,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,093:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,093:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,099:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:27:08,108:INFO:Calculating mean and std
2024-09-19 20:27:08,110:INFO:Creating metrics dataframe
2024-09-19 20:27:08,113:INFO:Uploading results into container
2024-09-19 20:27:08,114:INFO:Uploading model into container now
2024-09-19 20:27:08,114:INFO:_master_model_container: 5
2024-09-19 20:27:08,115:INFO:_display_container: 2
2024-09-19 20:27:08,115:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-19 20:27:08,116:INFO:create_model() successfully completed......................................
2024-09-19 20:27:08,230:INFO:SubProcess create_model() end ==================================
2024-09-19 20:27:08,230:INFO:Creating metrics dataframe
2024-09-19 20:27:08,234:INFO:Initializing Ridge Classifier
2024-09-19 20:27:08,235:INFO:Total runtime is 0.7792576471964517 minutes
2024-09-19 20:27:08,236:INFO:SubProcess create_model() called ==================================
2024-09-19 20:27:08,236:INFO:Initializing create_model()
2024-09-19 20:27:08,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:27:08,236:INFO:Checking exceptions
2024-09-19 20:27:08,237:INFO:Importing libraries
2024-09-19 20:27:08,237:INFO:Copying training dataset
2024-09-19 20:27:08,292:INFO:Defining folds
2024-09-19 20:27:08,292:INFO:Declaring metric variables
2024-09-19 20:27:08,294:INFO:Importing untrained model
2024-09-19 20:27:08,296:INFO:Ridge Classifier Imported successfully
2024-09-19 20:27:08,300:INFO:Starting cross validation
2024-09-19 20:27:08,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:27:08,545:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14206e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,592:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,595:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15081e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,663:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13435e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,680:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,765:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,777:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14836e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,838:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,903:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14565e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,918:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14873e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,939:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.13625e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,940:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14962e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,966:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,972:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.15831e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:08,978:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,985:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:08,995:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:09,000:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.14865e-11): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-19 20:27:09,007:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:09,029:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:09,045:INFO:Calculating mean and std
2024-09-19 20:27:09,047:INFO:Creating metrics dataframe
2024-09-19 20:27:09,050:INFO:Uploading results into container
2024-09-19 20:27:09,051:INFO:Uploading model into container now
2024-09-19 20:27:09,051:INFO:_master_model_container: 6
2024-09-19 20:27:09,052:INFO:_display_container: 2
2024-09-19 20:27:09,053:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-09-19 20:27:09,053:INFO:create_model() successfully completed......................................
2024-09-19 20:27:09,156:INFO:SubProcess create_model() end ==================================
2024-09-19 20:27:09,156:INFO:Creating metrics dataframe
2024-09-19 20:27:09,160:INFO:Initializing Random Forest Classifier
2024-09-19 20:27:09,160:INFO:Total runtime is 0.7946819980939228 minutes
2024-09-19 20:27:09,161:INFO:SubProcess create_model() called ==================================
2024-09-19 20:27:09,161:INFO:Initializing create_model()
2024-09-19 20:27:09,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:27:09,161:INFO:Checking exceptions
2024-09-19 20:27:09,162:INFO:Importing libraries
2024-09-19 20:27:09,162:INFO:Copying training dataset
2024-09-19 20:27:09,209:INFO:Defining folds
2024-09-19 20:27:09,209:INFO:Declaring metric variables
2024-09-19 20:27:09,211:INFO:Importing untrained model
2024-09-19 20:27:09,213:INFO:Random Forest Classifier Imported successfully
2024-09-19 20:27:09,216:INFO:Starting cross validation
2024-09-19 20:27:09,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:27:31,270:INFO:Calculating mean and std
2024-09-19 20:27:31,279:INFO:Creating metrics dataframe
2024-09-19 20:27:31,284:INFO:Uploading results into container
2024-09-19 20:27:31,287:INFO:Uploading model into container now
2024-09-19 20:27:31,288:INFO:_master_model_container: 7
2024-09-19 20:27:31,288:INFO:_display_container: 2
2024-09-19 20:27:31,289:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:27:31,290:INFO:create_model() successfully completed......................................
2024-09-19 20:27:31,404:INFO:SubProcess create_model() end ==================================
2024-09-19 20:27:31,404:INFO:Creating metrics dataframe
2024-09-19 20:27:31,408:INFO:Initializing Quadratic Discriminant Analysis
2024-09-19 20:27:31,408:INFO:Total runtime is 1.1654825488726297 minutes
2024-09-19 20:27:31,410:INFO:SubProcess create_model() called ==================================
2024-09-19 20:27:31,410:INFO:Initializing create_model()
2024-09-19 20:27:31,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:27:31,410:INFO:Checking exceptions
2024-09-19 20:27:31,410:INFO:Importing libraries
2024-09-19 20:27:31,410:INFO:Copying training dataset
2024-09-19 20:27:31,465:INFO:Defining folds
2024-09-19 20:27:31,466:INFO:Declaring metric variables
2024-09-19 20:27:31,468:INFO:Importing untrained model
2024-09-19 20:27:31,470:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-19 20:27:31,472:INFO:Starting cross validation
2024-09-19 20:27:31,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:27:31,816:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:31,875:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:31,996:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,054:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,107:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,179:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,304:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,319:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,380:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,444:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:32,461:INFO:Calculating mean and std
2024-09-19 20:27:32,462:INFO:Creating metrics dataframe
2024-09-19 20:27:32,463:INFO:Uploading results into container
2024-09-19 20:27:32,464:INFO:Uploading model into container now
2024-09-19 20:27:32,464:INFO:_master_model_container: 8
2024-09-19 20:27:32,464:INFO:_display_container: 2
2024-09-19 20:27:32,464:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-19 20:27:32,465:INFO:create_model() successfully completed......................................
2024-09-19 20:27:32,539:INFO:SubProcess create_model() end ==================================
2024-09-19 20:27:32,541:INFO:Creating metrics dataframe
2024-09-19 20:27:32,546:INFO:Initializing Ada Boost Classifier
2024-09-19 20:27:32,546:INFO:Total runtime is 1.1844531695048013 minutes
2024-09-19 20:27:32,548:INFO:SubProcess create_model() called ==================================
2024-09-19 20:27:32,549:INFO:Initializing create_model()
2024-09-19 20:27:32,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:27:32,549:INFO:Checking exceptions
2024-09-19 20:27:32,549:INFO:Importing libraries
2024-09-19 20:27:32,549:INFO:Copying training dataset
2024-09-19 20:27:32,599:INFO:Defining folds
2024-09-19 20:27:32,599:INFO:Declaring metric variables
2024-09-19 20:27:32,601:INFO:Importing untrained model
2024-09-19 20:27:32,604:INFO:Ada Boost Classifier Imported successfully
2024-09-19 20:27:32,608:INFO:Starting cross validation
2024-09-19 20:27:32,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:27:32,798:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:32,848:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:32,906:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:32,972:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:33,087:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:33,091:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:33,112:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:33,116:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:37,317:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,447:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,490:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,538:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,571:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,600:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,625:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,637:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:37,652:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:37,677:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-19 20:27:39,822:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:39,839:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:27:39,856:INFO:Calculating mean and std
2024-09-19 20:27:39,857:INFO:Creating metrics dataframe
2024-09-19 20:27:39,858:INFO:Uploading results into container
2024-09-19 20:27:39,859:INFO:Uploading model into container now
2024-09-19 20:27:39,859:INFO:_master_model_container: 9
2024-09-19 20:27:39,859:INFO:_display_container: 2
2024-09-19 20:27:39,859:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2024-09-19 20:27:39,860:INFO:create_model() successfully completed......................................
2024-09-19 20:27:39,934:INFO:SubProcess create_model() end ==================================
2024-09-19 20:27:39,934:INFO:Creating metrics dataframe
2024-09-19 20:27:39,939:INFO:Initializing Gradient Boosting Classifier
2024-09-19 20:27:39,939:INFO:Total runtime is 1.3076661189397174 minutes
2024-09-19 20:27:39,941:INFO:SubProcess create_model() called ==================================
2024-09-19 20:27:39,941:INFO:Initializing create_model()
2024-09-19 20:27:39,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:27:39,941:INFO:Checking exceptions
2024-09-19 20:27:39,942:INFO:Importing libraries
2024-09-19 20:27:39,942:INFO:Copying training dataset
2024-09-19 20:27:39,991:INFO:Defining folds
2024-09-19 20:27:39,991:INFO:Declaring metric variables
2024-09-19 20:27:39,993:INFO:Importing untrained model
2024-09-19 20:27:39,995:INFO:Gradient Boosting Classifier Imported successfully
2024-09-19 20:27:39,998:INFO:Starting cross validation
2024-09-19 20:27:39,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:28:30,037:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,138:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,365:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,488:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,509:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,522:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,524:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:30,612:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:58,547:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:58,651:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:58,668:INFO:Calculating mean and std
2024-09-19 20:28:58,669:INFO:Creating metrics dataframe
2024-09-19 20:28:58,671:INFO:Uploading results into container
2024-09-19 20:28:58,672:INFO:Uploading model into container now
2024-09-19 20:28:58,672:INFO:_master_model_container: 10
2024-09-19 20:28:58,672:INFO:_display_container: 2
2024-09-19 20:28:58,673:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-19 20:28:58,673:INFO:create_model() successfully completed......................................
2024-09-19 20:28:58,751:INFO:SubProcess create_model() end ==================================
2024-09-19 20:28:58,751:INFO:Creating metrics dataframe
2024-09-19 20:28:58,758:INFO:Initializing Linear Discriminant Analysis
2024-09-19 20:28:58,758:INFO:Total runtime is 2.6213110327720637 minutes
2024-09-19 20:28:58,759:INFO:SubProcess create_model() called ==================================
2024-09-19 20:28:58,760:INFO:Initializing create_model()
2024-09-19 20:28:58,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:28:58,760:INFO:Checking exceptions
2024-09-19 20:28:58,760:INFO:Importing libraries
2024-09-19 20:28:58,760:INFO:Copying training dataset
2024-09-19 20:28:58,811:INFO:Defining folds
2024-09-19 20:28:58,811:INFO:Declaring metric variables
2024-09-19 20:28:58,813:INFO:Importing untrained model
2024-09-19 20:28:58,815:INFO:Linear Discriminant Analysis Imported successfully
2024-09-19 20:28:58,817:INFO:Starting cross validation
2024-09-19 20:28:58,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:28:59,040:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,118:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,157:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,221:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,245:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,294:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,331:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,379:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,411:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,437:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-09-19 20:28:59,455:INFO:Calculating mean and std
2024-09-19 20:28:59,456:INFO:Creating metrics dataframe
2024-09-19 20:28:59,457:INFO:Uploading results into container
2024-09-19 20:28:59,458:INFO:Uploading model into container now
2024-09-19 20:28:59,458:INFO:_master_model_container: 11
2024-09-19 20:28:59,458:INFO:_display_container: 2
2024-09-19 20:28:59,458:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-19 20:28:59,458:INFO:create_model() successfully completed......................................
2024-09-19 20:28:59,514:INFO:SubProcess create_model() end ==================================
2024-09-19 20:28:59,514:INFO:Creating metrics dataframe
2024-09-19 20:28:59,518:INFO:Initializing Extra Trees Classifier
2024-09-19 20:28:59,518:INFO:Total runtime is 2.6339764157931005 minutes
2024-09-19 20:28:59,519:INFO:SubProcess create_model() called ==================================
2024-09-19 20:28:59,519:INFO:Initializing create_model()
2024-09-19 20:28:59,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:28:59,519:INFO:Checking exceptions
2024-09-19 20:28:59,519:INFO:Importing libraries
2024-09-19 20:28:59,519:INFO:Copying training dataset
2024-09-19 20:28:59,560:INFO:Defining folds
2024-09-19 20:28:59,560:INFO:Declaring metric variables
2024-09-19 20:28:59,562:INFO:Importing untrained model
2024-09-19 20:28:59,563:INFO:Extra Trees Classifier Imported successfully
2024-09-19 20:28:59,566:INFO:Starting cross validation
2024-09-19 20:28:59,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:29:13,639:INFO:Calculating mean and std
2024-09-19 20:29:13,653:INFO:Creating metrics dataframe
2024-09-19 20:29:13,657:INFO:Uploading results into container
2024-09-19 20:29:13,658:INFO:Uploading model into container now
2024-09-19 20:29:13,659:INFO:_master_model_container: 12
2024-09-19 20:29:13,659:INFO:_display_container: 2
2024-09-19 20:29:13,660:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2024-09-19 20:29:13,660:INFO:create_model() successfully completed......................................
2024-09-19 20:29:13,771:INFO:SubProcess create_model() end ==================================
2024-09-19 20:29:13,771:INFO:Creating metrics dataframe
2024-09-19 20:29:13,777:INFO:Initializing Extreme Gradient Boosting
2024-09-19 20:29:13,777:INFO:Total runtime is 2.871629162629445 minutes
2024-09-19 20:29:13,780:INFO:SubProcess create_model() called ==================================
2024-09-19 20:29:13,780:INFO:Initializing create_model()
2024-09-19 20:29:13,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:29:13,780:INFO:Checking exceptions
2024-09-19 20:29:13,780:INFO:Importing libraries
2024-09-19 20:29:13,781:INFO:Copying training dataset
2024-09-19 20:29:13,840:INFO:Defining folds
2024-09-19 20:29:13,841:INFO:Declaring metric variables
2024-09-19 20:29:13,843:INFO:Importing untrained model
2024-09-19 20:29:13,845:INFO:Extreme Gradient Boosting Imported successfully
2024-09-19 20:29:13,848:INFO:Starting cross validation
2024-09-19 20:29:13,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:29:14,488:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2024-09-19 20:29:20,556:INFO:Calculating mean and std
2024-09-19 20:29:20,558:INFO:Creating metrics dataframe
2024-09-19 20:29:20,560:INFO:Uploading results into container
2024-09-19 20:29:20,560:INFO:Uploading model into container now
2024-09-19 20:29:20,561:INFO:_master_model_container: 13
2024-09-19 20:29:20,561:INFO:_display_container: 2
2024-09-19 20:29:20,562:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-19 20:29:20,562:INFO:create_model() successfully completed......................................
2024-09-19 20:29:20,627:INFO:SubProcess create_model() end ==================================
2024-09-19 20:29:20,627:INFO:Creating metrics dataframe
2024-09-19 20:29:20,632:INFO:Initializing Light Gradient Boosting Machine
2024-09-19 20:29:20,632:INFO:Total runtime is 2.9858784000078833 minutes
2024-09-19 20:29:20,633:INFO:SubProcess create_model() called ==================================
2024-09-19 20:29:20,633:INFO:Initializing create_model()
2024-09-19 20:29:20,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:29:20,633:INFO:Checking exceptions
2024-09-19 20:29:20,633:INFO:Importing libraries
2024-09-19 20:29:20,633:INFO:Copying training dataset
2024-09-19 20:29:20,674:INFO:Defining folds
2024-09-19 20:29:20,674:INFO:Declaring metric variables
2024-09-19 20:29:20,676:INFO:Importing untrained model
2024-09-19 20:29:20,677:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-19 20:29:20,679:INFO:Starting cross validation
2024-09-19 20:29:20,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:29:40,126:INFO:Calculating mean and std
2024-09-19 20:29:40,129:INFO:Creating metrics dataframe
2024-09-19 20:29:40,131:INFO:Uploading results into container
2024-09-19 20:29:40,131:INFO:Uploading model into container now
2024-09-19 20:29:40,132:INFO:_master_model_container: 14
2024-09-19 20:29:40,132:INFO:_display_container: 2
2024-09-19 20:29:40,133:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-19 20:29:40,133:INFO:create_model() successfully completed......................................
2024-09-19 20:29:40,204:INFO:SubProcess create_model() end ==================================
2024-09-19 20:29:40,204:INFO:Creating metrics dataframe
2024-09-19 20:29:40,210:INFO:Initializing Dummy Classifier
2024-09-19 20:29:40,210:INFO:Total runtime is 3.312179613113403 minutes
2024-09-19 20:29:40,212:INFO:SubProcess create_model() called ==================================
2024-09-19 20:29:40,212:INFO:Initializing create_model()
2024-09-19 20:29:40,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x336fc04c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:29:40,212:INFO:Checking exceptions
2024-09-19 20:29:40,212:INFO:Importing libraries
2024-09-19 20:29:40,212:INFO:Copying training dataset
2024-09-19 20:29:40,263:INFO:Defining folds
2024-09-19 20:29:40,263:INFO:Declaring metric variables
2024-09-19 20:29:40,266:INFO:Importing untrained model
2024-09-19 20:29:40,268:INFO:Dummy Classifier Imported successfully
2024-09-19 20:29:40,272:INFO:Starting cross validation
2024-09-19 20:29:40,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-19 20:29:40,500:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,527:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,568:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,633:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,664:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,690:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,717:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,769:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,807:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,836:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-19 20:29:40,851:INFO:Calculating mean and std
2024-09-19 20:29:40,852:INFO:Creating metrics dataframe
2024-09-19 20:29:40,853:INFO:Uploading results into container
2024-09-19 20:29:40,853:INFO:Uploading model into container now
2024-09-19 20:29:40,853:INFO:_master_model_container: 15
2024-09-19 20:29:40,853:INFO:_display_container: 2
2024-09-19 20:29:40,853:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2024-09-19 20:29:40,853:INFO:create_model() successfully completed......................................
2024-09-19 20:29:40,908:INFO:SubProcess create_model() end ==================================
2024-09-19 20:29:40,908:INFO:Creating metrics dataframe
2024-09-19 20:29:40,913:WARNING:/opt/anaconda3/envs/finance/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-09-19 20:29:40,916:INFO:Initializing create_model()
2024-09-19 20:29:40,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x177b83820>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-19 20:29:40,916:INFO:Checking exceptions
2024-09-19 20:29:40,917:INFO:Importing libraries
2024-09-19 20:29:40,917:INFO:Copying training dataset
2024-09-19 20:29:40,957:INFO:Defining folds
2024-09-19 20:29:40,957:INFO:Declaring metric variables
2024-09-19 20:29:40,957:INFO:Importing untrained model
2024-09-19 20:29:40,957:INFO:Declaring custom model
2024-09-19 20:29:40,958:INFO:Random Forest Classifier Imported successfully
2024-09-19 20:29:40,958:INFO:Cross validation set to False
2024-09-19 20:29:40,958:INFO:Fitting Model
2024-09-19 20:29:43,260:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:29:43,260:INFO:create_model() successfully completed......................................
2024-09-19 20:29:43,343:INFO:_master_model_container: 15
2024-09-19 20:29:43,345:INFO:_display_container: 2
2024-09-19 20:29:43,377:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2024-09-19 20:29:43,377:INFO:compare_models() successfully completed......................................
